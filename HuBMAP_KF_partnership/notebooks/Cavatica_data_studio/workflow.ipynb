{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a071dd7a-e192-4688-8d13-9a95e62ba6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/20 12:06:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndf = spark.read.parquet('/sbgenomics/project-files/BS_0302Y3N5.parquet/')\\ndf = df.select(['contigName','start', 'end', 'names', 'referenceAllele',                  'alternateAlleles', 'qual', 'INFO_DP', 'splitFromMultiAllelic','genotypes'])\\n#print(df.count())\\n\\ndf = df.select(col('contigName').alias('chromosome'),'start','end',col('referenceAllele').alias('reference'),\\n         col('alternateAlleles').alias('alternate'),'qual','INFO_DP', 'splitFromMultiAllelic','genotypes')\\ndf = df.withColumn('alternate',F.explode('alternate'))\\ndf.show(1)\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "from collections import Counter\n",
    "import time\n",
    "#import pyranges as pr\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,collect_list, concat, lit, when, monotonically_increasing_id, concat_ws, broadcast\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"parquet\").getOrCreate()\n",
    "\n",
    "\n",
    "'''\n",
    "df = spark.read.parquet('/sbgenomics/project-files/BS_0302Y3N5.parquet/')\n",
    "df = df.select(['contigName','start', 'end', 'names', 'referenceAllele', \\\n",
    "                 'alternateAlleles', 'qual', 'INFO_DP', 'splitFromMultiAllelic','genotypes'])\n",
    "#print(df.count())\n",
    "\n",
    "df = df.select(col('contigName').alias('chromosome'),'start','end',col('referenceAllele').alias('reference'),\n",
    "         col('alternateAlleles').alias('alternate'),'qual','INFO_DP', 'splitFromMultiAllelic','genotypes')\n",
    "df = df.withColumn('alternate',F.explode('alternate'))\n",
    "df.show(1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4bfa04-41f7-4088-92b7-79fbec0b900c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177354\n",
      "+---------+---------+---------+---------+-----------------+------+-------+---------------------+--------------------+-------+---------+----------+------------+----------+\n",
      "|    start|      end|reference|alternate|unique_variant_id|  qual|INFO_DP|splitFromMultiAllelic|           genotypes| symbol|     rsID|cadd_score|eqtl_boolean|chromosome|\n",
      "+---------+---------+---------+---------+-----------------+------+-------+---------------------+--------------------+-------+---------+----------+------------+----------+\n",
      "|127508781|127508781|        T|        C|  6:127508781:T:C|558.77|     41|                 true|[{BS_0302Y3N5, 99...|YWHAZP4| rs553228|     0.071|           1|         6|\n",
      "|149889587|149889587|        C|        T|  6:149889587:C:T|545.77|     37|                 true|[{BS_0302Y3N5, 99...| RAET1E|rs6925151|     3.341|           1|         6|\n",
      "+---------+---------+---------+---------+-----------------+------+-------+---------------------+--------------------+-------+---------+----------+------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r = spark.read.parquet('/sbgenomics/project-files/BS_0302Y3N5_chd_scored_variants.parquet')\n",
    "print(r.count())\n",
    "r.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d06245-66ad-4150-a617-3faa7ea4e7de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4822\n",
      "+---------+---------+---------+---------+-------+--------------------+------+----+----------+------------+----------+\n",
      "|    start|      end|reference|alternate|INFO_DP|           genotypes|symbol|rsID|cadd_score|eqtl_boolean|chromosome|\n",
      "+---------+---------+---------+---------+-------+--------------------+------+----+----------+------------+----------+\n",
      "|129486504|129486504|        C|        A|     46|[{BS_0302Y3N5, 99...|      |    |      22.2|           0|         6|\n",
      "| 32581807| 32581807|        C|       CT|     55|[{BS_0302Y3N5, 99...|      |    |      23.5|           0|         6|\n",
      "| 63280743| 63280743|        A|        G|     36|[{BS_0302Y3N5, 99...|      |    |      20.5|           0|         6|\n",
      "| 32581793| 32581793|        T|        G|     52|[{BS_0302Y3N5, 18...|      |    |      24.1|           0|         6|\n",
      "|129287979|129287979|        A|        C|     41|[{BS_0302Y3N5, 99...|      |    |      23.1|           0|         6|\n",
      "+---------+---------+---------+---------+-------+--------------------+------+----+----------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take just the variants w/ cadd scores strictly over 20.\n",
    "gt20_vars = r.drop('unique_variant_id','qual','splitFromMultiAllelic').where((col('eqtl_boolean')!= 1))# &\\\n",
    "                                                                           # (col('cadd_score') < 20.0))\n",
    "print(gt20_vars.count())\n",
    "gt20_vars.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c1aa520-c14f-4616-b2fa-e263c73eb3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "413349"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.drop('unique_variant_id','qual','splitFromMultiAllelic').where(col('symbol')!= '').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91dfdc5-cb43-4dfb-9a34-60925fd726cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------+----+-------+---------------------+--------------------+--------------------+----------+\n",
      "|   start|     end|reference|alternate|qual|INFO_DP|splitFromMultiAllelic|           genotypes|   unique_variant_id|chromosome|\n",
      "+--------+--------+---------+---------+----+-------+---------------------+--------------------+--------------------+----------+\n",
      "|35837428|35837431|        T|<NON_REF>|null|   null|                false|[{BS_0302Y3N5, 99...|14:35837428:T:<NO...|        14|\n",
      "+--------+--------+---------+---------+----+-------+---------------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join = spark.read.parquet('/sbgenomics/project-files/df_bed_leftsemi.parquet')\n",
    "df_join.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a847a51-9dd0-4121-b34a-3ddc6fa40df3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load in all additional files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3361b9a0-3356-4ec0-853b-4c9fa2e48932",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadd_scores_gt20 = spark.read.parquet('/sbgenomics/project-files/cadd_gt20_snps.parquet')\n",
    "#cadd_scores_gt20.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f62aa5-7618-4275-a10e-f0fdc5857289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+---------+----------+-----------------+\n",
      "|chromosome| start|reference|alternate|cadd_score|unique_variant_id|\n",
      "+----------+------+---------+---------+----------+-----------------+\n",
      "|        11|426388|        A|        G|     3.628|    11:426388:A:G|\n",
      "+----------+------+---------+---------+----------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cadd_chrom = spark.read.option(\"header\",\"true\").parquet('/sbgenomics/project-files/cadd_chrom_files_parquet/chr11')\n",
    "\n",
    "cadd_chrom = cadd_chrom.select(col(\"0\").alias(\"chromosome\"), col(\"1\").alias(\"start\"),\n",
    "                col(\"2\").alias(\"reference\"),col(\"3\").alias(\"alternate\"),col('5').alias('cadd_score'))\n",
    "cadd_chrom = cadd_chrom.withColumn('unique_variant_id',concat(col(\"chromosome\"),\n",
    "                    lit(\":\"),col(\"start\"),lit(':'),col('reference'),lit(':'),col('alternate')))\n",
    "cadd_chrom.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ec9a0ac-3dfc-4d82-8e87-ec7e3c7fd8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+----------+--------------------+----------+\n",
      "|   start|reference|alternate|cadd_score|   unique_variant_id|chromosome|\n",
      "+--------+---------+---------+----------+--------------------+----------+\n",
      "|36449839|        A|AAAAAAAAC|     0.513|1:36449839:A:AAAA...|         1|\n",
      "+--------+---------+---------+----------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cadd_ALL_indels = spark.read.parquet('/sbgenomics/project-files/cadd_gnomad_all.parquet/')\n",
    "cadd_ALL_indels.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30c0281-3c0b-49bd-a528-a05b529f5f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+----------+----------+-----------------+\n",
      "|start|reference|alternate|cadd_score|chromosome|unique_variant_id|\n",
      "+-----+---------+---------+----------+----------+-----------------+\n",
      "|47070|        T|       TC|      23.2|        10|    10:47070:T:TC|\n",
      "+-----+---------+---------+----------+----------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cadd_indels = spark.read.parquet('/sbgenomics/project-files/cadd_gt20_gnomAD_all_chroms.parquet')\n",
    "cadd_indels.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b3becd-f2fb-419f-98ba-a88031e7c520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------+-----------+------+-----------------+----------+\n",
      "| start|reference|alternate|       rsID|symbol|unique_variant_id|chromosome|\n",
      "+------+---------+---------+-----------+------+-----------------+----------+\n",
      "|668472|        C|        A|rs372034137|ZNF595|     4:668472:C:A|         4|\n",
      "+------+---------+---------+-----------+------+-----------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtls_high_impact = spark.read.parquet('/sbgenomics/project-files/eqtls_and_high_impact.parquet')\n",
    "eqtls_high_impact.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62dad5f6-821d-4ca7-925b-25999b1f76b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------+\n",
      "|start_bed| end_bed|chromosome_bed|\n",
      "+---------+--------+--------------+\n",
      "| 38297023|38323217|            17|\n",
      "+---------+--------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "whole_genome_bed = spark.read.option(\"header\",\"true\").parquet(\n",
    "                            '/sbgenomics/project-files/bed_protein_coding_coords_only.parquet')\n",
    "whole_genome_bed.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a511c4-79f8-4805-8757-64b9cc0552fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Begin workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5fef42-b899-4af5-8340-73c5a15285e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NonRef = df_join.where( (col('alternate') == '<NON_REF>')) # will add this back on later!\n",
    "df_noNonRef = df_join.where(~ (col('alternate') == '<NON_REF>')) # only need to get CADD scores for this df\n",
    "\n",
    "df_snps = df_noNonRef.where((F.length(\"reference\") == 1) & (F.length(\"alternate\") == 1))                    \n",
    "df_indels = df_noNonRef.where(~ ((F.length(\"reference\") == 1) & (F.length(\"alternate\") == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6dcfcd7-5dfb-4c1d-bee3-859ac2fe20d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cadd_scores_gt20' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1503/1436519970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_snps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_snps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcadd_scores_gt20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unique_variant_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cadd_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"unique_variant_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"leftsemi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_snps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult_snps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cadd_scores_gt20' is not defined"
     ]
    }
   ],
   "source": [
    "result_snps = df_snps.join(cadd_scores_gt20.select('unique_variant_id','cadd_score'), [\"unique_variant_id\"], \"leftsemi\")\n",
    "print(result_snps.count())\n",
    "result_snps.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358f89ea-6a7d-4d49-9a05-e3e0e1e2fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2785"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47c608e-ee6c-4206-9034-fe1ebccf195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=====================================================>  (21 + 1) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+---------+---------+------+-------+---------------------+--------------------+----------+----------+\n",
      "|unique_variant_id|   start|     end|reference|alternate|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|chromosome|cadd_score|\n",
      "+-----------------+--------+--------+---------+---------+------+-------+---------------------+--------------------+----------+----------+\n",
      "|  3:27717830:T:TA|27717830|27717831|        T|       TA|289.73|     29|                 true|[{BS_0302Y3N5, 99...|         3|      21.7|\n",
      "+-----------------+--------+--------+---------+---------+------+-------+---------------------+--------------------+----------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_indels = df_indels.join(cadd_indels.select('unique_variant_id','cadd_score'), [\"unique_variant_id\"], \"inner\");\n",
    "print(result_indels.count())\n",
    "result_indels.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f85f129-b3e3-400f-b0fd-92bf4c3f4672",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/28 12:14:27 ERROR BroadcastExchangeExec: Could not execute broadcast in 300 secs.\n",
      "java.util.concurrent.TimeoutException\n",
      "\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:194)\n",
      "\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:515)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeBroadcast$1(SparkPlan.scala:193)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:189)\n",
      "\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:203)\n",
      "\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareRelation(BroadcastHashJoinExec.scala:217)\n",
      "\tat org.apache.spark.sql.execution.joins.HashJoin.codegenSemi(HashJoin.scala:580)\n",
      "\tat org.apache.spark.sql.execution.joins.HashJoin.codegenSemi$(HashJoin.scala:579)\n",
      "\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenSemi(BroadcastHashJoinExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume(HashJoin.scala:359)\n",
      "\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume$(HashJoin.scala:355)\n",
      "\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.constructDoConsumeFunction(WholeStageCodegenExec.scala:221)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:192)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n",
      "\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:41)\n",
      "\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:87)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n",
      "\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:113)\n",
      "\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:238)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n",
      "\tat org.apache.spark.sql.execution.ColumnarToRowExec.consume(Columnar.scala:66)\n",
      "\tat org.apache.spark.sql.execution.ColumnarToRowExec.doProduce(Columnar.scala:191)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.ColumnarToRowExec.produce(Columnar.scala:66)\n",
      "\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:153)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:113)\n",
      "\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:54)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n",
      "\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce(HashJoin.scala:352)\n",
      "\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce$(HashJoin.scala:351)\n",
      "\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:54)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n",
      "\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:655)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:718)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.UnionExec.$anonfun$doExecute$5(basicPhysicalOperators.scala:667)\n",
      "\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:392)\n",
      "\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n",
      "\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n",
      "\tat scala.collection.immutable.List.map(List.scala:298)\n",
      "\tat org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:667)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n",
      "\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n",
      "\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:746)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:118)\n",
      "\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:118)\n",
      "\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:151)\n",
      "\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:149)\n",
      "\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:166)\n",
      "\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n",
      "\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n",
      "\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n",
      "\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n",
      "\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n",
      "\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:746)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:321)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:387)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.count(Dataset.scala:3005)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "[Stage 51:================================>                       (27 + 1) / 47]\r"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o287.count.\n: org.apache.spark.SparkException: Could not execute broadcast in 300 secs. You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:205)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:515)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeBroadcast$1(SparkPlan.scala:193)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:189)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:203)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareRelation(BroadcastHashJoinExec.scala:217)\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenSemi(HashJoin.scala:580)\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenSemi$(HashJoin.scala:579)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenSemi(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume(HashJoin.scala:359)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume$(HashJoin.scala:355)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.CodegenSupport.constructDoConsumeFunction(WholeStageCodegenExec.scala:221)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:192)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:87)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:113)\n\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:238)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.ColumnarToRowExec.consume(Columnar.scala:66)\n\tat org.apache.spark.sql.execution.ColumnarToRowExec.doProduce(Columnar.scala:191)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ColumnarToRowExec.produce(Columnar.scala:66)\n\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:153)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:113)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:54)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce(HashJoin.scala:352)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce$(HashJoin.scala:351)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:54)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:655)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:718)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.UnionExec.$anonfun$doExecute$5(basicPhysicalOperators.scala:667)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.immutable.List.map(List.scala:298)\n\tat org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:667)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:746)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:118)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:118)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:151)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:149)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:166)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:163)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:746)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:321)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:387)\n\tat org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)\n\tat org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.count(Dataset.scala:3005)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.util.concurrent.TimeoutException\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:194)\n\t... 144 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_390/2347476911.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresults_gt20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_snps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_indels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_gt20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mresults_gt20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \"\"\"\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o287.count.\n: org.apache.spark.SparkException: Could not execute broadcast in 300 secs. You can increase the timeout for broadcasts via spark.sql.broadcastTimeout or disable broadcast join by setting spark.sql.autoBroadcastJoinThreshold to -1\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:205)\n\tat org.apache.spark.sql.execution.InputAdapter.doExecuteBroadcast(WholeStageCodegenExec.scala:515)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeBroadcast$1(SparkPlan.scala:193)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.executeBroadcast(SparkPlan.scala:189)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareBroadcast(BroadcastHashJoinExec.scala:203)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.prepareRelation(BroadcastHashJoinExec.scala:217)\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenSemi(HashJoin.scala:580)\n\tat org.apache.spark.sql.execution.joins.HashJoin.codegenSemi$(HashJoin.scala:579)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.codegenSemi(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume(HashJoin.scala:359)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doConsume$(HashJoin.scala:355)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doConsume(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.CodegenSupport.constructDoConsumeFunction(WholeStageCodegenExec.scala:221)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:192)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.ProjectExec.consume(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ProjectExec.doConsume(basicPhysicalOperators.scala:87)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.FilterExec.consume(basicPhysicalOperators.scala:113)\n\tat org.apache.spark.sql.execution.FilterExec.doConsume(basicPhysicalOperators.scala:238)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume(WholeStageCodegenExec.scala:194)\n\tat org.apache.spark.sql.execution.CodegenSupport.consume$(WholeStageCodegenExec.scala:149)\n\tat org.apache.spark.sql.execution.ColumnarToRowExec.consume(Columnar.scala:66)\n\tat org.apache.spark.sql.execution.ColumnarToRowExec.doProduce(Columnar.scala:191)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ColumnarToRowExec.produce(Columnar.scala:66)\n\tat org.apache.spark.sql.execution.FilterExec.doProduce(basicPhysicalOperators.scala:153)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.FilterExec.produce(basicPhysicalOperators.scala:113)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:54)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce(HashJoin.scala:352)\n\tat org.apache.spark.sql.execution.joins.HashJoin.doProduce$(HashJoin.scala:351)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.doProduce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.joins.BroadcastHashJoinExec.produce(BroadcastHashJoinExec.scala:40)\n\tat org.apache.spark.sql.execution.ProjectExec.doProduce(basicPhysicalOperators.scala:54)\n\tat org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:95)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:90)\n\tat org.apache.spark.sql.execution.ProjectExec.produce(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:655)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:718)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.UnionExec.$anonfun$doExecute$5(basicPhysicalOperators.scala:667)\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:238)\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:231)\n\tat scala.collection.immutable.List.map(List.scala:298)\n\tat org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:667)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:746)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:118)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:118)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:151)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:149)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:166)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:163)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:141)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:746)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:321)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:387)\n\tat org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:3006)\n\tat org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:3005)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.count(Dataset.scala:3005)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.util.concurrent.TimeoutException\n\tat java.util.concurrent.FutureTask.get(FutureTask.java:205)\n\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.doExecuteBroadcast(BroadcastExchangeExec.scala:194)\n\t... 144 more\n"
     ]
    }
   ],
   "source": [
    "result_snps = result_snps.select(result_snps.columns+[lit('').alias(\"symbol\"),lit('').alias(\"rsID\")])\n",
    "result_indels = result_indels.select(result_indels.columns+[lit('').alias(\"symbol\"),lit('').alias(\"rsID\")])\n",
    "\n",
    "results_gt20 = result_snps.union(result_indels)\n",
    "print(results_gt20.count())\n",
    "results_gt20.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f09224ff-0f6b-4b75-bbcc-70bc37a4454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:======================================================> (46 + 1) / 47]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+---------+---------+----+-------+---------------------+--------------------+----------+------+----+------+----+\n",
      "|unique_variant_id|   start|     end|reference|alternate|qual|INFO_DP|splitFromMultiAllelic|           genotypes|chromosome|symbol|rsID|symbol|rsID|\n",
      "+-----------------+--------+--------+---------+---------+----+-------+---------------------+--------------------+----------+------+----+------+----+\n",
      "|  10:27908546:T:G|27908546|27908547|        T|        G| 0.0|     50|                 true|[{BS_0302Y3N5, 99...|        10|      |    |      |    |\n",
      "+-----------------+--------+--------+---------+---------+----+-------+---------------------+--------------------+----------+------+----+------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_snps.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d4b9976-89e6-4f56-8dd9-764b11ff6e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:=====================================================>  (21 + 1) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+--------+---------+---------+------+-------+---------------------+--------------------+----------+------+----+------+----+\n",
      "|unique_variant_id|   start|     end|reference|alternate|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|chromosome|symbol|rsID|symbol|rsID|\n",
      "+-----------------+--------+--------+---------+---------+------+-------+---------------------+--------------------+----------+------+----+------+----+\n",
      "|  3:27717830:T:TA|27717830|27717831|        T|       TA|289.73|     29|                 true|[{BS_0302Y3N5, 99...|         3|      |    |      |    |\n",
      "+-----------------+--------+--------+---------+---------+------+-------+---------------------+--------------------+----------+------+----+------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_indels.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6b03bf-901e-4aae-8273-ede93cef1bf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Join eqtl/highImpact w/ patients variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75b23878-fff1-424b-950b-cae43a19df88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+---------+---------+---------+------------+----------+\n",
      "|unique_variant_id|   start|reference|alternate|     rsID|      symbol|chromosome|\n",
      "+-----------------+--------+---------+---------+---------+------------+----------+\n",
      "|  16:69571709:G:T|69571709|        G|        T|rs4783724|RP11-123C5.5|        16|\n",
      "+-----------------+--------+---------+---------+---------+------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eqtl_highImpact_BS.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50449c57-76c3-49c5-9905-c950c58992ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+----------+\n",
      "|   start|     end|reference|alternate|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|unique_variant_id|chromosome|\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+----------+\n",
      "|35837713|35837714|        A|        G|271.77|     31|                 true|[{BS_0302Y3N5, 99...|  14:35837713:A:G|        14|\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_noNonRef.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ef4438b-713a-4cbd-b6e8-71d717263f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:===================>                                      (1 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+---------+---------+---------+------------+----------+\n",
      "|unique_variant_id|   start|reference|alternate|     rsID|      symbol|chromosome|\n",
      "+-----------------+--------+---------+---------+---------+------------+----------+\n",
      "|  16:69571709:G:T|69571709|        G|        T|rs4783724|RP11-123C5.5|        16|\n",
      "+-----------------+--------+---------+---------+---------+------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eqtl_highImpact_BS = eqtls_high_impact.join(df_noNonRef.drop('start','chromosome','reference','alternate'),['unique_variant_id'],'leftsemi')\n",
    "print(eqtl_highImpact_BS.count())\n",
    "eqtl_highImpact_BS.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403ddc5c-698f-4b3b-ba93-fe84afd5af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtl_highImpact_BS_snps = eqtl_highImpact_BS.where(((F.length(\"reference\")==1) & (F.length(\"alternate\") == 1)))\n",
    "eqtl_highImpact_BS_indels= eqtl_highImpact_BS.where(~((F.length(\"reference\")==1)& (F.length(\"alternate\")== 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afddb527-93fd-49f2-b678-3366eb1be56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqtl_highImpact_indels_scored = eqtl_highImpact_BS_indels.join(\n",
    "    cadd_ALL_indels.select('unique_variant_id','cadd_score'),['unique_variant_id'],'inner') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3fb7582-81d1-4a77-bff1-51b77fce32f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+---------+---------+-----------+-----------+----------+----------+\n",
      "|unique_variant_id|   start|reference|alternate|       rsID|     symbol|chromosome|cadd_score|\n",
      "+-----------------+--------+---------+---------+-----------+-----------+----------+----------+\n",
      "| 18:77097913:T:TA|77097913|        T|       TA|rs140236492|RP11-4B16.3|        18|     0.166|\n",
      "+-----------------+--------+---------+---------+-----------+-----------+----------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(eqtl_highImpact_indels_scored.count())\n",
    "eqtl_highImpact_indels_scored.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adb751e3-7129-4bd9-badb-7ebf03caaff0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:>(52 + 1) / 66][Stage 103:> (0 + 0) / 47][Stage 104:>  (0 + 0) / 1]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_390/3059480088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0meqtl_highImpact_snps_scored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meqtls_results_chrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meqtl_highImpact_snps_scored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0meqtl_highImpact_snps_scored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eqtls_SNPs_chrom  = eqtl_highImpact_BS_snps.where(col('chromosome') == 1)\\\n",
    "                                .withColumn('unique_variant_id',concat(col(\"chromosome\"),\n",
    "                                lit(\":\"),col(\"start\"),lit(':'),col('reference'),lit(':'),col('alternate')))\n",
    "\n",
    "eqtls_results_chrom = eqtls_SNPs_chrom.join(\n",
    "    cadd_chrom.select('unique_variant_id','cadd_score'), [\"unique_variant_id\"], \"inner\")\n",
    "\n",
    "eqtl_highImpact_snps_scored = eqtls_results_chrom\n",
    "print(eqtl_highImpact_snps_scored.count())\n",
    "eqtl_highImpact_snps_scored.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ad1f46a-37c6-42c0-8ff0-d6fded77db18",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eqtl_highImpact_snps_scored' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_390/3345986085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meqtl_highImpact_scored\u001b[0m  \u001b[0;34m=\u001b[0m  \u001b[0meqtl_highImpact_snps_scored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meqtl_highImpact_indels_scored\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eqtl_highImpact_snps_scored' is not defined"
     ]
    }
   ],
   "source": [
    "eqtl_highImpact_scored  =  eqtl_highImpact_snps_scored.union(eqtl_highImpact_indels_scored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f330c48-d9f3-4ce0-ada6-41ec4812913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NonRef.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4a936-2735-4f8f-a9ee-2a0e3890af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['chromosome', 'start', 'end', 'reference', 'alternate', 'unique_variant_id','qual', \n",
    "     'INFO_DP', 'splitFromMultiAllelic', 'genotypes', 'symbol', 'rsID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448ebc9-dde1-4fc7-a553-4d980814ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_scored = results_gt20.union(eqtl_highImpact_scored)\n",
    "\n",
    "df_NonRef = df_NonRef.select(df_NonRef.columns+[lit('').alias(\"symbol\"),lit('').alias(\"rsID\"),lit('').alias(\"cadd_score\")])\n",
    "\n",
    "#df = df_scored.union(df_NonRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6e685-e0f6-499b-bae8-9ea6c404f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_join  \n",
    "bed = whole_genome_bed\n",
    "\n",
    "bs_name = df.withColumn('bs_id',df.genotypes.getItem(0).getItem('0')).select('bs_id').take(1)[0][0]\n",
    "df = df.withColumn('calls', df.genotypes.getItem(0).getItem('6'))\n",
    "df = df.withColumn('calls_str',concat(df.calls.getItem(0), lit(\":\"), df.calls.getItem(1) ))\n",
    "df = df.withColumn('AdditiveGenotype',when(df.calls_str.contains('-')  ,-9)\\\n",
    "                      .otherwise(df.calls.getItem(0) + df.calls.getItem(1)))\n",
    "\n",
    "# Create Participant ID column (should just be one participant per file)\n",
    "df = df.withColumn('participant_id', df.genotypes.getItem(0).getItem('0'))\n",
    "df = df.withColumn('INFO_DP',df.genotypes.getItem(0).getItem('10'))\n",
    "df = df.withColumn('qual',df.genotypes.getItem(0).getItem('1'))\n",
    "df = df.withColumn('PL',df.genotypes.getItem(0).getItem('9'))\n",
    "\n",
    "select_cols = ['chromosome','start','end','participant_id','unique_variant_id','reference','alternate','calls','AdditiveGenotype','splitFromMultiAllelic','PL',  'qual','INFO_DP']\n",
    "print('df columns are already filtered correctly? --',str(set(df.columns) == select_cols))\n",
    "df = df.select(select_cols)  # need this?\n",
    "\n",
    "df = df.withColumn('AdditiveGenotype',when((df.INFO_DP < 15) | (df.qual < 25) ,-9)\\\n",
    "                      .otherwise(df.AdditiveGenotype))\n",
    "\n",
    "\n",
    "df = df.where(~ ((df.splitFromMultiAllelic == 'true') & (df.alternate == '<NON_REF>') ))\n",
    "df = df.sort(['chromosome','start'])\n",
    "df = df.drop(*(\"splitFromMultiAllelic\")).dropDuplicates(['unique_variant_id','AdditiveGenotype'])\n",
    "\n",
    "df = df.withColumn('PL_00',df.PL.getItem(0))\n",
    "df = df.withColumn('PL_01',df.PL.getItem(1))\n",
    "df = df.withColumn('PL_11',df.PL.getItem(2))\n",
    "df = df.select(['unique_variant_id','chromosome','start','end','reference','alternate','PL','PL_00',\n",
    "                               'PL_01','PL_11','AdditiveGenotype'])\n",
    "\n",
    "df = df.withColumn('AdditiveGenotype',when((df.PL_00 == 0) & (df.PL_01 == 0) &\\\n",
    "                                           (col('AdditiveGenotype') == 0 ),-9).otherwise(df.AdditiveGenotype))\n",
    "\n",
    "df = df.withColumn('AdditiveGenotype',when(((df.PL_00 == 0) & (df.PL_01 == 0) &\\\n",
    "                     (df.PL_11 == 0)) & (col('AdditiveGenotype') == 0 ) ,-9).otherwise(df.AdditiveGenotype))\n",
    "\n",
    "df = df.drop(*(\"PL\",\"PL_00\",\"PL_01\",\"PL_11\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52067d41-adbf-4783-9626-cc778688bf49",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expand BED intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "671fc52a-ccc2-4abd-932f-12c9a286ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start_bed', 'end_bed', 'chromosome_bed', 'expanded_int']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bed = whole_genome_bed\n",
    "bed.sample(1/20000).count()\n",
    "bed = bed.rdd.map(lambda x: (x['start_bed'],x['end_bed'],\n",
    "                                    x['chromosome_bed'],list(range(x['start_bed'],x['end_bed']))))\n",
    "\n",
    "#bed.select(col('_1').alias('start_bed'),col('_2').alias('end_bed'),\n",
    "#                            col('_3').alias('chromosome_bed'),col('_4').alias('expanded_int'))\n",
    "\n",
    "bed = bed.toDF(['start_bed','end_bed','chromosome_bed','expanded_int'])\n",
    "print(bed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3af39e-083a-492a-ba25-3c982f437c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------+--------------------+\n",
      "|start_bed| end_bed|chromosome_bed|        expanded_int|\n",
      "+---------+--------+--------------+--------------------+\n",
      "| 38297023|38323217|            17|[38297023, 382970...|\n",
      "+---------+--------+--------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bed.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a667809e-1ea2-4554-bd8a-a8f447ed9e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[97] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed.rdd.map(lambda x: (x['start_bed'],x['end_bed'],\n",
    "                                    x['chromosome_bed'],list(range(x['start_bed'],x['end_bed']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2b820-77fc-49b8-9bc0-2a65aa75ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(x['start_bed'],x['end_bed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8be6a7b-a565-4a61-b9b5-d367241f3dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = bed.rdd.map(lambda x: (concat(x['chromosome_bed'],lit(\":\"))))\n",
    "\n",
    "#b.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32ce77d5-b3e3-408e-b6a2-56a563366499",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/28 15:05:06 ERROR Executor: Exception in task 0.0 in stage 33.0 (TID 172)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1560, in takeUpToNumLeft\n",
      "    yield next(iterator)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_1503/534504526.py\", line 1, in <lambda>\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 98, in lit\n",
      "    return col if isinstance(col, Column) else _invoke_function(\"lit\", col)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 57, in _invoke_function\n",
      "    jf = _get_get_jvm_function(name, SparkContext._active_spark_context)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 49, in _get_get_jvm_function\n",
      "    return getattr(sc._jvm.functions, name)\n",
      "AttributeError: 'NoneType' object has no attribute '_jvm'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "22/06/28 15:05:06 WARN TaskSetManager: Lost task 0.0 in stage 33.0 (TID 172) (i-0636f8f2a70597535 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1560, in takeUpToNumLeft\n",
      "    yield next(iterator)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_1503/534504526.py\", line 1, in <lambda>\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 98, in lit\n",
      "    return col if isinstance(col, Column) else _invoke_function(\"lit\", col)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 57, in _invoke_function\n",
      "    jf = _get_get_jvm_function(name, SparkContext._active_spark_context)\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 49, in _get_get_jvm_function\n",
      "    return getattr(sc._jvm.functions, name)\n",
      "AttributeError: 'NoneType' object has no attribute '_jvm'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "22/06/28 15:05:06 ERROR TaskSetManager: Task 0 in stage 33.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 33.0 failed 1 times, most recent failure: Lost task 0.0 in stage 33.0 (TID 172) (i-0636f8f2a70597535 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1560, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_1503/534504526.py\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 98, in lit\n    return col if isinstance(col, Column) else _invoke_function(\"lit\", col)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 57, in _invoke_function\n    jf = _get_get_jvm_function(name, SparkContext._active_spark_context)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 49, in _get_get_jvm_function\n    return getattr(sc._jvm.functions, name)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1560, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_1503/534504526.py\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 98, in lit\n    return col if isinstance(col, Column) else _invoke_function(\"lit\", col)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 57, in _invoke_function\n    jf = _get_get_jvm_function(name, SparkContext._active_spark_context)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 49, in _get_get_jvm_function\n    return getattr(sc._jvm.functions, name)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1503/2093515749.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mtoDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    673\u001b[0m             return super(SparkSession, self).createDataFrame(\n\u001b[1;32m    674\u001b[0m                 data, schema, samplingRatio, verifySchema)\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \"\"\"\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \"\"\"\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             raise ValueError(\"The first row in RDD is empty, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \"\"\"\n\u001b[0;32m-> 1586\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 33.0 failed 1 times, most recent failure: Lost task 0.0 in stage 33.0 (TID 172) (i-0636f8f2a70597535 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1560, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_1503/534504526.py\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 98, in lit\n    return col if isinstance(col, Column) else _invoke_function(\"lit\", col)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 57, in _invoke_function\n    jf = _get_get_jvm_function(name, SparkContext._active_spark_context)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 49, in _get_get_jvm_function\n    return getattr(sc._jvm.functions, name)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 259, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1560, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_1503/534504526.py\", line 1, in <lambda>\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 98, in lit\n    return col if isinstance(col, Column) else _invoke_function(\"lit\", col)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 57, in _invoke_function\n    jf = _get_get_jvm_function(name, SparkContext._active_spark_context)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/functions.py\", line 49, in _get_get_jvm_function\n    return getattr(sc._jvm.functions, name)\nAttributeError: 'NoneType' object has no attribute '_jvm'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:315)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:166)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2236)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "b.toDF()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2884990e-a6e2-4236-baa5-ccbd0c89da75",
   "metadata": {},
   "source": [
    "### Merge in cadd scored eqtl/highImpact variants to patients gvcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4660134-ab47-47f7-a936-2f83475ccd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------+-----------+------------+-----------------+----------+\n",
      "| start|reference|alternate|       rsID|      symbol|unique_variant_id|chromosome|\n",
      "+------+---------+---------+-----------+------------+-----------------+----------+\n",
      "|668472|        C|        A|rs372034137|      ZNF595|     4:668472:C:A|         4|\n",
      "|173022|        A|        T|  rs7678326|      ZNF718|     4:173022:A:T|         4|\n",
      "|207285|        T|        C| rs28716466|CH17-262A2.1|     4:207285:T:C|         4|\n",
      "+------+---------+---------+-----------+------------+-----------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtl_highImpact = spark.read.parquet('/sbgenomics/project-files/eqtls_and_high_impact.parquet')\n",
    "eqtl_highImpact.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff6b34ea-a528-4104-9e6f-fb5654870f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------+-----------+------+-----------------+----------+----------+\n",
      "| start|reference|alternate|       rsID|symbol|unique_variant_id|chromosome|cadd_score|\n",
      "+------+---------+---------+-----------+------+-----------------+----------+----------+\n",
      "|668472|        C|        A|rs372034137|ZNF595|     4:668472:C:A|         4|      10.0|\n",
      "|173022|        A|        T|  rs7678326|ZNF718|     4:173022:A:T|         4|      10.0|\n",
      "+------+---------+---------+-----------+------+-----------------+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtl_highImpact_scored = eqtl_highImpact.withColumn('cadd_score',lit(10.0))\n",
    "eqtl_highImpact_scored.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07dedd20-5757-40fa-baf4-3da1e959271e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+-----------+-------------+-----------------+----------+----------+\n",
      "|    start|reference|alternate|       rsID|       symbol|unique_variant_id|chromosome|cadd_score|\n",
      "+---------+---------+---------+-----------+-------------+-----------------+----------+----------+\n",
      "| 26781023|        A|        G| rs11731852|      TBC1D19|   4:26781023:A:G|         4|      10.0|\n",
      "| 61928437|        G|        T| rs79496289|   ADGRL3-AS1|   4:61928437:G:T|         4|      10.0|\n",
      "| 48341676|        G|        A|  rs1876834|      SLC10A4|   4:48341676:G:A|         4|      10.0|\n",
      "| 52426039|        C|        A|rs144987677|    USP46-AS1|   4:52426039:C:A|         4|      10.0|\n",
      "| 57263902|        G|        A|  rs1860625|         PPAT|   4:57263902:G:A|         4|      10.0|\n",
      "|163736259|        T|        G| rs62333003|        NPY5R|  4:163736259:T:G|         4|      10.0|\n",
      "|  5056678|        G|        T|  rs7695179|          EVC|    4:5056678:G:T|         4|      10.0|\n",
      "| 54332038|        G|        A| rs11729535|RP11-231C18.2|   4:54332038:G:A|         4|      10.0|\n",
      "| 76273650|        G|        A| rs12503821|        STBD1|   4:76273650:G:A|         4|      10.0|\n",
      "|158700845|        G|        A|  rs9918016|           U3|  4:158700845:G:A|         4|      10.0|\n",
      "|183678417|        G|       GT|rs201443677| RP11-739P1.3| 4:183678417:G:GT|         4|      10.0|\n",
      "|185701395|        C|        T| rs12648681|      ANKRD37|  4:185701395:C:T|         4|      10.0|\n",
      "|151126213|        C|        T| rs28593016|        RPS3A|  4:151126213:C:T|         4|      10.0|\n",
      "|184208768|        A|        G|  rs4443321|     CDKN2AIP|  4:184208768:A:G|         4|      10.0|\n",
      "|  5826248|       CA|        C| rs11318332|          EVC|   4:5826248:CA:C|         4|      10.0|\n",
      "| 57087112|        C|        A|  rs4242004|       IGFBP7|   4:57087112:C:A|         4|      10.0|\n",
      "| 67624379|        T|        G|  rs4860854|         UBA6|   4:67624379:T:G|         4|      10.0|\n",
      "| 70715987|        A|        G| rs75930396|          DCK|   4:70715987:A:G|         4|      10.0|\n",
      "| 74046133|        C|        T|   rs191613|          ALB|   4:74046133:C:T|         4|      10.0|\n",
      "|163491230|        T|        C|  rs7689631|        TMA16|  4:163491230:T:C|         4|      10.0|\n",
      "+---------+---------+---------+-----------+-------------+-----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eqtl_highImpact_scored.sample(1/100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5c942da-554e-469f-8e4f-22e5fb614040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eqtl_highImpact_scored.write.parquet('eqtl_highImpact_scored.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c3b7b16-d49f-4ed8-9921-c85e24f8ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv eqtl_highImpact_scored.parquet/ /sbgenomics/output-files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b05785-bce6-4a46-9913-d3b1bed27919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2310965\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+----------+\n",
      "|   start|     end|reference|alternate|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|unique_variant_id|chromosome|\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+----------+\n",
      "|35837713|35837714|        A|        G|271.77|     31|                 true|[{BS_0302Y3N5, 99...|  14:35837713:A:G|        14|\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.read.parquet('/sbgenomics/project-files/df_bed_leftsemi.parquet')\n",
    "df_noNonRef = df_join.where(~ (col('alternate') == '<NON_REF>')) # only need to get CADD scores for this df\n",
    "\n",
    "print(df_noNonRef.count())\n",
    "df_noNonRef.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15077456-24aa-4d83-9929-9fd07b6be64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = df_noNonRef.join(eqtl_highImpact_scored.select('unique_variant_id','rsID','symbol','cadd_score')\n",
    "                     ,['unique_variant_id'],'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617ad9b0-0135-46aa-b6af-6288b505677f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+---------+---------+---------+-------+-------+---------------------+--------------------+----------+------------+------------+----------+\n",
      "|unique_variant_id|    start|      end|reference|alternate|   qual|INFO_DP|splitFromMultiAllelic|           genotypes|chromosome|        rsID|      symbol|cadd_score|\n",
      "+-----------------+---------+---------+---------+---------+-------+-------+---------------------+--------------------+----------+------------+------------+----------+\n",
      "|  16:69571709:G:T| 69571709| 69571710|        G|        T| 559.77|     28|                 true|[{BS_0302Y3N5, 99...|        16|   rs4783724|RP11-123C5.5|      10.0|\n",
      "|   3:37364761:A:T| 37364761| 37364762|        A|        T| 427.77|     29|                 true|[{BS_0302Y3N5, 99...|         3|   rs7611351|     LRRFIP2|      10.0|\n",
      "|  2:233137352:T:A|233137352|233137353|        T|        A| 852.77|     32|                 true|[{BS_0302Y3N5, 99...|         2| rs182277546|     SCARNA6|      10.0|\n",
      "|  2:233137352:T:A|233137352|233137353|        T|        A| 852.77|     32|                 true|[{BS_0302Y3N5, 99...|         2| rs182277546|        NGEF|      10.0|\n",
      "|  11:45648526:C:A| 45648526| 45648527|        C|        A| 502.77|     26|                 true|[{BS_0302Y3N5, 99...|        11|   rs4756010|     SLC35C1|      10.0|\n",
      "|  22:36814425:G:A| 36814425| 36814426|        G|        A|1428.77|     34|                 true|[{BS_0302Y3N5, 99...|        22|   rs2067069|    NDUFA9P1|      10.0|\n",
      "|   2:61387209:A:C| 61387209| 61387210|        A|        C|1670.77|     39|                 true|[{BS_0302Y3N5, 99...|         2|   rs2442032|  AC010733.5|      10.0|\n",
      "|   X:38342626:A:G| 38342626| 38342627|        A|        G| 562.77|     17|                 true|[{BS_0302Y3N5, 51...|         X|  rs12845367|        RPGR|      10.0|\n",
      "|  19:37063631:C:T| 37063631| 37063632|        C|        T| 367.77|     30|                 true|[{BS_0302Y3N5, 99...|        19| rs188172404|      ZNF829|      10.0|\n",
      "|  19:37063631:C:T| 37063631| 37063632|        C|        T| 367.77|     30|                 true|[{BS_0302Y3N5, 99...|        19| rs188172404|CTD-2293H3.1|      10.0|\n",
      "| 18:77097913:T:TA| 77097913| 77097914|        T|       TA| 986.73|     36|                 true|[{BS_0302Y3N5, 99...|        18| rs140236492| RP11-4B16.3|      10.0|\n",
      "|   6:32587540:C:T| 32587540| 32587541|        C|        T| 390.89|     21|                 true|[{BS_0302Y3N5, 2,...|         6|rs1165303522|        TNXB|      10.0|\n",
      "| 16:70753010:G:GT| 70753010| 70753011|        G|       GT| 490.73|     40|                 true|[{BS_0302Y3N5, 99...|        16| rs879333435|        WWP2|      10.0|\n",
      "| 16:70753010:G:GT| 70753010| 70753011|        G|       GT| 490.73|     40|                 true|[{BS_0302Y3N5, 99...|        16| rs879333435|         FUK|      10.0|\n",
      "|  4:25318796:T:TG| 25318796| 25318797|        T|       TG| 348.73|     36|                 true|[{BS_0302Y3N5, 99...|         4| rs148356862|      ZCCHC4|      10.0|\n",
      "|  4:25318796:T:TG| 25318796| 25318797|        T|       TG| 348.73|     36|                 true|[{BS_0302Y3N5, 99...|         4| rs148356862|      ZCCHC4|      10.0|\n",
      "|  4:153694085:G:A|153694085|153694086|        G|        A| 339.77|     32|                 true|[{BS_0302Y3N5, 99...|         4|  rs10222800|         FGA|      10.0|\n",
      "|  2:223978047:T:G|223978047|223978048|        T|        G|1282.73|     44|                 true|[{BS_0302Y3N5, 99...|         2| rs114211301|        SCG2|      10.0|\n",
      "|  17:81149334:C:T| 81149334| 81149335|        C|        T| 508.77|     27|                 true|[{BS_0302Y3N5, 99...|        17|   rs4969406|        AATK|      10.0|\n",
      "|   9:33009726:C:T| 33009726| 33009727|        C|        T| 569.77|     32|                 true|[{BS_0302Y3N5, 99...|         9|  rs10971307|      DNAJA1|      10.0|\n",
      "+-----------------+---------+---------+---------+---------+-------+-------+---------------------+--------------------+----------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8a438a4-f2f8-4686-aa2b-9d73c558a66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cebc050-d96f-4e69-bb32-f47fc33eeb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.where(col('cadd_score').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfb495-f80c-4c47-9fb5-e8a47e7176d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1bb92d4-35a4-40a0-a86a-334a7197e9ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Post processing: Combine all eqtl/high Impact SNPs into single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6ddbea-dea8-41bd-977e-0e9fa3fbe4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/sbgenomics/project-files/cadd_chrom_files',\n",
       " '/sbgenomics/project-files/cadd_chrom_files_gt20',\n",
       " '/sbgenomics/project-files/cadd_chrom_files_parquet',\n",
       " '/sbgenomics/project-files/cadd_chrom_gt20_files',\n",
       " '/sbgenomics/project-files/cadd_gnomad_all.parquet',\n",
       " '/sbgenomics/project-files/cadd_gnomad_gt_20.tsv',\n",
       " '/sbgenomics/project-files/cadd_gt20_gnomAD_all_chroms.parquet',\n",
       " '/sbgenomics/project-files/cadd_gt20_snps.parquet']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('/sbgenomics/project-files/cadd*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91664662-7653-4e4a-8d22-0144adcc45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('bs_*_eqtl_highImpct_snps.csv')\n",
    "assert len(all_files) == 711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f449b-d1a1-4b33-974f-625e732eb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "\n",
    "# may need to use dask here, the data from each person is going to be bigger bc of +1 to start position\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "# join this frame w/ the main cadd snp file chrom by chrom -- possibly parallelize \n",
    "# then combine with the other variants using an app. this way we only need to load the large cadd snp file one time.\n",
    "\n",
    "# get gene names from VWB consequences table\n",
    "\n",
    "# then search for all of these variants (the unique set) in each gvcf/parquet file,\n",
    "# we need to know if its a 0,1,2 or -9. how to do this quickly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59a998-63b6-419d-a47a-92c22d7ff582",
   "metadata": {},
   "outputs": [],
   "source": [
    "vargenemap = spark.read.parquet('/sbgenomics/project-files/tcsq_variant_gene_mappings.parquet/')\n",
    "print(vargenemap.count())\n",
    "vargenemap.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73bb666-7a7a-4c19-956e-790dce8fdd3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Find the Additive genotype (0,1,2,-9) of all variants in each gVCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2cfe0-57e4-47ff-b37f-32e134b14824",
   "metadata": {},
   "source": [
    "### why duplicates in scored df?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f918a-7acb-412e-adf5-dc434b99e88c",
   "metadata": {},
   "source": [
    "### do all df preprossing/adding columns first, before cadd filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188a546-fa94-48c2-aac6-5ceecabd366c",
   "metadata": {},
   "source": [
    "### did incorrect 'end' column get merged onto the df? just for highImpact/eQTL? --no we matched on ref/alt as well so end should always be correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4915d6c7-6c96-4f64-8c6a-33c851dc2069",
   "metadata": {},
   "source": [
    "## cant just check location for genotype, what if its a different allele?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1ee1b-e745-4a72-be5b-f634ae4e9ced",
   "metadata": {},
   "source": [
    "## other way to get frequencies of variants is from VWB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90204df8-ce3e-4705-b527-1b622fcd1942",
   "metadata": {},
   "source": [
    "### make sure I'm not finding high Impact SNP scores twice (for the ones that are above 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dc625-5d9a-4141-9360-a60e696fac04",
   "metadata": {},
   "source": [
    "### Precompute highImpact/eQTL cadd scores and then just merge them into each patients df on the unique_variant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b11c430-d624-4f7b-9f9e-ab1dfca185b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------+-----------------+------+-------+---------------------+--------------------+------+---------+----------+------------+----------+-------------------+\n",
      "|   start|     end|reference|alternate|unique_variant_id|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|symbol|     rsID|cadd_score|eqtl_boolean|chromosome|    unique_location|\n",
      "+--------+--------+---------+---------+-----------------+------+-------+---------------------+--------------------+------+---------+----------+------------+----------+-------------------+\n",
      "|66246975|66246975|        A|        G|   1:66246975:A:G|578.77|     39|                 true|[{BS_0302Y3N5, 99...|  LEPR|rs7523912|     1.164|           1|         1|1:66246975:66246975|\n",
      "+--------+--------+---------+---------+-----------------+------+-------+---------------------+--------------------+------+---------+----------+------------+----------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load in scored variants\n",
    "variants = spark.read.parquet('/sbgenomics/project-files/BS_0302Y3N5_chd_scored_variants.parquet')\n",
    "\n",
    "variants = variants.withColumn('unique_location',concat(col(\"chromosome\"),\n",
    "                                lit(\":\"),col(\"start\"),lit(\":\"),col(\"end\")))\n",
    "variants = variants.drop_duplicates()\n",
    "print(variants.count())\n",
    "variants.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ba368d-ba78-47d9-865b-b408742b726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177482"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants.where(col('splitFromMultiAllelic') == 'true').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a49c240-c13e-4341-b2b0-a776922f98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants_noneqtl = variants.where(col('eqtl_boolean') == 0)\n",
    "variants_noneqtl.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4677ac12-3678-4e98-aa1b-90b726a0a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================================> (41 + 1) / 42]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.1 ms, sys: 32.7 ms, total: 99.8 ms\n",
      "Wall time: 5min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "166977"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#df = spark.read.parquet('/sbgenomics/project-files/BS_0302Y3N5.parquet/')\n",
    "\n",
    "# DIFFERENT gVCF than the one we got the variants from\n",
    "df = spark.read.parquet('/sbgenomics/project-files/BS_03BQSV43.parquet/')\n",
    "\n",
    "\n",
    "\n",
    "df = df.select(col('contigName').alias('chromosome'),'start','end',col('referenceAllele').alias('reference'),\n",
    "         col('alternateAlleles').alias('alternate'),'qual','INFO_DP', 'splitFromMultiAllelic','genotypes')\n",
    "\n",
    "\n",
    "df = df.withColumn('chromosome',F.regexp_replace(col(\"chromosome\"), \"[chr,]\", \"\") )\n",
    "\n",
    "#df = df.where(col('chromosome') == '15')\n",
    "\n",
    "df = df.withColumn('alternate',F.explode('alternate'))\n",
    "df = df.withColumn(\"start\", df[\"start\"]+1)\n",
    "\n",
    "#df = gvcf.where( (col('alternate') == '<NON_REF>'))\n",
    "df = df.where(~ (col('alternate') == '<NON_REF>'))\n",
    "\n",
    "df = df.withColumn('unique_variant_id',concat(col(\"chromosome\"),\n",
    "                                lit(\":\"),col(\"start\"),lit(':'),col('reference'),lit(':'),col('alternate')))\n",
    "\n",
    "df = df.withColumn('unique_location',concat(col(\"chromosome\"),\n",
    "                                lit(\":\"),col(\"start\"),lit(\":\"),col(\"end\")))\n",
    "'''\n",
    "#bs_name = df.withColumn('bs_id',df.genotypes.getItem(0).getItem('0')).select('bs_id').take(1)[0][0]\n",
    "df = df.withColumn('calls', df.genotypes.getItem(0).getItem('6'))\n",
    "df = df.withColumn('calls_str',concat(df.calls.getItem(0), lit(\":\"), df.calls.getItem(1) ))\n",
    "df = df.withColumn('AdditiveGenotype',when(df.calls_str.contains('-')  ,-9)\\\n",
    "                      .otherwise(df.calls.getItem(0) + df.calls.getItem(1)))\n",
    "\n",
    "\n",
    "# Create Participant ID column (should just be one participant per file)\n",
    "df = df.withColumn('participant_id', df.genotypes.getItem(0).getItem('0'))\n",
    "df = df.withColumn('INFO_DP',df.genotypes.getItem(0).getItem('10'))\n",
    "df = df.withColumn('qual',df.genotypes.getItem(0).getItem('1'))\n",
    "\n",
    "df = df.withColumn('AdditiveGenotype',when((df.INFO_DP < 15) | (df.qual < 25) ,-9)\\\n",
    "                      .otherwise(df.AdditiveGenotype))\n",
    "\n",
    "df = df.where(~ ((df.splitFromMultiAllelic == 'true') & (df.alternate == '<NON_REF>') ))\n",
    "#df = df.sort(['chromosome','start'])\n",
    "df = df.drop(*(\"splitFromMultiAllelic\")).dropDuplicates(['unique_variant_id','AdditiveGenotype'])\n",
    "\n",
    "#######\n",
    "df = df.withColumn('PL',df.genotypes.getItem(0).getItem('9'))\n",
    "df = df.withColumn('PL_00',df.PL.getItem(0))\n",
    "df = df.withColumn('PL_01',df.PL.getItem(1))\n",
    "df = df.withColumn('PL_11',df.PL.getItem(2))\n",
    "#df = df.select(['unique_variant_id','unique_location','chromosome','start','end','reference','alternate','PL','PL_00',\n",
    "#                               'PL_01','PL_11','AdditiveGenotype'])\n",
    "df = df.withColumn('AdditiveGenotype',when((df.PL_00 == 0) & (df.PL_01 == 0) &\\\n",
    "                                           (col('AdditiveGenotype') == 0 ),-9).otherwise(df.AdditiveGenotype))\n",
    "df = df.withColumn('AdditiveGenotype',when(((df.PL_00 == 0) & (df.PL_01 == 0) &\\\n",
    "                     (df.PL_11 == 0)) & (col('AdditiveGenotype') == 0 ) ,-9).otherwise(df.AdditiveGenotype))\n",
    "\n",
    "df = df.drop(*(\"PL\",\"PL_00\",\"PL_01\",\"PL_11\"))\n",
    "'''\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea65d718-3c05-4630-9e69-d098754ca12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[chromosome: string, start: bigint, end: bigint, reference: string, alternate: string, qual: double, INFO_DP: int, splitFromMultiAllelic: boolean, genotypes: array<struct<0:string,1:int,2:array<int>,3:array<int>,4:string,5:boolean,6:array<int>,7:int,8:string,9:array<int>,10:int>>, unique_variant_id: string, unique_location: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f682fba2-b610-47f1-8dfb-b217681d90aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+--------------------+\n",
      "|chromosome|   start|     end|reference|alternate|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|unique_variant_id|     unique_location|\n",
      "+----------+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+--------------------+\n",
      "|        15|28611511|28611511|        T|       TC|610.73|     39|                 true|[{BS_03BQSV43, 99...| 15:28611511:T:TC|15:28611511:28611511|\n",
      "|        15|28611518|28611518|        C|        T|   0.0|     41|                 true|[{BS_03BQSV43, 99...|  15:28611518:C:T|15:28611518:28611518|\n",
      "|        15|28611525|28611525|        T|        C|643.77|     39|                 true|[{BS_03BQSV43, 99...|  15:28611525:T:C|15:28611525:28611525|\n",
      "+----------+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 108 ms, sys: 35.4 ms, total: 144 ms\n",
      "Wall time: 14min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#df = df.drop('INFO_DP','splitFromMultiAllelic','qual','genotypes','unique_location','reference','alternate')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b787faf5-e783-48bf-89b4-f7ff4c4281ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = variants_noneqtl.rdd.mapPartitions(lambda it: [sum(1 for _ in it)])\n",
    "variants_noneqtl = variants_noneqtl.repartitionByRange(4, \"chromosome\", \"start\")\n",
    "#variants.rdd.mapPartitionsWithIndex(lambda x,it: [(x,sum(1 for _ in it))]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c46db7a5-a000-4cb3-874a-59e2ee11dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:===========================================>          (161 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "CPU times: user 53.4 ms, sys: 26.4 ms, total: 79.8 ms\n",
      "Wall time: 4min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_chrom = df.where(col('chromosome') == '15')\n",
    "print(df_chrom.count())\n",
    "chrom_locs = variants_noneqtl[variants_noneqtl['chromosome'] == '15']#['location']\n",
    "print(chrom_locs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19846a14-feed-4c80-8add-23fff0d809d4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+-----------------+-------------+-----------+------------------+----------+\n",
      "|    start|      end|reference|alternate|unique_variant_id|       symbol|       rsID|        cadd_score|chromosome|\n",
      "+---------+---------+---------+---------+-----------------+-------------+-----------+------------------+----------+\n",
      "| 66246975| 66246975|        A|        G|   1:66246975:A:G|         LEPR|  rs7523912|             1.164|         1|\n",
      "| 61817832| 61817832|        A|        C|   1:61817832:A:C|RP11-430G17.3|  rs6700692|             4.789|         1|\n",
      "| 77283842| 77283842|        C|        T|   1:77283842:C:T|          AK5|  rs1779173|             4.533|         1|\n",
      "|150989647|150989647|        C|        T|  1:150989647:C:T|       ZNF687|  rs4590677|             0.211|         1|\n",
      "|154975851|154975851|        G|        T|  1:154975851:G:T|        DCST2| rs12087657|6.1610000000000005|         1|\n",
      "| 76102821| 76102821|        T|        G|   1:76102821:T:G|RP11-510C10.2| rs10873866|             3.549|         1|\n",
      "|160140536|160140536|        T|        G|  1:160140536:T:G|         CD48|  rs2753263|             0.395|         1|\n",
      "|114107525|114107525|        G|        C|  1:114107525:G:C|        PHTF1| rs12140761|1.3259999999999998|         1|\n",
      "| 70030908| 70030908|        A|        G|   1:70030908:A:G|RP11-181B18.1|   rs725795|              7.75|         1|\n",
      "|112540817|112540817|        C|        T|  1:112540817:C:T|       CAPZA1| rs10745330|7.2570000000000014|         1|\n",
      "|109225161|109225161|        C|        A|  1:109225161:C:A|       CELSR2|  rs7539716|             0.225|         1|\n",
      "|151096070|151096070|        A|        G|  1:151096070:A:G|       SEMA6C|  rs4970941|             9.372|         1|\n",
      "|162226709|162226709|        G|        A|  1:162226709:G:A|     C1orf226|  rs4233387|             0.068|         1|\n",
      "|119130721|119130721|        G|        A|  1:119130721:G:A|         HAO2| rs10923755|             14.73|         1|\n",
      "| 89257661| 89257661|        G|        A|   1:89257661:G:A|     PKN2-AS1|  rs2209307|             0.959|         1|\n",
      "| 94256104| 94256104|        T|        C|   1:94256104:T:C|         CNN3| rs12750249|             11.25|         1|\n",
      "|150574389|150574389|        A|        T|  1:150574389:A:T|      GOLPH3L|  rs6587756|             6.915|         1|\n",
      "| 63589207| 63589207|        C|        A|   1:63589207:C:A|         PGM1|rs143305589|             0.317|         1|\n",
      "|152037054|152037054|        T|        C|  1:152037054:T:C|      S100A11|  rs3811422|             4.347|         1|\n",
      "| 65348550| 65348550|        T|        G|   1:65348550:T:G|       DNAJC6| rs12755229|               1.9|         1|\n",
      "+---------+---------+---------+---------+-----------------+-------------+-----------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "variants.drop('INFO_DP','splitFromMultiAllelic','qual','genotypes','eqtl_boolean','unique_location').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0993c74-4901-466a-a6f0-7ab52f243511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_locs_trim = chrom_locs.select(col('chromosome').alias('var_chrom'),col('start').alias('var_start'),\n",
    "                                                col('unique_variant_id').alias('var_unique_variant_id'),\n",
    "                                                col('end').alias('var_end'))\n",
    "chrom_locs_trim.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "909f700a-3bb8-428c-b9f6-b565977d2b13",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:===================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+-----------------+---------+---------+---------------------+--------+\n",
      "|chromosome|   start|     end|unique_variant_id|var_chrom|var_start|var_unique_variant_id| var_end|\n",
      "+----------+--------+--------+-----------------+---------+---------+---------------------+--------+\n",
      "|        15|34528068|34528068|  15:34528067:G:A|       15| 34528068|      15:34528068:G:A|34528068|\n",
      "|        15|37019897|37019897|  15:37019896:A:G|       15| 37019897|      15:37019897:A:G|37019897|\n",
      "|        15|39589977|39589977|  15:39589976:A:G|       15| 39589977|      15:39589977:A:G|39589977|\n",
      "|        15|39973598|39973598|  15:39973597:A:G|       15| 39973598|      15:39973598:A:G|39973598|\n",
      "|        15|40459356|40459356|  15:40459355:C:A|       15| 40459356|      15:40459356:C:A|40459356|\n",
      "|        15|40813728|40813728|  15:40813727:T:G|       15| 40813728|      15:40813728:T:G|40813728|\n",
      "|        15|41573327|41573327|  15:41573326:G:T|       15| 41573327|      15:41573327:G:T|41573327|\n",
      "|        15|41857308|41857308|  15:41857307:G:C|       15| 41857308|      15:41857308:G:C|41857308|\n",
      "|        15|42878595|42878595|  15:42878594:A:G|       15| 42878595|      15:42878595:A:G|42878595|\n",
      "|        15|43369604|43369604|  15:43369603:T:C|       15| 43369604|      15:43369604:T:C|43369604|\n",
      "|        15|43525206|43525206|  15:43525205:G:A|       15| 43525206|      15:43525206:G:A|43525206|\n",
      "|        15|43660050|43660050|  15:43660049:G:A|       15| 43660050|      15:43660050:G:A|43660050|\n",
      "|        15|43660056|43660056|  15:43660055:G:A|       15| 43660056|      15:43660056:G:A|43660056|\n",
      "|        15|44736512|44736512|  15:44736511:T:C|       15| 44736512|      15:44736512:T:C|44736512|\n",
      "|        15|45099877|45099877|  15:45099876:G:A|       15| 45099877|      15:45099877:G:A|45099877|\n",
      "|        15|45167366|45167366|  15:45167365:G:A|       15| 45167366|      15:45167366:G:A|45167366|\n",
      "|        15|45184814|45184814|  15:45184813:A:G|       15| 45184814|      15:45184814:A:G|45184814|\n",
      "|        15|47349702|47349702|  15:47349701:A:G|       15| 47349702|      15:47349702:A:G|47349702|\n",
      "|        15|53615751|53615751|  15:53615750:G:A|       15| 53615751|      15:53615751:G:A|53615751|\n",
      "|        15|59668062|59668062|  15:59668061:T:C|       15| 59668062|      15:59668062:T:C|59668062|\n",
      "+----------+--------+--------+-----------------+---------+---------+---------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 84.1 ms, sys: 14.3 ms, total: 98.4 ms\n",
      "Wall time: 6min 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_join = df_chrom.join(chrom_locs_trim, \n",
    "                  (df_chrom['chromosome'] == chrom_locs_trim['var_chrom']) &\\\n",
    "                  (df_chrom['start'] <= chrom_locs_trim['var_start']) &\\\n",
    "                  (df_chrom['end'] >= chrom_locs_trim['var_start']),'inner' )\n",
    "\n",
    "df_join.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5232a414-2d37-4733-9c1c-9da292c4008d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc40e76-109b-4c2d-ad05-53ded039e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "+----------+--------+--------+---------+---------+-----------------+--------------------+---------+---------+---------------------+--------+\n",
    "|chromosome|   start|     end|reference|alternate|unique_variant_id|     unique_location|var_chrom|var_start|var_unique_variant_id| var_end|\n",
    "+----------+--------+--------+---------+---------+-----------------+--------------------+---------+---------+---------------------+--------+\n",
    "|        15|34528067|34528068|        G|        A|  15:34528067:G:A|15:34528067:34528068|       15| 34528068|      15:34528068:G:A|34528068|\n",
    "|        15|37019896|37019897|        A|        G|  15:37019896:A:G|15:37019896:37019897|       15| 37019897|      15:37019897:A:G|37019897|\n",
    "|        15|39589976|39589977|        A|        G|  15:39589976:A:G|15:39589976:39589977|       15| 39589977|      15:39589977:A:G|39589977|\n",
    "|        15|39973597|39973598|        A|        G|  15:39973597:A:G|15:39973597:39973598|       15| 39973598|      15:39973598:A:G|39973598|\n",
    "|        15|40459355|40459356|        C|        A|  15:40459355:C:A|15:40459355:40459356|       15| 40459356|      15:40459356:C:A|40459356|\n",
    "|        15|40813727|40813728|        T|        G|  15:40813727:T:G|15:40813727:40813728|       15| 40813728|      15:40813728:T:G|40813728|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551665d-9219-4b4c-8373-c953a326d857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6884a046-0a4a-44c6-87a9-d8c8912982c2",
   "metadata": {},
   "source": [
    "### Join on unique location to find set of variants we have direct genotypes for \n",
    "##### Can filter out NON_REF rows when searching initially ,----- actually cannot do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d8e261-348b-42c3-926d-8411e38b9f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:================================================>     (178 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "CPU times: user 9.89 ms, sys: 0 ns, total: 9.89 ms\n",
      "Wall time: 1.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first get set of variants/locs from the input\n",
    "uniq_locs = [row['unique_location'] for row in variants_noneqtl.where(col('chromosome') == '15')\\\n",
    "                                                                .select('unique_location').collect()]\n",
    "print(len(uniq_locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7449250d-fede-49a5-b45a-cf1047c4b641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=====================================================>(198 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CPU times: user 147 ms, sys: 47.6 ms, total: 194 ms\n",
      "Wall time: 18min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vars_found = variants_noneqtl.where(col('chromosome') == '15')\\\n",
    "                .join(df.where(col('chromosome') == '15')\\\n",
    "                      .select('unique_location','unique_variant_id','AdditiveGenotype')\\\n",
    "                      ,['unique_location'],'inner')\n",
    "print(vars_found.count())\n",
    "#vars_found.drop('splitFromMultiAllelic','genotypes').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8690a5b-e16a-453e-8c90-b96cde9831bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==========>                                              (8 + 1) / 42]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127/1838286448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chromosome'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'21'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \"\"\"\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(df.where(col('chromosome') == '15').count())\n",
    "print(variants_noneqtl.where(col('chromosome') == '15').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb81e18-d88c-4c00-b3d2-05cd128ac050",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['15:22851829:22851830']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set(a.select('unique_location').collect())\n",
    "\n",
    "# what if someone has a different variation, still just 1 or 2?\n",
    "uniq_locs = [row['unique_location'] for row in vars_found.select('unique_location').collect()]\n",
    "uniq_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ce5bc-5756-40c0-a35f-f16e01212adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all eqtl variants first and find the unique set of locations/variants for the entire cohort.\n",
    "# Then, merge this set w/ a gvcf to see which vars we already have a genotype match for. set these off to theside.\n",
    "# Then do anti merge do get list of vars that we dont have direct genotype matches for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a7a7808-d309-46cc-bcf8-c9166ce2ba3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniq_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bebef052-3860-4645-af2e-53939b966bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the list of locations we dont have direct genotype hits for\n",
    "vars_missing = variants_noneqtl.where(col('chromosome') == '15').where(~col('unique_location').isin(uniq_locs))\n",
    "vars_missing.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04498df5-32fa-4884-bf5a-81175003072e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "missing_uniq_locs = [row['unique_location'] for row in vars_missing.select('unique_location').collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4d3f162-82ef-4b31-a8dd-5baa1265caae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15:60764664:60764664'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m  =missing_uniq_locs[0]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7010a1-6a2c-4d33-a4b9-473808ea3a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15', '60764664', '60764664']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f243c67-eff9-45da-8b12-4bddf54473cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:=========>                                               (7 + 1) / 42]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_130/3405281767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70a46884-825a-4cb2-9f80-270128083da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.DataFrame([i.split(':') for i in missing_uniq_locs],columns=['chrom','start','end'])\n",
    "df_missing['location'] = missing_uniq_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd75891a-5469-4ea6-84d9-cbe22c6fbf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.8 ms, sys: 0 ns, total: 3.8 ms\n",
      "Wall time: 17.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_chrom = df.where(col('chromosome') == '15')\n",
    "chrom_locs = df_missing[df_missing['chrom'] == '15']['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab02258c-c750-4f4f-a2e3-6e010871d958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>60764664</td>\n",
       "      <td>60764664</td>\n",
       "      <td>15:60764664:60764664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>32665918</td>\n",
       "      <td>32665918</td>\n",
       "      <td>15:32665918:32665918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>83970598</td>\n",
       "      <td>83970598</td>\n",
       "      <td>15:83970598:83970598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>39973598</td>\n",
       "      <td>39973598</td>\n",
       "      <td>15:39973598:39973598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>66296165</td>\n",
       "      <td>66296165</td>\n",
       "      <td>15:66296165:66296165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chrom     start       end              location\n",
       "0    15  60764664  60764664  15:60764664:60764664\n",
       "1    15  32665918  32665918  15:32665918:32665918\n",
       "2    15  83970598  83970598  15:83970598:83970598\n",
       "3    15  39973598  39973598  15:39973598:39973598\n",
       "4    15  66296165  66296165  15:66296165:66296165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e9658-5f3e-4b9c-bbc6-d85b48497818",
   "metadata": {},
   "source": [
    "# Examine results of getting genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6194cf26-91fc-4891-8b43-99a87a106fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11927164"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.parquet('/sbgenomics/project-files/BS_0302Y3N5.parquet/')\n",
    "\n",
    "df = df.select(col('contigName').alias('chromosome'),'start','end',col('referenceAllele').alias('reference'),\n",
    "                        col('alternateAlleles').alias('alternate'),'qual','INFO_DP', 'splitFromMultiAllelic',\n",
    "                                'genotypes').withColumn('alternate',F.explode('alternate')).withColumn('chromosome',F.regexp_replace(col(\"chromosome\"), \"[chr,]\", \"\") )                    \n",
    "df = df.withColumn(\"start\", df[\"start\"]+1) #df_count = df.count() \n",
    "\n",
    "df = df.withColumn('unique_variant_id',concat(col(\"chromosome\"), lit(\":\"),\n",
    "                    col(\"start\"),lit(':'),col('reference'),lit(':'),col('alternate'))) \n",
    "\n",
    "df = df.where(col('chromosome') == '15')\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca1040d-9ca6-45dd-bb28-374b953637fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where(~ (col('alternate') == '<NON_REF>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf74a5f7-b512-4912-a669-3e97029fc066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "169129"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f586f396-4367-4c53-b063-62274a31d819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[37888, 2062]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = spark.read.parquet('/sbgenomics/project-files/bed_protein_coding_coords_only.parquet')\n",
    "print(b.rdd.getNumPartitions())\n",
    "b.rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2326d4d-c08f-4492-abc8-bf22ca1a39c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[151775, 25707]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = spark.read.parquet('/sbgenomics/project-files/BS_0302Y3N5_chd_scored_variants.parquet')\n",
    "print(e.rdd.getNumPartitions())\n",
    "e.rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec2c0817-6c14-4592-b189-7fcf30d559f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4950]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.where(col('eqtl_boolean') == 0).coalesce(1).rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bfb442d-7a73-4d60-8bca-eb285e6d3f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "d = df.rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).collect()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18844d5e-c186-40b3-9383-28e954bcc44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175854962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87927481"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snps_gt20 = spark.read.parquet('/sbgenomics/project-files/cadd_gt20_snps.parquet')\n",
    "print(snps_gt20.count())\n",
    "snps_gt20_dedup = snps_gt20.dropDuplicates()\n",
    "snps_gt20_dedup.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d6b3b48-da7f-4e0e-8147-f6a277f06a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+----------+-----------------+----------+\n",
      "|    start|reference|alternate|cadd_score|unique_variant_id|chromosome|\n",
      "+---------+---------+---------+----------+-----------------+----------+\n",
      "|112769487|        A|        C|      20.0| 12:112769487:A:C|        12|\n",
      "+---------+---------+---------+----------+-----------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "snps_gt20_dedup.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfbf20b4-0e4a-49a1-9d6a-53cbe51cf545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175854962"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*87927481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e9d4de5-7da3-438f-b12f-f06ff19d1c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "snps_gt20_dedup.repartitionByRange(60, \"chromosome\").write\\\n",
    "      .mode('overwrite')\\\n",
    "      .partitionBy(\"chromosome\")\\\n",
    "      .parquet(\"cadd_gt20_snps_2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c01622ad-f8ae-47cf-8138-a37699eb373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv cadd_gt20_snps_2.parquet/ /sbgenomics/output-files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d4d45a-97b8-453c-9458-0f9b96228264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/20 12:27:08 WARN DataSource: All paths were ignored:\n",
      "  file:/sbgenomics/project-files/_8_BS_0302Y3N5_chd_scored_variants.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177482\n"
     ]
    }
   ],
   "source": [
    "t = spark.read.parquet('/sbgenomics/project-files/_8_BS_0302Y3N5_chd_scored_variants.parquet')\n",
    "print(t.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e487d755-24e8-4581-b182-d64a78ef1387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177482"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e73c76-ee73-44a2-99cd-ca5a6d038b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+-----------------+-------+-------+---------------------+--------------------+------+----+----------+------------+----------+\n",
      "|    start|      end|reference|alternate|unique_variant_id|   qual|INFO_DP|splitFromMultiAllelic|           genotypes|symbol|rsID|cadd_score|eqtl_boolean|chromosome|\n",
      "+---------+---------+---------+---------+-----------------+-------+-------+---------------------+--------------------+------+----+----------+------------+----------+\n",
      "|125889890|125889890|        A|        G| 10:125889890:A:G|1019.77|     70|                 true|[{BS_0302Y3N5, 99...|      |    |      20.7|           0|        10|\n",
      "+---------+---------+---------+---------+-----------------+-------+-------+---------------------+--------------------+------+----+----------+------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bd0fb3-a3e7-48a3-bcf5-e877243e1d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "172660"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.where(col('cadd_score') < 20).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4b8c17-c058-45f7-a6f3-acbf295bca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(list(t.where(col('eqtl_boolean') == 1).select(col('cadd_score')).toPandas()['cadd_score'])).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88562c6-ddcc-46ac-bba3-84ad588b7810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6920\n",
      "+--------+--------+---------+---------+-----------------+------+-------+---------------------+--------------------+------------+-----------+-------------------+------------+----------+\n",
      "|   start|     end|reference|alternate|unique_variant_id|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|      symbol|       rsID|         cadd_score|eqtl_boolean|chromosome|\n",
      "+--------+--------+---------+---------+-----------------+------+-------+---------------------+--------------------+------------+-----------+-------------------+------------+----------+\n",
      "|57780703|57780703|        A|        C|  15:57780703:A:C|   0.0|     38|                 true|[{BS_0302Y3N5, 80...|            |           |               20.1|           0|        15|\n",
      "|78773847|78773847|        A|        G|  15:78773847:A:G|382.77|     28|                 true|[{BS_0302Y3N5, 99...|RP11-285A1.1|rs181072044|0.16699999999999998|           1|        15|\n",
      "+--------+--------+---------+---------+-----------------+------+-------+---------------------+--------------------+------------+-----------+-------------------+------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t15 = t.where((col('unique_variant_id').startswith('15')))# & (col('AdditiveGenotype') == -9))\n",
    "print(t15.count())\n",
    "t15.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a274c9c9-f4d3-4fcb-85ee-9709aa2755bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t15 = t.where(col('chromosome') == '15').select('unique_variant_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f390060-09b9-4929-a404-ccc4b70d566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5760"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t15v = list(t15.select('unique_variant_id').toPandas()['unique_variant_id']) \n",
    "print(len(t15v))\n",
    "len(set(t15v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28e23e4-1d21-477b-9206-b7657bd3be3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "169129"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15 = list(df.select('unique_variant_id').toPandas()['unique_variant_id']) \n",
    "print(len(df15))\n",
    "len(set(df15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5c8852-713a-4609-92d1-a6e781655dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(t15v) - set(df15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fd28b7-b4fc-4bf4-b01a-18018fc5bda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5760"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df15).intersection(set(t15v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d6ce92-1e2b-4208-9a3c-11ba1587bf98",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15:28611511:T:TC',\n",
       " '15:28611518:C:T',\n",
       " '15:28611525:T:C',\n",
       " '15:28612776:T:G',\n",
       " '15:28612777:T:G',\n",
       " '15:28612778:T:G',\n",
       " '15:28613520:T:G',\n",
       " '15:28614975:C:T',\n",
       " '15:28615086:C:T',\n",
       " '15:28615277:G:C',\n",
       " '15:28615339:G:A',\n",
       " '15:28619609:CTTTTTTTT:C',\n",
       " '15:28623163:A:G',\n",
       " '15:28623172:T:G',\n",
       " '15:28623182:A:G',\n",
       " '15:28623537:T:C',\n",
       " '15:28625642:C:CT',\n",
       " '15:28628095:A:G',\n",
       " '15:28628155:T:C',\n",
       " '15:28628192:G:T',\n",
       " '15:28629273:G:C',\n",
       " '15:28634773:T:C',\n",
       " '15:28634779:C:T',\n",
       " '15:28636563:C:T',\n",
       " '15:28637107:G:C',\n",
       " '15:28637113:G:C',\n",
       " '15:28645213:C:T',\n",
       " '15:28646616:T:C',\n",
       " '15:28646917:GTC:G',\n",
       " '15:28646917:G:GTC',\n",
       " '15:28646917:G:GTCTGTC',\n",
       " '15:28646921:C:G',\n",
       " '15:28646935:A:C',\n",
       " '15:28658997:T:C',\n",
       " '15:28659128:G:A',\n",
       " '15:28659526:A:T',\n",
       " '15:28659775:G:A',\n",
       " '15:28659781:G:T',\n",
       " '15:28662903:AT:A',\n",
       " '15:28663630:A:G',\n",
       " '15:28665162:CT:C',\n",
       " '15:28668999:G:A',\n",
       " '15:28669394:CT:C',\n",
       " '15:28669394:C:CT',\n",
       " '15:28669394:C:CTT',\n",
       " '15:28670474:G:C',\n",
       " '15:28671042:C:T',\n",
       " '15:28672671:G:A',\n",
       " '15:28673044:G:A',\n",
       " '15:28673551:A:G',\n",
       " '15:28678090:T:C',\n",
       " '15:28678568:C:T',\n",
       " '15:28678601:C:A',\n",
       " '15:28678782:A:G',\n",
       " '15:28678797:G:T',\n",
       " '15:28678803:CA:C',\n",
       " '15:28678886:GAAATTA:G',\n",
       " '15:28678905:C:T',\n",
       " '15:28678916:A:AGGAG',\n",
       " '15:28678922:G:T',\n",
       " '15:28678950:G:A',\n",
       " '15:28678959:G:A',\n",
       " '15:28678987:A:G',\n",
       " '15:28679022:G:A',\n",
       " '15:28679135:G:T',\n",
       " '15:28679136:C:T',\n",
       " '15:28679174:G:T',\n",
       " '15:28679251:C:T',\n",
       " '15:28679315:A:G',\n",
       " '15:28679515:A:G',\n",
       " '15:28680646:C:T',\n",
       " '15:28681579:CAAATAAATAAATAAAT:C',\n",
       " '15:28681579:CAAAT:C',\n",
       " '15:28682787:A:G',\n",
       " '15:28685777:G:A',\n",
       " '15:28685813:C:A',\n",
       " '15:28685820:G:A',\n",
       " '15:28685839:T:C',\n",
       " '15:28687966:G:T',\n",
       " '15:28689362:AT:A',\n",
       " '15:28692217:A:G',\n",
       " '15:28692223:A:G',\n",
       " '15:28692235:A:T',\n",
       " '15:28692636:A:G',\n",
       " '15:28692655:T:C',\n",
       " '15:28693020:T:TTTA',\n",
       " '15:28693217:G:T',\n",
       " '15:28693285:T:G',\n",
       " '15:28693289:CT:C',\n",
       " '15:28693289:C:CT',\n",
       " '15:28693459:CTT:C',\n",
       " '15:28693481:G:T',\n",
       " '15:28693484:G:A',\n",
       " '15:28693765:GT:G',\n",
       " '15:28693779:G:T',\n",
       " '15:28693896:A:G',\n",
       " '15:28693918:G:A',\n",
       " '15:28693953:T:G',\n",
       " '15:28694384:G:A',\n",
       " '15:28694390:T:A',\n",
       " '15:28694519:G:A',\n",
       " '15:28694527:T:C',\n",
       " '15:28694600:C:T',\n",
       " '15:28694678:G:A',\n",
       " '15:28694735:G:GA',\n",
       " '15:28694913:T:TAA',\n",
       " '15:28695084:C:CTA',\n",
       " '15:28695361:T:A',\n",
       " '15:28695439:C:T',\n",
       " '15:28695444:T:G',\n",
       " '15:28695895:A:G',\n",
       " '15:28696103:A:ATTTT',\n",
       " '15:28696172:A:G',\n",
       " '15:28696758:A:G',\n",
       " '15:28698321:T:C',\n",
       " '15:28703107:C:G',\n",
       " '15:28703148:C:G',\n",
       " '15:28703151:C:T',\n",
       " '15:28703158:C:G',\n",
       " '15:28703164:A:C',\n",
       " '15:28703301:A:AG',\n",
       " '15:28703365:T:C',\n",
       " '15:28703725:A:G',\n",
       " '15:28703986:C:G',\n",
       " '15:28705980:C:T',\n",
       " '15:28705999:T:C',\n",
       " '15:28706146:T:A',\n",
       " '15:28706155:T:G',\n",
       " '15:28709167:C:T',\n",
       " '15:28710299:T:A',\n",
       " '15:28710559:C:T',\n",
       " '15:28716039:T:C',\n",
       " '15:28716040:G:A',\n",
       " '15:28717475:T:TAC',\n",
       " '15:28722935:A:G',\n",
       " '15:28722938:G:A',\n",
       " '15:28725608:A:ATTTTTTTTTTT',\n",
       " '15:28725608:A:ATTTTTTTTTTTT',\n",
       " '15:28725886:C:T',\n",
       " '15:28726475:C:T',\n",
       " '15:28726503:A:T',\n",
       " '15:28730522:C:T',\n",
       " '15:28730710:CAT:C',\n",
       " '15:28730710:C:CAT',\n",
       " '15:28735568:A:G',\n",
       " '15:28736436:C:A',\n",
       " '15:28742820:CAT:C',\n",
       " '15:28742901:TGTACATACATATATGTATATATGCATGTATAC:T',\n",
       " '15:28742933:C:T',\n",
       " '15:28746463:G:C',\n",
       " '15:28748405:G:A',\n",
       " '15:28757020:A:C',\n",
       " '15:28757395:GAA:G',\n",
       " '15:28757592:A:T',\n",
       " '15:28757711:A:C',\n",
       " '15:28757959:A:G',\n",
       " '15:28757983:G:C',\n",
       " '15:28758124:A:G',\n",
       " '15:28760947:C:T',\n",
       " '15:28761351:T:C',\n",
       " '15:28761365:T:C',\n",
       " '15:28761670:C:CTTA',\n",
       " '15:28762935:C:G',\n",
       " '15:28763012:G:C',\n",
       " '15:28763144:C:CTT',\n",
       " '15:28763219:C:T',\n",
       " '15:28763495:GCCCCTCCATGGATCACCGGCA:G',\n",
       " '15:28763705:C:T',\n",
       " '15:28763904:A:AC',\n",
       " '15:28764165:A:G',\n",
       " '15:28765223:G:A',\n",
       " '15:28765943:T:C',\n",
       " '15:28766272:A:G',\n",
       " '15:28766320:C:A',\n",
       " '15:28766418:C:T',\n",
       " '15:28766518:G:T',\n",
       " '15:28767364:T:C',\n",
       " '15:28767598:GT:G',\n",
       " '15:28767656:A:G',\n",
       " '15:28768013:G:A',\n",
       " '15:28768018:G:A',\n",
       " '15:28769032:G:A',\n",
       " '15:28769133:A:G',\n",
       " '15:28769258:C:G',\n",
       " '15:28769419:C:G',\n",
       " '15:28769935:A:G',\n",
       " '15:28772487:G:A',\n",
       " '15:28772887:C:T',\n",
       " '15:28773489:G:A',\n",
       " '15:28774013:G:A',\n",
       " '15:28774114:T:TTTTC',\n",
       " '15:28774138:CT:C',\n",
       " '15:28774139:T:TTTC',\n",
       " '15:28774172:C:T',\n",
       " '15:28774203:G:A',\n",
       " '15:28774819:T:G',\n",
       " '15:28775397:CAGT:C',\n",
       " '15:28775458:T:A',\n",
       " '15:28775479:G:A',\n",
       " '15:28775482:T:A',\n",
       " '15:28775485:C:T',\n",
       " '15:28776096:A:G',\n",
       " '15:28776381:T:C',\n",
       " '15:28776911:A:AT',\n",
       " '15:28777920:A:G',\n",
       " '15:28777938:A:G',\n",
       " '15:28777971:G:T',\n",
       " '15:28778014:G:T',\n",
       " '15:28778416:C:T',\n",
       " '15:28778801:C:T',\n",
       " '15:28778986:GT:G',\n",
       " '15:28780824:TA:T',\n",
       " '15:28780897:C:CT',\n",
       " '15:28780914:G:T',\n",
       " '15:28781071:AT:A',\n",
       " '15:28781678:A:G',\n",
       " '15:28781678:A:T',\n",
       " '15:28782006:C:T',\n",
       " '15:28782115:C:A',\n",
       " '15:28782518:G:A',\n",
       " '15:28782896:A:T',\n",
       " '15:28782904:T:A',\n",
       " '15:28783752:AT:A',\n",
       " '15:28784174:CT:C',\n",
       " '15:28784357:AT:A',\n",
       " '15:28785334:C:A',\n",
       " '15:28785334:C:CAA',\n",
       " '15:28785334:C:CAAA',\n",
       " '15:28787203:C:T',\n",
       " '15:28787435:G:C',\n",
       " '15:28787453:C:T',\n",
       " '15:28788336:A:G',\n",
       " '15:28788763:G:A',\n",
       " '15:28789131:G:C',\n",
       " '15:28789400:G:C',\n",
       " '15:28789574:G:C',\n",
       " '15:28789765:A:AG',\n",
       " '15:28790304:CAAA:C',\n",
       " '15:28790462:G:T',\n",
       " '15:28791533:T:C',\n",
       " '15:28792216:A:AT',\n",
       " '15:28793371:C:T',\n",
       " '15:28794040:C:T',\n",
       " '15:28794152:AT:A',\n",
       " '15:28794598:T:C',\n",
       " '15:28794918:A:G',\n",
       " '15:28795169:T:C',\n",
       " '15:28795243:G:A',\n",
       " '15:28795410:G:C',\n",
       " '15:28795421:G:A',\n",
       " '15:28795571:A:T',\n",
       " '15:28796468:T:C',\n",
       " '15:28796498:G:GAA',\n",
       " '15:28796888:A:G',\n",
       " '15:28796936:A:G',\n",
       " '15:28797109:AT:A',\n",
       " '15:28797370:C:T',\n",
       " '15:28797425:G:T',\n",
       " '15:28797435:C:A',\n",
       " '15:28797936:T:C',\n",
       " '15:28798190:C:T',\n",
       " '15:28798340:C:T',\n",
       " '15:28798365:T:G',\n",
       " '15:28798609:A:C',\n",
       " '15:28798636:A:G',\n",
       " '15:28798707:C:T',\n",
       " '15:28798881:CA:C',\n",
       " '15:28798885:C:T',\n",
       " '15:28799281:G:GTA',\n",
       " '15:28799615:T:C',\n",
       " '15:28799820:A:G',\n",
       " '15:28799886:T:C',\n",
       " '15:28800170:A:C',\n",
       " '15:28801936:G:GTGTATATATAT',\n",
       " '15:28802301:A:T',\n",
       " '15:28803298:T:C',\n",
       " '15:28803987:G:C',\n",
       " '15:28804007:C:A',\n",
       " '15:28804394:C:T',\n",
       " '15:28805052:G:T',\n",
       " '15:28806241:T:C',\n",
       " '15:28806430:G:A',\n",
       " '15:28806708:C:CT',\n",
       " '15:28806721:C:T',\n",
       " '15:28806875:A:T',\n",
       " '15:28808374:C:T',\n",
       " '15:28808633:T:C',\n",
       " '15:28808656:C:A',\n",
       " '15:28809140:T:A',\n",
       " '15:28809441:G:A',\n",
       " '15:28809565:A:G',\n",
       " '15:28809594:A:G',\n",
       " '15:28811721:C:A',\n",
       " '15:28811736:TA:T',\n",
       " '15:28813152:G:A',\n",
       " '15:28813398:T:C',\n",
       " '15:28813714:C:T',\n",
       " '15:28813780:T:C',\n",
       " '15:28815726:A:G',\n",
       " '15:28815730:A:G',\n",
       " '15:28815753:T:C',\n",
       " '15:28815769:G:A',\n",
       " '15:28815793:G:GTT',\n",
       " '15:28815922:G:T',\n",
       " '15:28819638:C:CG',\n",
       " '15:28819869:C:G',\n",
       " '15:28820100:C:A',\n",
       " '15:28820864:A:G',\n",
       " '15:28824613:G:GTA',\n",
       " '15:28833728:C:G',\n",
       " '15:28835165:T:C',\n",
       " '15:28841290:C:A',\n",
       " '15:28841443:G:A',\n",
       " '15:28843359:TCTCCTGATCCCGTAGCTC:T',\n",
       " '15:28844663:G:C',\n",
       " '15:28845123:C:T',\n",
       " '15:28845125:TAC:T',\n",
       " '15:28845164:ACG:A',\n",
       " '15:28846286:T:C',\n",
       " '15:28846612:T:A',\n",
       " '15:28847111:C:T',\n",
       " '15:28847285:C:T',\n",
       " '15:28847300:G:A',\n",
       " '15:28847511:G:A',\n",
       " '15:28849719:C:T',\n",
       " '15:28851426:A:T',\n",
       " '15:28859309:C:CTT',\n",
       " '15:28860596:CAT:C',\n",
       " '15:28861593:TTTCC:T',\n",
       " '15:28865305:CTTT:C',\n",
       " '15:28865305:CTT:C',\n",
       " '15:28865305:CT:C',\n",
       " '15:28871220:C:T',\n",
       " '15:28872426:A:G',\n",
       " '15:28875216:C:A',\n",
       " '15:28875216:C:CA',\n",
       " '15:28876826:C:G',\n",
       " '15:28881843:G:C',\n",
       " '15:28881966:A:AT',\n",
       " '15:28882297:C:A',\n",
       " '15:28882297:C:CA',\n",
       " '15:28882772:T:TA',\n",
       " '15:28883939:G:A',\n",
       " '15:28884947:C:G',\n",
       " '15:28884977:A:G',\n",
       " '15:28885078:A:G',\n",
       " '15:28885987:C:G',\n",
       " '15:28886491:G:T',\n",
       " '15:28886822:T:C',\n",
       " '15:28886962:C:G',\n",
       " '15:28887454:T:C',\n",
       " '15:28887561:A:G',\n",
       " '15:28887737:G:A',\n",
       " '15:28887753:T:C',\n",
       " '15:28887830:T:C',\n",
       " '15:28887858:G:A',\n",
       " '15:28887868:C:T',\n",
       " '15:28887882:T:C',\n",
       " '15:28887887:A:G',\n",
       " '15:28887927:C:T',\n",
       " '15:28888149:T:C',\n",
       " '15:28888334:A:G',\n",
       " '15:28888574:C:T',\n",
       " '15:28888920:T:C',\n",
       " '15:28888993:G:A',\n",
       " '15:28889266:T:C',\n",
       " '15:28889601:C:G',\n",
       " '15:28889698:T:C',\n",
       " '15:28889961:T:C',\n",
       " '15:28890260:G:C',\n",
       " '15:28890482:A:G',\n",
       " '15:28890685:C:T',\n",
       " '15:28891173:T:C',\n",
       " '15:28891179:T:C',\n",
       " '15:28891196:T:G',\n",
       " '15:28891225:A:G',\n",
       " '15:28891475:C:T',\n",
       " '15:28891634:A:G',\n",
       " '15:28891971:A:G',\n",
       " '15:28892073:A:T',\n",
       " '15:28892085:GT:G',\n",
       " '15:28892235:T:C',\n",
       " '15:28892276:T:C',\n",
       " '15:28892326:C:T',\n",
       " '15:28892337:G:A',\n",
       " '15:28893186:T:C',\n",
       " '15:28893668:T:C',\n",
       " '15:28894066:T:C',\n",
       " '15:28894173:A:G',\n",
       " '15:28894380:G:A',\n",
       " '15:28894903:A:G',\n",
       " '15:28895211:C:A',\n",
       " '15:28895502:A:G',\n",
       " '15:28895840:T:C',\n",
       " '15:28895852:A:C',\n",
       " '15:28895927:C:T',\n",
       " '15:28897182:G:GACACAC',\n",
       " '15:28897495:A:G',\n",
       " '15:28897617:C:CAAA',\n",
       " '15:28898284:A:C',\n",
       " '15:28898326:G:T',\n",
       " '15:28898684:G:A',\n",
       " '15:28899884:T:A',\n",
       " '15:28901908:A:ATGTGTGTGTGTGTGTG',\n",
       " '15:28902050:A:C',\n",
       " '15:28902825:T:G',\n",
       " '15:28902841:C:G',\n",
       " '15:28914970:G:A',\n",
       " '15:28915091:A:C',\n",
       " '15:28917005:C:T',\n",
       " '15:28923581:T:G',\n",
       " '15:28928142:T:TA',\n",
       " '15:28951865:GC:G',\n",
       " '15:28952561:A:C',\n",
       " '15:28956614:G:T',\n",
       " '15:28956618:A:G',\n",
       " '15:28956621:C:G',\n",
       " '15:28960148:C:CA',\n",
       " '15:28962703:TG:T',\n",
       " '15:28962856:T:G',\n",
       " '15:28964539:G:T',\n",
       " '15:28966414:C:T',\n",
       " '15:28967154:A:C',\n",
       " '15:28969128:TTTTC:T',\n",
       " '15:28969128:T:TTTTCTTTCTTTCTTTC',\n",
       " '15:28977860:C:T',\n",
       " '15:28983644:G:A',\n",
       " '15:28987772:G:T',\n",
       " '15:28987773:A:T',\n",
       " '15:29013273:C:T',\n",
       " '15:29013273:C:CT',\n",
       " '15:29017157:G:C',\n",
       " '15:29017397:CTTTTTTT:C',\n",
       " '15:29023441:C:T',\n",
       " '15:29023441:C:CT',\n",
       " '15:29025690:GCCTATAAT:G',\n",
       " '15:29025699:C:G',\n",
       " '15:29025969:AAGAAATGGCCC:A',\n",
       " '15:29026759:GA:G',\n",
       " '15:29033964:C:CAA',\n",
       " '15:29036251:AT:A',\n",
       " '15:29036293:T:A',\n",
       " '15:29038665:A:AT',\n",
       " '15:29039098:GGTGT:G',\n",
       " '15:29039995:G:A',\n",
       " '15:29046123:A:G',\n",
       " '15:29047254:G:A',\n",
       " '15:29047296:G:A',\n",
       " '15:29047744:A:G',\n",
       " '15:29050978:C:CA',\n",
       " '15:29051425:C:T',\n",
       " '15:29051589:A:C',\n",
       " '15:29052454:C:CAAAAAAAAAAAAA',\n",
       " '15:29052454:C:CAAAAAAAAAAAAAAA',\n",
       " '15:29053693:T:C',\n",
       " '15:29054816:T:C',\n",
       " '15:29055638:A:T',\n",
       " '15:29055668:AGTGT:A',\n",
       " '15:29055668:AGT:A',\n",
       " '15:29056123:C:T',\n",
       " '15:29056254:A:G',\n",
       " '15:29056610:C:CTCCCTTCCTTCCT',\n",
       " '15:29056636:CCT:C',\n",
       " '15:29058235:G:A',\n",
       " '15:29058723:G:T',\n",
       " '15:29058724:T:TTTTA',\n",
       " '15:29058726:G:T',\n",
       " '15:29058727:GA:G',\n",
       " '15:29058730:G:T',\n",
       " '15:29058732:CAGGTT:C',\n",
       " '15:29058740:G:C',\n",
       " '15:29058742:A:ACC',\n",
       " '15:29058745:A:C',\n",
       " '15:29063318:G:A',\n",
       " '15:29063478:TG:T',\n",
       " '15:29063499:T:G',\n",
       " '15:29064106:C:G',\n",
       " '15:29064308:T:C',\n",
       " '15:29065351:C:T',\n",
       " '15:29066533:G:A',\n",
       " '15:29066625:A:G',\n",
       " '15:29066720:T:G',\n",
       " '15:29066764:G:A',\n",
       " '15:29067468:C:T',\n",
       " '15:29067539:G:A',\n",
       " '15:29067587:T:C',\n",
       " '15:29067689:C:T',\n",
       " '15:29067745:A:C',\n",
       " '15:29068198:G:A',\n",
       " '15:29068922:T:G',\n",
       " '15:29068923:C:T',\n",
       " '15:29069101:A:G',\n",
       " '15:29076018:A:G',\n",
       " '15:29085524:C:A',\n",
       " '15:29087265:A:T',\n",
       " '15:29087284:G:C',\n",
       " '15:29089598:T:C',\n",
       " '15:29090866:A:C',\n",
       " '15:29090964:C:CA',\n",
       " '15:29091135:C:T',\n",
       " '15:29091769:A:G',\n",
       " '15:29091942:G:A',\n",
       " '15:29092147:C:T',\n",
       " '15:29092159:A:G',\n",
       " '15:29092748:T:C',\n",
       " '15:29092946:A:G',\n",
       " '15:29093001:A:G',\n",
       " '15:29093813:A:G',\n",
       " '15:29094390:G:A',\n",
       " '15:29094530:T:C',\n",
       " '15:29094646:T:C',\n",
       " '15:29094900:CTT:C',\n",
       " '15:29094926:T:G',\n",
       " '15:29095385:A:G',\n",
       " '15:29095435:GAA:G',\n",
       " '15:29096084:GT:G',\n",
       " '15:29097980:T:C',\n",
       " '15:29098655:G:A',\n",
       " '15:29098712:C:T',\n",
       " '15:29099307:A:C',\n",
       " '15:29101120:C:CA',\n",
       " '15:29101217:CT:C',\n",
       " '15:29101806:C:T',\n",
       " '15:29102488:T:C',\n",
       " '15:29102759:CA:C',\n",
       " '15:29103175:G:A',\n",
       " '15:29103866:C:T',\n",
       " '15:29105142:C:T',\n",
       " '15:29105874:G:A',\n",
       " '15:29105878:C:T',\n",
       " '15:29106578:C:T',\n",
       " '15:29106945:G:T',\n",
       " '15:29107394:A:G',\n",
       " '15:29107421:T:C',\n",
       " '15:29107588:C:T',\n",
       " '15:29107597:G:T',\n",
       " '15:29107806:T:C',\n",
       " '15:29107922:C:T',\n",
       " '15:29108176:C:T',\n",
       " '15:29108755:A:G',\n",
       " '15:29110924:G:T',\n",
       " '15:29112824:A:G',\n",
       " '15:29113172:C:T',\n",
       " '15:29113320:A:G',\n",
       " '15:29114343:T:C',\n",
       " '15:29114408:A:G',\n",
       " '15:29114494:A:C',\n",
       " '15:29114697:AGT:A',\n",
       " '15:29114703:T:C',\n",
       " '15:29114711:C:CAT',\n",
       " '15:29114771:T:TGA',\n",
       " '15:29114789:AGT:A',\n",
       " '15:29114892:GGT:G',\n",
       " '15:29115305:A:C',\n",
       " '15:29115715:T:C',\n",
       " '15:29116034:G:C',\n",
       " '15:29116354:C:T',\n",
       " '15:29116364:G:A',\n",
       " '15:29116456:C:G',\n",
       " '15:29116484:T:C',\n",
       " '15:29116684:G:C',\n",
       " '15:29117668:G:GTGAT',\n",
       " '15:29117870:G:C',\n",
       " '15:29118350:G:A',\n",
       " '15:29118375:C:T',\n",
       " '15:29118520:C:A',\n",
       " '15:29118802:C:CACTT',\n",
       " '15:29118867:C:T',\n",
       " '15:29119123:G:A',\n",
       " '15:29119844:C:T',\n",
       " '15:29119861:G:A',\n",
       " '15:29119876:G:A',\n",
       " '15:29119959:G:A',\n",
       " '15:29119966:C:T',\n",
       " '15:29120141:C:T',\n",
       " '15:29120426:G:C',\n",
       " '15:29120465:G:A',\n",
       " '15:29120744:T:G',\n",
       " '15:29120748:A:G',\n",
       " '15:29120860:G:A',\n",
       " '15:29120892:T:G',\n",
       " '15:29121174:T:C',\n",
       " '15:29121175:A:G',\n",
       " '15:29121475:C:T',\n",
       " '15:29122034:C:T',\n",
       " '15:29122343:T:C',\n",
       " '15:29123357:G:A',\n",
       " '15:29123495:A:G',\n",
       " '15:29124896:G:C',\n",
       " '15:29125070:T:C',\n",
       " '15:29125459:T:C',\n",
       " '15:29125744:C:T',\n",
       " '15:29125912:T:A',\n",
       " '15:29126128:C:T',\n",
       " '15:29126317:C:T',\n",
       " '15:29126370:A:G',\n",
       " '15:29126371:T:C',\n",
       " '15:29126542:G:T',\n",
       " '15:29127692:C:G',\n",
       " '15:29128178:C:T',\n",
       " '15:29128530:A:G',\n",
       " '15:29129040:C:T',\n",
       " '15:29129142:C:A',\n",
       " '15:29129676:T:C',\n",
       " '15:29129843:A:G',\n",
       " '15:29129985:C:G',\n",
       " '15:29130292:A:G',\n",
       " '15:29130479:T:G',\n",
       " '15:29130554:G:A',\n",
       " '15:29130561:A:C',\n",
       " '15:29131288:A:G',\n",
       " '15:29131472:A:G',\n",
       " '15:29131630:T:C',\n",
       " '15:29131788:C:T',\n",
       " '15:29131935:G:GGCATCTGACCTAATCCTACCCTAACCCA',\n",
       " '15:29132552:A:G',\n",
       " '15:29132633:C:T',\n",
       " '15:29132699:G:A',\n",
       " '15:29132799:C:T',\n",
       " '15:29132812:T:C',\n",
       " '15:29133519:G:C',\n",
       " '15:29133542:C:T',\n",
       " '15:29133733:G:A',\n",
       " '15:29136081:G:A',\n",
       " '15:29136353:C:G',\n",
       " '15:29136664:GT:G',\n",
       " '15:29136704:A:G',\n",
       " '15:29136814:G:C',\n",
       " '15:29136861:C:A',\n",
       " '15:29136885:G:A',\n",
       " '15:29136956:A:T',\n",
       " '15:29137749:C:T',\n",
       " '15:29138702:CGTGT:C',\n",
       " '15:29139132:T:G',\n",
       " '15:29139618:G:A',\n",
       " '15:29139979:T:C',\n",
       " '15:29141826:C:T',\n",
       " '15:29145622:C:CA',\n",
       " '15:29145622:C:CAA',\n",
       " '15:29146274:G:A',\n",
       " '15:29149038:G:T',\n",
       " '15:29150001:A:G',\n",
       " '15:29150171:T:A',\n",
       " '15:29150322:C:A',\n",
       " '15:29150588:A:T',\n",
       " '15:29151133:T:G',\n",
       " '15:29151271:T:G',\n",
       " '15:29151927:GC:G',\n",
       " '15:29153145:CT:C',\n",
       " '15:29154473:T:C',\n",
       " '15:29155057:T:C',\n",
       " '15:29155065:A:G',\n",
       " '15:29155079:G:A',\n",
       " '15:29155095:A:G',\n",
       " '15:29155099:G:C',\n",
       " '15:29155126:CA:C',\n",
       " '15:29155143:G:A',\n",
       " '15:29155289:GA:G',\n",
       " '15:29155289:G:A',\n",
       " '15:29157526:A:G',\n",
       " '15:29157731:CT:C',\n",
       " '15:29157878:C:G',\n",
       " '15:29158073:T:G',\n",
       " '15:29158141:C:A',\n",
       " '15:29158405:CTT:C',\n",
       " '15:29158405:CT:C',\n",
       " '15:29158408:T:C',\n",
       " '15:29158425:A:G',\n",
       " '15:29158499:G:A',\n",
       " '15:29158508:G:C',\n",
       " '15:29158724:A:T',\n",
       " '15:29158769:G:C',\n",
       " '15:29158843:T:C',\n",
       " '15:29158876:G:C',\n",
       " '15:29158895:A:C',\n",
       " '15:29159023:C:G',\n",
       " '15:29159061:G:C',\n",
       " '15:29159410:T:C',\n",
       " '15:29159426:G:A',\n",
       " '15:29159471:C:G',\n",
       " '15:29159700:CAG:C',\n",
       " '15:29159975:C:T',\n",
       " '15:29160176:G:A',\n",
       " '15:29160797:C:T',\n",
       " '15:29161302:T:C',\n",
       " '15:29161898:A:T',\n",
       " '15:29162431:A:G',\n",
       " '15:29162466:T:A',\n",
       " '15:29162702:A:C',\n",
       " '15:29162705:T:C',\n",
       " '15:29163487:A:C',\n",
       " '15:29163488:G:A',\n",
       " '15:29163523:C:T',\n",
       " '15:29163599:C:T',\n",
       " '15:29164201:A:G',\n",
       " '15:29164650:T:C',\n",
       " '15:29166831:A:T',\n",
       " '15:29167193:T:A',\n",
       " '15:29167836:G:T',\n",
       " '15:29167957:G:T',\n",
       " '15:29168153:A:G',\n",
       " '15:29168190:C:T',\n",
       " '15:29168394:A:C',\n",
       " '15:29169267:A:C',\n",
       " '15:29169330:G:A',\n",
       " '15:29170239:T:C',\n",
       " '15:29170273:A:C',\n",
       " '15:29170307:CAA:C',\n",
       " '15:29170307:CA:C',\n",
       " '15:29170307:C:CAA',\n",
       " '15:29170631:C:A',\n",
       " '15:29173944:C:A',\n",
       " '15:29174613:T:C',\n",
       " '15:29174707:C:A',\n",
       " '15:29174710:C:A',\n",
       " '15:29175269:G:A',\n",
       " '15:29175402:C:T',\n",
       " '15:29176295:T:C',\n",
       " '15:29177899:C:A',\n",
       " '15:29177904:C:G',\n",
       " '15:29199507:T:C',\n",
       " '15:29207455:CG:C',\n",
       " '15:29208095:C:T',\n",
       " '15:29208130:T:G',\n",
       " '15:29209202:T:A',\n",
       " '15:29209202:T:TA',\n",
       " '15:29210753:T:C',\n",
       " '15:29212233:G:A',\n",
       " '15:29213485:G:C',\n",
       " '15:29214033:GAAAC:G',\n",
       " '15:29214690:T:TAA',\n",
       " '15:29215577:A:AAT',\n",
       " '15:29216377:T:C',\n",
       " '15:29216451:G:A',\n",
       " '15:29217245:G:C',\n",
       " '15:29217853:G:A',\n",
       " '15:29218670:C:T',\n",
       " '15:29219112:GA:G',\n",
       " '15:29219427:G:C',\n",
       " '15:29219610:CATAAATATATATATATATATATATATATATATATAT:C',\n",
       " '15:29219614:A:AAT',\n",
       " '15:29219857:C:A',\n",
       " '15:29220493:C:G',\n",
       " '15:29222109:G:A',\n",
       " '15:29222693:T:C',\n",
       " '15:29223454:C:T',\n",
       " '15:29223489:G:A',\n",
       " '15:29224028:A:C',\n",
       " '15:29224113:C:T',\n",
       " '15:29224145:G:C',\n",
       " '15:29224204:A:G',\n",
       " '15:29224243:C:T',\n",
       " '15:29224282:C:T',\n",
       " '15:29224312:T:C',\n",
       " '15:29224431:G:T',\n",
       " '15:29224528:A:G',\n",
       " '15:29224784:T:C',\n",
       " '15:29224889:A:G',\n",
       " '15:29224925:G:T',\n",
       " '15:29224993:A:G',\n",
       " '15:29225115:T:C',\n",
       " '15:29225166:A:G',\n",
       " '15:29225297:T:C',\n",
       " '15:29225416:A:G',\n",
       " '15:29226685:C:T',\n",
       " '15:29226740:C:T',\n",
       " '15:29226960:G:C',\n",
       " '15:29227609:A:G',\n",
       " '15:29227982:GA:G',\n",
       " '15:29228059:T:C',\n",
       " '15:29228095:G:A',\n",
       " '15:29228148:G:A',\n",
       " '15:29228318:CAAACAA:C',\n",
       " '15:29228964:T:C',\n",
       " '15:29228987:G:T',\n",
       " '15:29229009:A:C',\n",
       " '15:29229118:A:T',\n",
       " '15:29229202:A:G',\n",
       " '15:29229204:T:TAGTC',\n",
       " '15:29229369:A:T',\n",
       " '15:29229655:T:C',\n",
       " '15:29229920:G:C',\n",
       " '15:29229963:T:TA',\n",
       " '15:29231271:C:T',\n",
       " '15:29231788:T:C',\n",
       " '15:29231885:C:CTTTTTTT',\n",
       " '15:29231885:C:CTTTTTTTT',\n",
       " '15:29231890:C:T',\n",
       " '15:29231894:C:T',\n",
       " '15:29231925:C:G',\n",
       " '15:29232097:T:G',\n",
       " '15:29232259:A:C',\n",
       " '15:29232655:C:G',\n",
       " '15:29232664:A:ATTGT',\n",
       " '15:29232733:T:G',\n",
       " '15:29233387:G:A',\n",
       " '15:29233651:T:C',\n",
       " '15:29234075:C:T',\n",
       " '15:29234205:G:T',\n",
       " '15:29234717:T:A',\n",
       " '15:29235008:G:C',\n",
       " '15:29235962:CA:C',\n",
       " '15:29235985:A:AC',\n",
       " '15:29235994:A:G',\n",
       " '15:29235998:C:G',\n",
       " '15:29236025:C:T',\n",
       " '15:29236662:A:C',\n",
       " '15:29236724:T:G',\n",
       " '15:29236814:A:G',\n",
       " '15:29236866:T:C',\n",
       " '15:29236875:T:G',\n",
       " '15:29237684:C:A',\n",
       " '15:29237706:C:G',\n",
       " '15:29238041:T:G',\n",
       " '15:29238077:T:C',\n",
       " '15:29238279:G:A',\n",
       " '15:29238769:A:G',\n",
       " '15:29239129:A:G',\n",
       " '15:29240251:A:C',\n",
       " '15:29240277:T:C',\n",
       " '15:29240278:C:T',\n",
       " '15:29240593:A:G',\n",
       " '15:29241174:C:T',\n",
       " '15:29241435:C:CA',\n",
       " '15:29242329:A:G',\n",
       " '15:29242476:C:T',\n",
       " '15:29243969:T:C',\n",
       " '15:29244082:C:A',\n",
       " '15:29244249:A:T',\n",
       " '15:29244741:A:T',\n",
       " '15:29244982:G:T',\n",
       " '15:29246392:CA:C',\n",
       " '15:29246875:C:CA',\n",
       " '15:29246973:G:GCACA',\n",
       " '15:29246973:G:GCACACA',\n",
       " '15:29247453:C:G',\n",
       " '15:29247738:T:TA',\n",
       " '15:29248059:C:T',\n",
       " '15:29248213:C:T',\n",
       " '15:29248907:C:T',\n",
       " '15:29249949:C:T',\n",
       " '15:29250328:C:G',\n",
       " '15:29250751:T:C',\n",
       " '15:29250773:A:G',\n",
       " '15:29250908:C:T',\n",
       " '15:29250988:C:T',\n",
       " '15:29251225:A:G',\n",
       " '15:29251471:C:T',\n",
       " '15:29251744:C:CTT',\n",
       " '15:29252032:A:G',\n",
       " '15:29252319:A:C',\n",
       " '15:29252452:T:C',\n",
       " '15:29252924:C:T',\n",
       " '15:29253452:C:CT',\n",
       " '15:29253632:G:A',\n",
       " '15:29254161:C:CA',\n",
       " '15:29254161:C:CAAA',\n",
       " '15:29254794:T:C',\n",
       " '15:29255106:T:C',\n",
       " '15:29255818:G:A',\n",
       " '15:29255932:C:T',\n",
       " '15:29256000:CAA:C',\n",
       " '15:29256043:T:C',\n",
       " '15:29256279:C:T',\n",
       " '15:29257014:G:T',\n",
       " '15:29257031:G:A',\n",
       " '15:29257043:ATTAT:A',\n",
       " '15:29257361:C:T',\n",
       " '15:29258212:CAAA:C',\n",
       " '15:29258212:CA:C',\n",
       " '15:29258230:A:AG',\n",
       " '15:29258230:A:AAAG',\n",
       " '15:29258230:A:AAAAG',\n",
       " '15:29258311:A:G',\n",
       " '15:29258497:G:GT',\n",
       " '15:29258615:T:C',\n",
       " '15:29258941:C:T',\n",
       " '15:29259170:G:A',\n",
       " '15:29259260:A:G',\n",
       " '15:29259428:A:G',\n",
       " '15:29259480:C:T',\n",
       " '15:29259935:C:T',\n",
       " '15:29260352:T:C',\n",
       " '15:29260751:C:CAT',\n",
       " '15:29261725:G:T',\n",
       " '15:29261921:T:TA',\n",
       " '15:29262080:G:A',\n",
       " '15:29262095:A:AG',\n",
       " '15:29262191:C:T',\n",
       " '15:29262192:C:T',\n",
       " '15:29262535:T:G',\n",
       " '15:29262547:C:G',\n",
       " '15:29262813:A:G',\n",
       " '15:29263309:A:G',\n",
       " '15:29263533:A:G',\n",
       " '15:29263925:G:A',\n",
       " '15:29264123:A:ACAGCCTGG',\n",
       " '15:29264154:C:CAAAAAAAAAAAAAAAAA',\n",
       " '15:29264158:A:AAAAAAAAAAAAAAG',\n",
       " '15:29264219:T:TG',\n",
       " '15:29265637:C:G',\n",
       " '15:29266333:CA:C',\n",
       " '15:29266336:A:T',\n",
       " '15:29267232:T:G',\n",
       " '15:29267396:A:G',\n",
       " '15:29268463:C:T',\n",
       " '15:29268495:G:T',\n",
       " '15:29271541:A:G',\n",
       " '15:29272272:C:T',\n",
       " '15:29272431:G:A',\n",
       " '15:29272589:A:G',\n",
       " '15:29273918:C:T',\n",
       " '15:29278117:A:C',\n",
       " '15:29278123:A:C',\n",
       " '15:29278128:A:C',\n",
       " '15:29278364:T:G',\n",
       " '15:29279222:C:T',\n",
       " '15:29279595:C:T',\n",
       " '15:29280660:G:A',\n",
       " '15:29281413:A:G',\n",
       " '15:29281495:C:T',\n",
       " '15:29281576:C:T',\n",
       " '15:29281774:T:G',\n",
       " '15:29281826:G:A',\n",
       " '15:29282047:T:A',\n",
       " '15:29282235:G:A',\n",
       " '15:29282349:G:A',\n",
       " '15:29282757:G:T',\n",
       " '15:29283632:C:G',\n",
       " '15:29283868:A:G',\n",
       " '15:29284249:A:G',\n",
       " '15:29284499:G:A',\n",
       " '15:29284556:CAAAA:C',\n",
       " '15:29284595:A:G',\n",
       " '15:29285242:A:G',\n",
       " '15:29287207:C:T',\n",
       " '15:29287383:C:CA',\n",
       " '15:29287383:C:CAA',\n",
       " '15:29287398:GAA:G',\n",
       " '15:29287398:GA:G',\n",
       " '15:29287398:G:A',\n",
       " '15:29287399:A:AG',\n",
       " '15:29287400:A:G',\n",
       " '15:29287820:A:G',\n",
       " '15:29287944:C:T',\n",
       " '15:29288334:C:G',\n",
       " '15:29289002:A:C',\n",
       " '15:29290443:C:T',\n",
       " '15:29290629:G:A',\n",
       " '15:29290761:C:T',\n",
       " '15:29290859:T:C',\n",
       " '15:29291676:T:C',\n",
       " '15:29291990:T:C',\n",
       " '15:29292537:C:T',\n",
       " '15:29293044:T:C',\n",
       " '15:29293437:T:C',\n",
       " '15:29294047:A:G',\n",
       " '15:29296596:T:A',\n",
       " '15:29300298:AGATG:A',\n",
       " '15:29300398:A:AATGG',\n",
       " '15:29300404:T:G',\n",
       " '15:29301772:C:T',\n",
       " '15:29305277:C:T',\n",
       " '15:29306664:A:AT',\n",
       " '15:29306664:A:ATTTTT',\n",
       " '15:29322019:AAAGG:A',\n",
       " '15:29322022:G:T',\n",
       " '15:29322023:G:T',\n",
       " '15:29322024:A:T',\n",
       " '15:29322025:A:ATT',\n",
       " '15:29322025:A:ATTTTTT',\n",
       " '15:29322029:GAA:G',\n",
       " '15:29322035:G:C',\n",
       " '15:29322037:T:G',\n",
       " '15:29322038:CA:C',\n",
       " '15:29322041:A:AC',\n",
       " '15:29322042:A:C',\n",
       " '15:29322045:T:C',\n",
       " '15:29322046:C:G',\n",
       " '15:29322258:C:T',\n",
       " '15:29323372:T:C',\n",
       " '15:29324106:AT:A',\n",
       " '15:29324925:C:T',\n",
       " '15:29324954:G:C',\n",
       " '15:29327390:T:C',\n",
       " '15:29333078:C:T',\n",
       " '15:29333513:C:T',\n",
       " '15:29333735:A:G',\n",
       " '15:29333740:C:A',\n",
       " '15:29334245:G:C',\n",
       " '15:29334421:GT:G',\n",
       " '15:29334506:G:A',\n",
       " '15:29334580:TTGAC:T',\n",
       " '15:29334590:G:A',\n",
       " '15:29335019:T:C',\n",
       " '15:29335158:C:T',\n",
       " '15:29335926:C:G',\n",
       " '15:29336031:G:A',\n",
       " '15:29336141:C:CAA',\n",
       " '15:29336141:C:CAAA',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e9f0c9f-81c9-4110-96e7-d1a7bdc4f320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 6920})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([len(i.split(':')) for i in t15v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdfcb0af-3158-4e90-9ee6-faa03ca59ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:====================================================>   (16 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+--------------------+\n",
      "|chromosome|   start|     end|reference|alternate|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|unique_variant_id|     unique_location|\n",
      "+----------+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+--------------------+\n",
      "|        15|28611511|28611511|        T|       TC|610.73|     39|                 true|[{BS_03BQSV43, 99...| 15:28611511:T:TC|15:28611511:28611511|\n",
      "+----------+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90105f5-1973-4660-96f4-fdbea848817f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08ff7fd4-03e9-4b43-b7e9-b06cda19c0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(t15v).issubset(set(df15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47636766-cab9-497b-acd9-f22737e9d0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14b95a3c-286a-4657-b494-cd0cc5afc741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+---------+---------+----+-------+---------------------+---------+-----------------+---------------+\n",
      "|chromosome|start|end|reference|alternate|qual|INFO_DP|splitFromMultiAllelic|genotypes|unique_variant_id|unique_location|\n",
      "+----------+-----+---+---------+---------+----+-------+---------------------+---------+-----------------+---------------+\n",
      "+----------+-----+---+---------+---------+----+-------+---------------------+---------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col('unique_variant_id') == '15:100603213:A:T' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c59694-79da-49cc-8647-f929a6cb8f27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   unique_variant_id|\n",
      "+--------------------+\n",
      "|    15:28611511:T:TC|\n",
      "|     15:28611518:C:T|\n",
      "|     15:28611525:T:C|\n",
      "|     15:28612776:T:G|\n",
      "|     15:28612777:T:G|\n",
      "|     15:28612778:T:G|\n",
      "|     15:28613520:T:G|\n",
      "|     15:28614975:C:T|\n",
      "|     15:28615086:C:T|\n",
      "|     15:28615277:G:C|\n",
      "|     15:28615339:G:A|\n",
      "|15:28619609:CTTTT...|\n",
      "|     15:28623163:A:G|\n",
      "|     15:28623172:T:G|\n",
      "|     15:28623182:A:G|\n",
      "|     15:28623537:T:C|\n",
      "|    15:28625642:C:CT|\n",
      "|     15:28628095:A:G|\n",
      "|     15:28628155:T:C|\n",
      "|     15:28628192:G:T|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('unique_variant_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b5d955-0ffe-41e1-b31f-c11ea3a60470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+---------+---------------------+---------+---------+--------+----------+\n",
      "|   start|     end|reference|alternate|splitFromMultiAllelic|var_chrom|var_start| var_end|chromosome|\n",
      "+--------+--------+---------+---------+---------------------+---------+---------+--------+----------+\n",
      "|30922706|30922706|        G|        T|                 true|        6| 30922706|30922706|         6|\n",
      "|30922706|30922706|        G|<NON_REF>|                 true|        6| 30922706|30922706|         6|\n",
      "|30925350|30925350|        G|        A|                 true|        6| 30925350|30925350|         6|\n",
      "|30925350|30925350|        G|<NON_REF>|                 true|        6| 30925350|30925350|         6|\n",
      "|31138114|31138114|        A|        G|                 true|        6| 31138114|31138114|         6|\n",
      "|31138114|31138114|        A|<NON_REF>|                 true|        6| 31138114|31138114|         6|\n",
      "|31144707|31144707|        C|        T|                 true|        6| 31144707|31144707|         6|\n",
      "|31144707|31144707|        C|<NON_REF>|                 true|        6| 31144707|31144707|         6|\n",
      "|31144960|31144960|        C|        A|                 true|        6| 31144960|31144960|         6|\n",
      "|31144960|31144960|        C|<NON_REF>|                 true|        6| 31144960|31144960|         6|\n",
      "+--------+--------+---------+---------+---------------------+---------+---------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.drop('qual','INFO_DP','var_unique_variant_id','genotypes',\n",
    "       'unique_variant_id','unique_location').show(10) # 'reference','alternate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac7875-0c1d-411b-8570-a4e03d4c561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "startsWith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8615717-d9cf-4b8b-a143-7d7e1946ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t.where(col('splitFromMultiAllelic') == 'true').count()\n",
    "#t.where(col('start') == col('end')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5567cb42-6017-46c4-ac32-42b2f4bdf412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 ms, sys: 3.87 ms, total: 26.6 ms\n",
      "Wall time: 560 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = t\n",
    "df = df.withColumn('calls', df.genotypes.getItem(0).getItem('6'))\n",
    "df = df.withColumn('calls_str',concat(df.calls.getItem(0), lit(\":\"), df.calls.getItem(1) ))\n",
    "df = df.withColumn('AdditiveGenotype',when(df.calls_str.contains('-')  ,-9)\\\n",
    "                      .otherwise(df.calls.getItem(0) + df.calls.getItem(1)))\n",
    "\n",
    "# Create Participant ID column (should just be one participant per file)\n",
    "df = df.withColumn('participant_id', df.genotypes.getItem(0).getItem('0'))\n",
    "df = df.withColumn('INFO_DP',df.genotypes.getItem(0).getItem('10'))\n",
    "df = df.withColumn('qual',df.genotypes.getItem(0).getItem('1'))\n",
    "df = df.withColumn('PL',df.genotypes.getItem(0).getItem('9'))\n",
    "\n",
    "select_cols = ['chromosome','start','end','participant_id','unique_variant_id','unique_location','reference','alternate','calls','AdditiveGenotype','splitFromMultiAllelic','PL',  'qual','INFO_DP']\n",
    "\n",
    "#print('df columns are already filtered correctly? --',str(set(df.columns) == select_cols))\n",
    "#print(df.columns); time.sleep(10)  #df = df.select(select_cols)  # need this?\n",
    "\n",
    "df = df.withColumn('AdditiveGenotype',when((df.INFO_DP < 15) | (df.qual < 25) ,-9)\\\n",
    "                      .otherwise(df.AdditiveGenotype))\n",
    "df = df.where(~ ((df.splitFromMultiAllelic == 'true') & (df.alternate == '<NON_REF>') ))\n",
    "\n",
    "#df = df.sort(['chromosome','start'])\n",
    "#df = df.drop(*(\"splitFromMultiAllelic\")).dropDuplicates(['unique_variant_id','AdditiveGenotype'])\n",
    "\n",
    "df = df.withColumn('PL_00',df.PL.getItem(0)).withColumn('PL_01',df.PL.getItem(1)).withColumn('PL_11',df.PL.getItem(2))\n",
    "#df = df.select(['unique_variant_id','unique_location','chromosome','start','end','reference','alternate','PL','PL_00', 'PL_01','PL_11','AdditiveGenotype'])\n",
    "\n",
    "df = df.withColumn('AdditiveGenotype',when((df.PL_00 == 0) & (df.PL_01 == 0) &\\\n",
    "                                           (col('AdditiveGenotype') == 0 ),-9).otherwise(df.AdditiveGenotype))\n",
    "df = df.withColumn('AdditiveGenotype',when(((df.PL_00 == 0) & (df.PL_01 == 0) &\\\n",
    "                     (df.PL_11 == 0)) & (col('AdditiveGenotype') == 0 ) ,-9).otherwise(df.AdditiveGenotype))\n",
    "\n",
    "df = df.drop(*(\"PL\",\"PL_00\",\"PL_01\",\"PL_11\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9648f4-24c8-435a-863f-f045e3ef13e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5038\n",
      "+--------+--------+---------+---------+----+-------+---------------------+--------------------+-----------------+-------------------+---------+---------+---------------------+--------+----------+------+---------+----------------+--------------+\n",
      "|   start|     end|reference|alternate|qual|INFO_DP|splitFromMultiAllelic|           genotypes|unique_variant_id|    unique_location|var_chrom|var_start|var_unique_variant_id| var_end|chromosome| calls|calls_str|AdditiveGenotype|participant_id|\n",
      "+--------+--------+---------+---------+----+-------+---------------------+--------------------+-----------------+-------------------+---------+---------+---------------------+--------+----------+------+---------+----------------+--------------+\n",
      "|30922706|30922706|        G|        T|  99|     40|                 true|[{BS_0302Y3N5, 99...|   6:30922706:G:T|6:30922706:30922706|        6| 30922706|       6:30922706:G:T|30922706|         6|[0, 1]|      0:1|               1|   BS_0302Y3N5|\n",
      "+--------+--------+---------+---------+----+-------+---------------------+--------------------+-----------------+-------------------+---------+---------+---------------------+--------+----------+------+---------+----------------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.count())\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66f6d0f-0f6d-45e7-9e6f-7bcd73431297",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+-------------------+-----------------+----------------+\n",
      "|chromosome|   start|     end|    unique_location|unique_variant_id|AdditiveGenotype|\n",
      "+----------+--------+--------+-------------------+-----------------+----------------+\n",
      "|         6|30922706|30922706|6:30922706:30922706|   6:30922706:G:T|               1|\n",
      "|         6|30925350|30925350|6:30925350:30925350|   6:30925350:G:A|               1|\n",
      "|         6|31138114|31138114|6:31138114:31138114|   6:31138114:A:G|               2|\n",
      "|         6|31144707|31144707|6:31144707:31144707|   6:31144707:C:T|               1|\n",
      "|         6|31144960|31144960|6:31144960:31144960|   6:31144960:C:A|               1|\n",
      "|         6|31148407|31148407|6:31148407:31148407|   6:31148407:G:T|               0|\n",
      "|         6|31151121|31151121|6:31151121:31151121|   6:31151121:A:T|               1|\n",
      "|         6|31154538|31154538|6:31154538:31154538|   6:31154538:G:C|               1|\n",
      "|         6|31154705|31154705|6:31154705:31154705|   6:31154705:G:A|               1|\n",
      "|         6|31154723|31154723|6:31154723:31154723|   6:31154723:G:A|               1|\n",
      "|         6|31157072|31157072|6:31157072:31157072|   6:31157072:C:T|               1|\n",
      "|         6|31157480|31157480|6:31157480:31157480|   6:31157480:C:A|               1|\n",
      "|         6|31161930|31161930|6:31161930:31161930|   6:31161930:C:T|               1|\n",
      "|         6|31356822|31356822|6:31356822:31356822|   6:31356822:T:G|              -9|\n",
      "|         6|31356824|31356824|6:31356824:31356824|  6:31356824:C:CA|              -9|\n",
      "|         6|31356824|31356824|6:31356824:31356824|  6:31356824:C:CA|              -9|\n",
      "|         6|31356824|31356824|6:31356824:31356824|  6:31356824:C:CG|              -9|\n",
      "|         6|31356824|31356824|6:31356824:31356824|  6:31356824:C:CG|              -9|\n",
      "|         6|31356826|31356827|6:31356826:31356827|  6:31356826:CT:C|              -9|\n",
      "|         6|31635190|31635190|6:31635190:31635190|   6:31635190:G:A|               1|\n",
      "+----------+--------+--------+-------------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select(['chromosome','start','end','unique_location','unique_variant_id','AdditiveGenotype'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e8800-3f96-418e-b7fc-31c51e7300e3",
   "metadata": {},
   "source": [
    "# Merge genes into the results of the new genotypes dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2af2e8-f9ae-48ea-8390-1b6fc21e0d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/13 13:07:49 WARN DataSource: All paths were ignored:\n",
      "  file:/sbgenomics/project-files/_1_test_FULL_join_july.parquet\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10021\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+-------------------+---------+---------+---------------------+--------+----------+\n",
      "|   start|     end|reference|alternate|  qual|INFO_DP|splitFromMultiAllelic|           genotypes|unique_variant_id|    unique_location|var_chrom|var_start|var_unique_variant_id| var_end|chromosome|\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+-------------------+---------+---------+---------------------+--------+----------+\n",
      "|30922706|30922706|        G|        T|581.77|     40|                 true|[{BS_0302Y3N5, 99...|   6:30922706:G:T|6:30922706:30922706|        6| 30922706|       6:30922706:G:T|30922706|         6|\n",
      "+--------+--------+---------+---------+------+-------+---------------------+--------------------+-----------------+-------------------+---------+---------+---------------------+--------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = spark.read.parquet('/sbgenomics/project-files/_1_test_FULL_join_july.parquet')\n",
    "print(t.count())\n",
    "t.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b51d5b-ea08-44f1-a193-d510c208247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10932230\n",
      "+----------+--------+---------+---------+---------+---------+-----------------+\n",
      "|chromosome|   start|reference|alternate|     rsID|   symbol|unique_variant_id|\n",
      "+----------+--------+---------+---------+---------+---------+-----------------+\n",
      "|         6|31674322|        G|        A|     null|   LY6G5B|   6:31674322:G:A|\n",
      "|         6|25727870|        C|        T|rs9356985|HIST1H2BA|   6:25727870:C:T|\n",
      "|         6|25957982|       AT|        A|     null|   TRIM38|  6:25957982:AT:A|\n",
      "+----------+--------+---------+---------+---------+---------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gene_map = spark.read.option(\"mode\", \"DROPMALFORMED\").parquet('/sbgenomics/project-files/tcsq_variant_gene_mappings_july4_3.parquet')\n",
    "gene_map = gene_map.withColumn('unique_variant_id',concat(col(\"chromosome\"), lit(\":\"),\n",
    "                                                   col(\"start\"),lit(':'),col('reference'),\n",
    "                                                   lit(':'),col('alternate')))\n",
    "print(gene_map.count())\n",
    "gene_map.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81739ccd-489f-4dab-b4e5-7ad2b75e3ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+----------+-----------+\n",
      "|unique_variant_id|           genotypes|    symbol|       rsID|\n",
      "+-----------------+--------------------+----------+-----------+\n",
      "|   6:32828908:A:G|[{BS_0302Y3N5, 99...|      TAP2|   rs241448|\n",
      "|   6:32828974:T:C|[{BS_0302Y3N5, 99...|      TAP2|   rs241447|\n",
      "|   6:31636814:C:T|[{BS_0302Y3N5, 99...|   MIR6832|    rs10885|\n",
      "|   6:32828974:T:C|[{BS_0302Y3N5, 99...|AL669918.1|   rs241447|\n",
      "|   6:32521954:G:C|[{BS_0302Y3N5, 99...|  HLA-DRB5| rs41554620|\n",
      "|   6:32519432:C:G|[{BS_0302Y3N5, 21...|  HLA-DRB5|rs189435670|\n",
      "|   6:32332045:G:A|[{BS_0302Y3N5, 99...|   C6orf10|  rs1003878|\n",
      "|   6:31356822:T:G|[{BS_0302Y3N5, 6,...|   MIR6891|  rs1050538|\n",
      "|   6:33069222:T:C|[{BS_0302Y3N5, 99...|  HLA-DPA1|  rs1042190|\n",
      "|   6:29173855:T:C|[{BS_0302Y3N5, 99...|     OR2J2|  rs3116855|\n",
      "|   6:35317943:A:C|[{BS_0302Y3N5, 99...|      DEF6|  rs2395617|\n",
      "|   6:32519567:T:C|[{BS_0302Y3N5, 99...|  HLA-DRB5|rs201863832|\n",
      "|   6:29101487:T:C|[{BS_0302Y3N5, 99...|     OR2J1|  rs2394516|\n",
      "|   6:29726904:A:T|[{BS_0302Y3N5, 99...|  RPL23AP1|  rs3734815|\n",
      "|   6:31161930:C:T|[{BS_0302Y3N5, 99...|     TCF19|  rs2073724|\n",
      "|   6:31810169:C:T|[{BS_0302Y3N5, 99...|      LSM2|  rs2075800|\n",
      "|   6:32154609:C:G|[{BS_0302Y3N5, 99...|AL662884.4|  rs3134604|\n",
      "|   6:32518555:C:G|[{BS_0302Y3N5, 39...|  HLA-DRB5|rs201788268|\n",
      "|   6:31672202:C:T|[{BS_0302Y3N5, 99...|    CSNK2B|  rs9267532|\n",
      "|   6:32581793:T:G|[{BS_0302Y3N5, 18...|  HLA-DRB1|       null|\n",
      "+-----------------+--------------------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapped_df = t.select(['unique_variant_id','genotypes']).join(gene_map.select('unique_variant_id','symbol','rsID'),'unique_variant_id','inner')\n",
    "print(mapped_df.count())\n",
    "mapped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f83982-6e35-4c01-a255-a3d19fbbd04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49e89f68-98a1-449a-b022-1d19d63fd09d",
   "metadata": {},
   "source": [
    "# Normalize by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1d523a-d750-4198-829e-ccf33a408fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172809\n",
      "+----+--------------+-----+------+--------+--------+--------+--------+---------+--------------------+--------------------+-----+--------+------------+----------+--------------------+\n",
      "|#bin|          name|chrom|strand| txStart|   txEnd|cdsStart|  cdsEnd|exonCount|          exonStarts|            exonEnds|score|   name2|cdsStartStat|cdsEndStat|          exonFrames|\n",
      "+----+--------------+-----+------+--------+--------+--------+--------+---------+--------------------+--------------------+-----+--------+------------+----------+--------------------+\n",
      "|   0|NM_001276352.2| chr1|     -|67092164|67134970|67093579|67127240|        9|67092164,67096251...|67093604,67096321...|    0|C1orf141|        cmpl|      cmpl|2,1,0,1,2,0,0,-1,-1,|\n",
      "+----+--------------+-----+------+--------+--------+--------+--------+---------+--------------------+--------------------+-----+--------+------------+----------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gene_lens = spark.read.option('sep','\\t').option('header',True).csv('/sbgenomics/project-files/gene_regions_refseq')\n",
    "print(gene_lens.count())\n",
    "gene_lens.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa7214-b914-49a5-b1e7-23cab974bcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056c14f-febe-424f-aa60-2935887ae555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2eab3dc-ca02-4559-8a0d-8527fb3f3966",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 60764664\n",
      "\tSearch: 60764663..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=>(21 + 1) / 42][Stage 36:>  (0 + 0) / 42][Stage 39:>  (0 + 0) / 42]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \"\"\"\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:560)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:528)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n",
      "[Stage 36:====>           (12 + 1) / 42][Stage 39:>                (0 + 0) / 42]\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chroms = ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '22', '3', '4', '5', '6', '7','8', '9', 'X','Y']\n",
    "\n",
    "AdditiveGenotypes = []\n",
    "\n",
    "for CHROM in ['15']:#chroms:\n",
    "    #df_chrom = df.where(col('chromosome') == CHROM)\n",
    "    #chrom_locs = df_missing[df_missing['chrom'] == CHROM]['location']\n",
    "    \n",
    "    for LOC in chrom_locs:\n",
    "        start_loc = int(LOC.split(':')[1])\n",
    "        end_loc = int(LOC.split(':')[2])\n",
    "        \n",
    "        print(f'Searching for {start_loc}')\n",
    "        FOUND = False\n",
    "        N = 1\n",
    "    \n",
    "        while FOUND == False:\n",
    "            print(f'\\tSearch: {start_loc - N}...',end='')\n",
    "            df_loc = df_chrom.where(col('start') ==  start_loc - N)\n",
    "            \n",
    "            if df_loc.count() == 1:\n",
    "                FOUND = True\n",
    "                print('Found!')\n",
    "                end_pos_df = [row['end'] for row in df_loc.select('end').collect()] \n",
    "                \n",
    "                if end_loc <= end_pos_df: \n",
    "                    AdditiveGenotypes.append((LOC,[row['AdditiveGenotype'] for row in\\\n",
    "                                                          df_loc.select('AdditiveGenotype').collect()]) )\n",
    "                else:\n",
    "                    AdditiveGenotypes.append((LOC, -9 )) # not reported in gVCF, assign missing (-9)\n",
    "            elif df_loc.count() == 0:\n",
    "                print('Not Found.')\n",
    "                N=N+1\n",
    "            else:\n",
    "                print('Found Loc with more than one match!!!')\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "beabd16b-bc16-405c-881a-eee40d98c768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element is present at index 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Returns index of x in arr if present, else -1\n",
    "def binary_search(arr, low, high, x):\n",
    " \n",
    "    # Check base case\n",
    "    if high >= low:\n",
    " \n",
    "        mid = (high + low) // 2\n",
    " \n",
    "        # If element is present at the middle itself\n",
    "        if arr[mid] == x:\n",
    "            return mid\n",
    " \n",
    "        # If element is smaller than mid, then it can only\n",
    "        # be present in left subarray\n",
    "        elif arr[mid] > x:\n",
    "            return binary_search(arr, low, mid - 1, x)\n",
    " \n",
    "        # Else the element can only be present in right subarray\n",
    "        else:\n",
    "            return binary_search(arr, mid + 1, high, x)\n",
    " \n",
    "    else:\n",
    "        # Element is not present in the array\n",
    "        return -1\n",
    " \n",
    "# Test array\n",
    "arr = [ 2, 3, 4, 10, 40 ]\n",
    "x = 10\n",
    " \n",
    "# Function call\n",
    "result = binary_search(arr, 0, len(arr)-1, x)\n",
    " \n",
    "if result != -1:\n",
    "    print(\"Element is present at index\", str(result))\n",
    "else:\n",
    "    print(\"Element is not present in array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c18da-211f-4706-a537-62bb62176cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

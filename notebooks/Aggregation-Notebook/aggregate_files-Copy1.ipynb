{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data files by node or relationship type\n",
    "Load in the files from each step and combine them based on node or relationship type. This way we dont need to write a cypher import query for CUI's for every step, we can just load all CUIs with one query.  \n",
    "For example, combine all the CUIs.csv files into one CUI_MASTER file.  \n",
    "Then, when everything looks good, we can add these master files directly to the UMLS-KG csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data that we are incorporating into UMLS connects to the HGNC, HPO, UBERON ontologies/vocabs only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#from matplotlib_venn import venn2, venn3\n",
    "#import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "from umls_utils import get_paths\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install \"dask[complete]\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/stearb/Desktop/hubmap-kg/FREEZE/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dask\n",
    "umls_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook aggregate_files-Copy1.ipynb to script\n",
      "[NbConvertApp] Writing 32099 bytes to aggregate_files-Copy1.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script aggregate_files-Copy1.ipynb\n",
    "!sed -i '' '/.head(/d' aggregate_files-Copy1.py\n",
    "!sed -i '' '/^#/d' aggregate_files-Copy1.py\n",
    "!sed -i '' '/get_ipython()/d' aggregate_files-Copy1.py\n",
    "#!sed -i '' '/print/d' aggregate_files-Copy1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir,helper_data_dir,output_dir,LOCAL_CPU,umls_dir, umls_out_dir = get_paths('/Users/stearb/Dropbox/CHOP/R03/code/neo4j_build_CFDIKG/build_scripts/')\n",
    "\n",
    "# We will import our data from the folder where we saved the CSVs from each step.\n",
    "import_dir = output_dir\n",
    " \n",
    "if not os.path.isdir(output_dir+'new_UMLS_CSVs'):\n",
    "    os.mkdir(output_dir+'new_UMLS_CSVs')\n",
    "    print('Creating new_UMLS_CSVs directory...')\n",
    "\n",
    "new_UMLS_CSVs_path = output_dir+'new_UMLS_CSVs'+'/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate the file types across each of the different steps\n",
    "Put all CUIs.csv into one CUIs.csv file  \n",
    "Put all CUI-CODEs.csv into one CUI-CODEs.csv file  \n",
    "Etc.,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Load CUI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CUI files took 0.0 min. 38.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Load mouse ortholog CUIs\n",
    "CUI_ortho = pd.read_pickle(output_dir+'orthologs/CUI_mouse_ortho.pickle')\n",
    "\n",
    "# Load mouse phenotype CUIs\n",
    "CUI_genopheno = pd.read_pickle(output_dir+'genopheno/CUIs_genotype.pickle')\n",
    "\n",
    "# Load mammalian phenotype ontology CUIs\n",
    "CUI_mp = pd.read_pickle(output_dir+'MPO/CUIs_mp_ont.pickle') \n",
    "\n",
    "# Load phenomapping CUIs \n",
    "CUI_phenomap = pd.read_csv(output_dir+'hpo_mp_mapping/CUIs_phenomapping.csv')\n",
    "\n",
    "#  GTEx CUIs (eQTLs and median gene expression)   \n",
    "CUI_gtex = pd.read_pickle(output_dir+'GTEx/CUIs_GTEx.pickle')\n",
    "\n",
    "# dbSNP CUIs\n",
    "#CUI_dbsnp = pd.read_csv(LOCAL_PATH+'dbsnp/CUIs_dbsnp.csv')\n",
    "\n",
    "# KF phenotype\n",
    "CUI_kf = pd.read_csv(output_dir+'KF_phenotypes/CUIs_kf.csv')\n",
    "\n",
    "# scHeart\n",
    "CUI_scHeart = pd.read_csv(output_dir+'scHeart/CUIs_scHeart.csv')\n",
    "\n",
    "# Hubmap \n",
    "CUI_hubmap = pd.read_pickle(output_dir+'HUBMAPsc/hubmap_CUIs.pickle')\n",
    "\n",
    "\n",
    "CUIs_all = pd.DataFrame(np.concatenate([CUI_ortho.values,CUI_genopheno ,CUI_mp  # CUI_dbsnp,\n",
    "                             ,CUI_phenomap,CUI_gtex,CUI_kf,CUI_scHeart,CUI_hubmap]),columns=['CUI:ID']).drop_duplicates()\n",
    "\n",
    "\n",
    "#CUIs_all = pd.Series([i[0] for i in CUIs_all.values],name='CUI:ID')\n",
    "# Check that all CUIs are in the same format (same length)\n",
    "#assert np.all(CUIs_all['CUI:ID'].str.len() == 16) CUIs will be different lengths using the base64 method\n",
    "\n",
    "# Check for no collisions\n",
    "assert CUIs_all.nunique()['CUI:ID'] == len(CUIs_all)\n",
    "\n",
    "end = time.time() - t0\n",
    "print(f'All CUI files took {np.floor(end/60)} min. {np.round(end%60)} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and combine all CUI-CUI files, need ':TYPE',  'SAB' columns to match UMLS CUI-CUI import files\n",
    "Remember the  relationship :type is just the Code-Code relationship types but in the Concept (CUI) space.  \n",
    "So our relationships will be:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUI-CUI relationship :TYPEs by file\n",
    "orthologs/CUI-CUI_ortho.csv  -----> :ortholog\n",
    "\n",
    "genopheno/CUI-CUI_genotype.csv ----> :has_phenotype\n",
    "\n",
    "MPO/CUI-CUIs_mp_ont.csv ------> :SCO     #### FIX\n",
    "\n",
    "hpo_mp_mapping/CUI-CUI_phenomapping.csv   ------>  :has_human_phenotype,:has_mouse_phenotype,\n",
    "\n",
    "GTEx/CUI-CUI_GTEx.csv \n",
    "-----> GTEX EXP :has_median_expression_in_gene,  :has_median_expression_in_tissue  \n",
    "-----> GTEX EQTL:has_eqtl :in_gene, :in_tissue, :in_variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUI-CUI SAB by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'hpo_mp_mapping/CUI_CUI_phenomapping.csv',,'kf_phenotypes/CUI_CUIs_kf.csv',\n",
    "                'scHeart/CUI_CUIs_scHeart.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_cui_paths = ['orthologs/CUI_CUI_ortho.pickle','genopheno/CUI_CUI_genotype.pickle',\n",
    "                 'MPO/CUI_CUIs_mp_ont.pickle',\n",
    "                 'GTEx/CUI_CUI_GTEx.pickle','HGNC_HPO/CUI_CUIs_hgnc_hpo.pickle',\n",
    "                 'HUBMAPsc/hubmap_CUI_CUIs.pickle',\n",
    "                'hpo_mp_mapping/CUI_CUI_phenomapping.csv','kf_phenotypes/CUI_CUIs_kf.csv',\n",
    "                'scHeart/CUI_CUIs_scHeart.csv']\n",
    "\n",
    "cui_cui_paths_pickle = [output_dir+i for i in cui_cui_paths]\n",
    "cui_cui_paths_csv = [i.replace('pickle','csv') for i in cui_cui_paths_pickle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CUI-CUI files took 0.0 min. 39.0 seconds.\n",
      "Concat CUI-CUI files took 0.0 min. 31.0 seconds.\n",
      "All CUI-CUI files took 2.0 min. 33.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Load mouse ortholog CUIs\n",
    "CUI_CUI_ortho = pd.read_pickle(output_dir+'orthologs/CUI_CUI_ortho.pickle')\n",
    "\n",
    "# Load mouse phenotype CUIs\n",
    "CUI_CUI_genopheno = pd.read_pickle(output_dir+'genopheno/CUI_CUI_genotype.pickle')\n",
    "\n",
    "# Load mammalian phenotype ontology CUIs     \n",
    "CUI_CUI_mp = pd.read_pickle(output_dir+'MPO/CUI_CUIs_mp_ont.pickle') # All :TYPEs are 'SCO' still...\n",
    "\n",
    "# Load phenomapping CUIs \n",
    "CUI_CUI_phenomap = pd.read_csv(output_dir+'hpo_mp_mapping/CUI_CUI_phenomapping.csv')\n",
    "\n",
    "#  GTEx CUIs (eQTLs and med. expression)\n",
    "CUI_CUI_gtex = pd.read_pickle(output_dir+'GTEx/CUI_CUI_GTEx.pickle')\n",
    "\n",
    "# dbSNP CUI-CUIs, this is the actual dbSNP data, we have dbSNP rs IDs from GTEx already\n",
    "#CUI_CUI_dbsnp = pd.read_csv(LOCAL_PATH+'dbsnp/CUI_CUIs_dbsnp.csv')\n",
    "\n",
    "# KF phenotypes\n",
    "CUI_CUI_kf = pd.read_csv(output_dir+'kf_phenotypes/CUI_CUIs_kf.csv')\n",
    "\n",
    "# scHeart\n",
    "CUI_CUI_scHeart = pd.read_csv(output_dir+'scHeart/CUI_CUIs_scHeart.csv')\n",
    "\n",
    "# HGNC-HPO \n",
    "CUI_CUI_hgnc_hpo = pd.read_pickle(output_dir+'HGNC_HPO/CUI_CUIs_hgnc_hpo.pickle')\n",
    "\n",
    "# Hubmap\n",
    "\n",
    "CUI_CUI_hubmap = pd.read_pickle(output_dir+'HUBMAPsc/hubmap_CUI_CUIs.pickle')\n",
    "\n",
    "end = time.time() - t0\n",
    "print(f'Reading CUI-CUI files took {np.floor(end/60)} min. {np.round(end%60)} seconds.')\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "np_concat = np.concatenate([CUI_CUI_ortho.values,\n",
    "                                    CUI_CUI_genopheno,\n",
    "                                    CUI_CUI_mp,\n",
    "                                    CUI_CUI_phenomap,\n",
    "                                    CUI_CUI_gtex, \n",
    "                                    CUI_CUI_kf, \n",
    "                                    CUI_CUI_scHeart,\n",
    "                                    CUI_CUI_hgnc_hpo, # CUI_CUI_dbsnp\n",
    "                                    CUI_CUI_hubmap\n",
    "                                    ])\n",
    "end = time.time() - t0\n",
    "print(f'Concat CUI-CUI files took {np.floor(end/60)} min. {np.round(end%60)} seconds.')\n",
    "\n",
    "\n",
    "CUI_CUIs_all = pd.DataFrame(np_concat,columns=[':START_ID',':END_ID',':TYPE','SAB']).drop_duplicates()\n",
    "\n",
    "\n",
    "'''\n",
    "CUI_CUIs_all = pd.DataFrame(np.concatenate([CUI_CUI_ortho.values,\n",
    "                                            CUI_CUI_genopheno,\n",
    "                                            CUI_CUI_mp,\n",
    "                                            CUI_CUI_phenomap,\n",
    "                                            CUI_CUI_gtex, \n",
    "                                            CUI_CUI_kf, \n",
    "                                            CUI_CUI_scHeart,\n",
    "                                            CUI_CUI_hgnc_hpo, # CUI_CUI_dbsnp\n",
    "                                            CUI_CUI_hubmap\n",
    "                                            ]),\n",
    "                                                columns=[':START_ID',':END_ID',':TYPE','SAB']).drop_duplicates()\n",
    "'''\n",
    "\n",
    "end = time.time() - t0\n",
    "print(f'All CUI-CUI files took {np.floor(end/60)} min. {np.round(end%60)} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.5 s, sys: 11.6 s, total: 27 s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Output = pd.concat([pd.read_pickle(x) for x in cui_cui_paths_pickle])\n",
    "type(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\u0000\u0000j\u000b",
      "B\u0000\u0000j\f",
      "B\u0000\u0000j\r",
      "B\u0000\u0000j\u000eB\u0000\u0000j\u000fB\u0000\u0000j\u0010B\u0000\u0000j\u0011B\u0000\u0000j\u0012B\u0000\u0000j\u0013B\u0000\u0000j\u0014B\u0000\u0000j\u0015B\u0000\u0000j\u0016B\u0000\u0000j\u0017B\u0000\u0000j\u0018B\u0000\u0000j\u0019B\u0000\u0000j\u001aB\u0000\u0000j\u001bB\u0000\u0000j\u001c",
      "B\u0000\u0000j\u001d",
      "B\u0000\u0000j\u001e",
      "B\u0000\u0000j\u001fB\u0000\u0000j B\u0000\u0000j!B\u0000\u0000j\"B\u0000\u0000j#B\u0000\u0000j$B\u0000\u0000j%B\u0000\u0000j&B\u0000\u0000j'B\u0000\u0000j(B\u0000\u0000j)B\u0000\u0000j*B\u0000\u0000j+B\u0000\u0000j,B\u0000\u0000j-B\u0000\u0000j.B\u0000\u0000j/B\u0000\u0000j0B\u0000\u0000j1B\u0000\u0000j2B\u0000\u0000j3B\u0000\u0000j4B\u0000\u0000j5B\u0000\u0000j6B\u0000\u0000j7B\u0000\u0000j8B\u0000\u0000j9B\u0000\u0000j:B\u0000\u0000j;B\u0000\u0000j<B\u0000\u0000j=B\u0000\u0000j>B\u0000\u0000j?B\u0000\u0000j@B\u0000\u0000jAB\u0000\u0000jBB\u0000\u0000jCB\u0000\u0000jDB\u0000\u0000jEB\u0000\u0000jFB\u0000\u0000jGB\u0000\u0000jHB\u0000\u0000jIB\u0000\u0000jJB\u0000\u0000jKB\u0000\u0000jLB\u0000\u0000jMB\u0000\u0000jNB\u0000\u0000jOB\u0000\u0000jPB\u0000\u0000jQB\u0000\u0000jRB\u0000\u0000jSB\u0000\u0000jTB\u0000\u0000jUB\u0000\u0000jVB\u0000\u0000jWB\u0000\u0000jXB\u0000\u0000jYB\u0000\u0000jZB\u0000\u0000j[B\u0000\u0000j\\B\u0000\u0000j]B\u0000\u0000j^B\u0000\u0000j_B\u0000\u0000j`B\u0000\u0000jaB\u0000\u0000jbB\u0000\u0000jcB\u0000\u0000jdB\u0000\u0000jeB\u0000\u0000jfB\u0000\u0000jgB\u0000\u0000jhB\u0000\u0000jiB\u0000\u0000jjB\u0000\u0000jkB\u0000\u0000jlB\u0000\u0000jmB\u0000\u0000jnB\u0000\u0000joB\u0000\u0000jpB\u0000\u0000jqB\u0000\u0000jrB\u0000\u0000jsB\u0000\u0000jtB\u0000\u0000juB\u0000\u0000jvB\u0000\u0000jwB\u0000\u0000jxB\u0000\u0000jyB\u0000\u0000jzB\u0000\u0000j{B\u0000\u0000j|B\u0000\u0000j}B\u0000\u0000j~B\u0000\u0000jB\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j�B\u0000\u0000j\u0000C\u0000\u0000j\u0001C\u0000\u0000j\u0002C\u0000\u0000j\u0003C\u0000\u0000j\u0004C\u0000\u0000j\u0005C\u0000\u0000j\u0006C\u0000\u0000j\u0007C\u0000\u0000j\bC\u0000\u0000j\tC\u0000\u0000j\r\n",
      "C\u0000\u0000j\u000b",
      "C\u0000\u0000j\f",
      "C\u0000\u0000j\r",
      "C\u0000\u0000j\u000eC\u0000\u0000j\u000fC\u0000\u0000j\u0010C\u0000\u0000j\u0011C\u0000\u0000j\u0012C\u0000\u0000j\u0013C\u0000\u0000j\u0014C\u0000\u0000j\u0015C\u0000\u0000j\u0016C\u0000\u0000j\u0017C\u0000\u0000j\u0018C\u0000\u0000j\u0019C\u0000\u0000j\u001aC\u0000\u0000j\u001bC\u0000\u0000j\u001c",
      "C\u0000\u0000j\u001d",
      "C\u0000\u0000j\u001e",
      "C\u0000\u0000j\u001fC\u0000\u0000j C\u0000\u0000j!C\u0000\u0000j\"C\u0000\u0000j#C\u0000\u0000j$C\u0000\u0000j%C\u0000\u0000j&C\u0000\u0000j'C\u0000\u0000j(C\u0000\u0000j)C\u0000\u0000j*C\u0000\u0000j+C\u0000\u0000j,C\u0000\u0000j-C\u0000\u0000j.C\u0000\u0000j/C\u0000\u0000j0C\u0000\u0000j1C\u0000\u0000j2C\u0000\u0000j3C\u0000\u0000j4C\u0000\u0000j5C\u0000\u0000j6C\u0000\u0000j7C\u0000\u0000j8C\u0000\u0000j9C\u0000\u0000j:C\u0000\u0000j;C\u0000\u0000j<C\u0000\u0000j=C\u0000\u0000j>C\u0000\u0000j?C\u0000\u0000j@C\u0000\u0000jAC\u0000\u0000jBC\u0000\u0000jCC\u0000\u0000jDC\u0000\u0000jEC\u0000\u0000jFC\u0000\u0000jGC\u0000\u0000jHC\u0000\u0000jIC\u0000\u0000jJC\u0000\u0000jKC\u0000\u0000jLC\u0000\u0000jMC\u0000\u0000jNC\u0000\u0000jOC\u0000\u0000jPC\u0000\u0000jQC\u0000\u0000jRC\u0000\u0000jSC\u0000\u0000jTC\u0000\u0000jUC\u0000\u0000jVC\u0000\u0000jWC\u0000\u0000jXC\u0000\u0000jYC\u0000\u0000jZC\u0000\u0000j[C\u0000\u0000j\\C\u0000\u0000j]C\u0000\u0000j^C\u0000\u0000j_C\u0000\u0000j`C\u0000\u0000jaC\u0000\u0000jbC\u0000\u0000jcC\u0000\u0000jdC\u0000\u0000jeC\u0000\u0000jfC\u0000\u0000jgC\u0000\u0000jhC\u0000\u0000jiC\u0000\u0000jjC\u0000\u0000jkC\u0000\u0000jlC\u0000\u0000jmC\u0000\u0000jnC\u0000\u0000joC\u0000\u0000jpC\u0000\u0000jqC\u0000\u0000jrC\u0000\u0000jsC\u0000\u0000jtC\u0000\u0000juC\u0000\u0000jvC\u0000\u0000jwC\u0000\u0000jxC\u0000\u0000jyC\u0000\u0000jzC\u0000\u0000j{C\u0000\u0000j|C\u0000\u0000j}C\u0000\u0000j~C\u0000\u0000jC\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000e(j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j�C\u0000\u0000j\u0000D\u0000\u0000j\u0001D\u0000\u0000j\u0002D\u0000\u0000j\u0003D\u0000\u0000j\u0004D\u0000\u0000j\u0005D\u0000\u0000j\u0006D\u0000\u0000j\u0007D\u0000\u0000j\bD\u0000\u0000j\tD\u0000\u0000j\r\n",
      "D\u0000\u0000j\u000b",
      "D\u0000\u0000j\f",
      "D\u0000\u0000j\r",
      "D\u0000\u0000j\u000eD\u0000\u0000j\u000fD\u0000\u0000j\u0010D\u0000\u0000j\u0011D\u0000\u0000j\u0012D\u0000\u0000j\u0013D\u0000\u0000j\u0014D\u0000\u0000j\u0015D\u0000\u0000j\u0016D\u0000\u0000j\u0017D\u0000\u0000j\u0018D\u0000\u0000j\u0019D\u0000\u0000j\u001aD\u0000\u0000j\u001bD\u0000\u0000j\u001c",
      "D\u0000\u0000j\u001d",
      "D\u0000\u0000j\u001e",
      "D\u0000\u0000j\u001fD\u0000\u0000j D\u0000\u0000j!D\u0000\u0000j\"D\u0000\u0000j#D\u0000\u0000j$D\u0000\u0000j%D\u0000\u0000j&D\u0000\u0000j'D\u0000\u0000j(D\u0000\u0000j)D\u0000\u0000j*D\u0000\u0000j+D\u0000\u0000j,D\u0000\u0000j-D\u0000\u0000j.D\u0000\u0000j/D\u0000\u0000j0D\u0000\u0000j1D\u0000\u0000j2D\u0000\u0000j3D\u0000\u0000j4D\u0000\u0000j5D\u0000\u0000j6D\u0000\u0000j7D\u0000\u0000j8D\u0000\u0000j9D\u0000\u0000j:D\u0000\u0000j;D\u0000\u0000j<D\u0000\u0000j=D\u0000\u0000j>D\u0000\u0000j?D\u0000\u0000j@D\u0000\u0000jAD\u0000\u0000jBD\u0000\u0000jCD\u0000\u0000jDD\u0000\u0000jED\u0000\u0000jFD\u0000\u0000jGD\u0000\u0000jHD\u0000\u0000jID\u0000\u0000jJD\u0000\u0000jKD\u0000\u0000jLD\u0000\u0000jMD\u0000\u0000jND\u0000\u0000jOD\u0000\u0000jPD\u0000\u0000jQD\u0000\u0000jRD\u0000\u0000jSD\u0000\u0000jTD\u0000\u0000jUD\u0000\u0000jVD\u0000\u0000jWD\u0000\u0000jXD\u0000\u0000jYD\u0000\u0000jZD\u0000\u0000j[D\u0000\u0000j\\D\u0000\u0000j]D\u0000\u0000j^D\u0000\u0000j_D\u0000\u0000j`D\u0000\u0000jaD\u0000\u0000jbD\u0000\u0000jcD\u0000\u0000jdD\u0000\u0000jeD\u0000\u0000jfD\u0000\u0000jgD\u0000\u0000jhD\u0000\u0000jiD\u0000\u0000jjD\u0000\u0000jkD\u0000\u0000jlD\u0000\u0000jmD\u0000\u0000jnD\u0000\u0000joD\u0000\u0000jpD\u0000\u0000jqD\u0000\u0000jrD\u0000\u0000jsD\u0000\u0000jtD\u0000\u0000juD\u0000\u0000jvD\u0000\u0000jwD\u0000\u0000jxD\u0000\u0000jyD\u0000\u0000jzD\u0000\u0000j{D\u0000\u0000j|D\u0000\u0000j}D\u0000\u0000j~D\u0000\u0000jD\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j�D\u0000\u0000j\u0000E\u0000\u0000j\u0001E\u0000\u0000j\u0002E\u0000\u0000j\u0003E\u0000\u0000j\u0004E\u0000\u0000j\u0005E\u0000\u0000j\u0006E\u0000\u0000j\u0007E\u0000\u0000j\bE\u0000\u0000j\tE\u0000\u0000j\r\n",
      "E\u0000\u0000j\u000b",
      "E\u0000\u0000j\f",
      "E\u0000\u0000j\r",
      "E\u0000\u0000j\u000eE\u0000\u0000j\u000fE\u0000\u0000j\u0010E\u0000\u0000j\u0011E\u0000\u0000j\u0012E\u0000\u0000j\u0013E\u0000\u0000j\u0014E\u0000\u0000j\u0015E\u0000\u0000j\u0016E\u0000\u0000j\u0017E\u0000\u0000j\u0018E\u0000\u0000j\u0019E\u0000\u0000j\u001aE\u0000\u0000j\u001bE\u0000\u0000j\u001c",
      "E\u0000\u0000j\u001d",
      "E\u0000\u0000j\u001e",
      "E\u0000\u0000j\u001fE\u0000\u0000j E\u0000\u0000j!E\u0000\u0000j\"E\u0000\u0000j#E\u0000\u0000j$E\u0000\u0000j%E\u0000\u0000j&E\u0000\u0000j'E\u0000\u0000j(E\u0000\u0000j)E\u0000\u0000j*E\u0000\u0000j+E\u0000\u0000j,E\u0000\u0000j-E\u0000\u0000j.E\u0000\u0000j/E\u0000\u0000j0E\u0000\u0000j1E\u0000\u0000j2E\u0000\u0000j3E\u0000\u0000j4E\u0000\u0000j5E\u0000\u0000j6E\u0000\u0000j7E\u0000\u0000j8E\u0000\u0000j9E\u0000\u0000j:E\u0000\u0000j;E\u0000\u0000j<E\u0000\u0000j=E\u0000\u0000j>E\u0000\u0000j?E\u0000\u0000j@E\u0000\u0000jAE\u0000\u0000jBE\u0000\u0000jCE\u0000\u0000jDE\u0000\u0000jEE\u0000\u0000jFE\u0000\u0000jGE\u0000\u0000jHE\u0000\u0000jIE\u0000\u0000jJE\u0000\u0000jKE\u0000\u0000jLE\u0000\u0000jME\u0000\u0000jNE\u0000\u0000jOE\u0000\u0000jPE\u0000\u0000jQE\u0000\u0000jRE\u0000\u0000jSE\u0000\u0000jTE\u0000\u0000jUE\u0000\u0000jVE\u0000\u0000jWE\u0000\u0000jXE\u0000\u0000jYE\u0000\u0000jZE\u0000\u0000j[E\u0000\u0000j\\E\u0000\u0000j]E\u0000\u0000j^E\u0000\u0000j_E\u0000\u0000j`E\u0000\u0000jaE\u0000\u0000jbE\u0000\u0000jcE\u0000\u0000jdE\u0000\u0000jeE\u0000\u0000jfE\u0000\u0000jgE\u0000\u0000jhE\u0000\u0000jiE\u0000\u0000jjE\u0000\u0000jkE\u0000\u0000jlE\u0000\u0000jmE\u0000\u0000jnE\u0000\u0000joE\u0000\u0000jpE\u0000\u0000jqE\u0000\u0000jrE\u0000\u0000jsE\u0000\u0000jtE\u0000\u0000juE\u0000\u0000jvE\u0000\u0000jwE\u0000\u0000jxE\u0000\u0000jyE\u0000\u0000jzE\u0000\u0000j{E\u0000\u0000j|E\u0000\u0000j}E\u0000\u0000j~E\u0000\u0000jE\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j�E\u0000\u0000j\u0000F\u0000\u0000j\u0001F\u0000\u0000j\u0002F\u0000\u0000j\u0003F\u0000\u0000j\u0004F\u0000\u0000j\u0005F\u0000\u0000j\u0006F\u0000\u0000j\u0007F\u0000\u0000j\bF\u0000\u0000j\tF\u0000\u0000j\r\n",
      "F\u0000\u0000j\u000b",
      "F\u0000\u0000j\f",
      "F\u0000\u0000j\r",
      "F\u0000\u0000j\u000eF\u0000\u0000j\u000fF\u0000\u0000j\u0010F\u0000\u0000j\u0011F\u0000\u0000j\u0012F\u0000\u0000j\u0013F\u0000\u0000j\u0014F\u0000\u0000j\u0015F\u0000\u0000j\u0016F\u0000\u0000j\u0017F\u0000\u0000j\u0018F\u0000\u0000j\u0019F\u0000\u0000j\u001aF\u0000\u0000j\u001bF\u0000\u0000j\u001c",
      "F\u0000\u0000j\u001d",
      "F\u0000\u0000j\u001e",
      "F\u0000\u0000j\u001fF\u0000\u0000j F\u0000\u0000j!F\u0000\u0000j\"F\u0000\u0000j#F\u0000\u0000j$F\u0000\u0000j%F\u0000\u0000j&F\u0000\u0000j'F\u0000\u0000j(F\u0000\u0000j)F\u0000\u0000j*F\u0000\u0000j+F\u0000\u0000j,F\u0000\u0000j-F\u0000\u0000j.F\u0000\u0000j/F\u0000\u0000j0F\u0000\u0000j1F\u0000\u0000j2F\u0000\u0000j3F\u0000\u0000j4F\u0000\u0000j5F\u0000\u0000j6F\u0000\u0000j7F\u0000\u0000j8F\u0000\u0000j9F\u0000\u0000j:F\u0000\u0000j;F\u0000\u0000j<F\u0000\u0000j=F\u0000\u0000j>F\u0000\u0000j?F\u0000\u0000j@F\u0000\u0000jAF\u0000\u0000jBF\u0000\u0000jCF\u0000\u0000jDF\u0000\u0000jEF\u0000\u0000jFF\u0000\u0000jGF\u0000\u0000jHF\u0000\u0000jIF\u0000\u0000jJF\u0000\u0000jKF\u0000\u0000jLF\u0000\u0000jMF\u0000\u0000jNF\u0000\u0000jOF\u0000\u0000jPF\u0000\u0000jQF\u0000\u0000jRF\u0000\u0000jSF\u0000\u0000jTF\u0000\u0000jUF\u0000\u0000jVF\u0000\u0000jWF\u0000\u0000jXF\u0000\u0000jYF\u0000\u0000jZF\u0000\u0000j[F\u0000\u0000j\\F\u0000\u0000j]F\u0000\u0000j^F\u0000\u0000j_F\u0000\u0000j`F\u0000\u0000jaF\u0000\u0000jbF\u0000\u0000jcF\u0000\u0000jdF\u0000\u0000jeF\u0000\u0000jfF\u0000\u0000jgF\u0000\u0000jhF\u0000\u0000jiF\u0000\u0000jjF\u0000\u0000jkF\u0000\u0000jlF\u0000\u0000jmF\u0000\u0000jnF\u0000\u0000joF\u0000\u0000jpF\u0000\u0000jqF\u0000\u0000jrF\u0000\u0000jsF\u0000\u0000jtF\u0000\u0000juF\u0000\u0000jvF\u0000\u0000jwF\u0000\u0000jxF\u0000\u0000jyF\u0000\u0000jzF\u0000\u0000j{F\u0000\u0000j|F\u0000\u0000j}F\u0000\u0000j~F\u0000\u0000jF\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j�F\u0000\u0000j\u0000G\u0000\u0000j\u0001G\u0000\u0000j\u0002G\u0000\u0000j\u0003G\u0000\u0000j\u0004G\u0000\u0000j\u0005G\u0000\u0000j\u0006G\u0000\u0000j\u0007G\u0000\u0000j\bG\u0000\u0000j\tG\u0000\u0000j\r\n",
      "G\u0000\u0000j\u000b",
      "G\u0000\u0000j\f",
      "G\u0000\u0000j\r",
      "G\u0000\u0000j\u000eG\u0000\u0000j\u000fG\u0000\u0000j\u0010G\u0000\u0000j\u0011G\u0000\u0000j\u0012G\u0000\u0000j\u0013G\u0000\u0000j\u0014G\u0000\u0000j\u0015G\u0000\u0000j\u0016G\u0000\u0000j\u0017G\u0000\u0000j\u0018G\u0000\u0000j\u0019G\u0000\u0000j\u001aG\u0000\u0000j\u001bG\u0000\u0000j\u001c",
      "G\u0000\u0000j\u001d",
      "G\u0000\u0000j\u001e",
      "G\u0000\u0000j\u001fG\u0000\u0000j G\u0000\u0000j!G\u0000\u0000j\"G\u0000\u0000j#G\u0000\u0000j$G\u0000\u0000j%G\u0000\u0000j&G\u0000\u0000j'G\u0000\u0000j(G\u0000\u0000j)G\u0000\u0000j*G\u0000\u0000j+G\u0000\u0000j,G\u0000\u0000j-G\u0000\u0000j.G\u0000\u0000j/G\u0000\u0000j0G\u0000\u0000j1G\u0000\u0000j2G\u0000\u0000j3G\u0000\u0000j4G\u0000\u0000j5G\u0000\u0000j6G\u0000\u0000j7G\u0000\u0000j8G\u0000\u0000j9G\u0000\u0000j:G\u0000\u0000j;G\u0000\u0000j<G\u0000\u0000j=G\u0000\u0000j>G\u0000\u0000j?G\u0000\u0000j@G\u0000\u0000jAG\u0000\u0000jBG\u0000\u0000jCG\u0000\u0000jDG\u0000\u0000jEG\u0000\u0000jFG\u0000\u0000jGG\u0000\u0000jHG\u0000\u0000jIG\u0000\u0000jJG\u0000\u0000jKG\u0000\u0000jLG\u0000\u0000jMG\u0000\u0000jNG\u0000\u0000jOG\u0000\u0000jPG\u0000\u0000jQG\u0000\u0000jRG\u0000\u0000jSG\u0000\u0000jTG\u0000\u0000jUG\u0000\u0000jVG\u0000\u0000jWG\u0000\u0000jXG\u0000\u0000jYG\u0000\u0000jZG\u0000\u0000j[G\u0000\u0000j\\G\u0000\u0000j]G\u0000\u0000j^G\u0000\u0000j_G\u0000\u0000j`G\u0000\u0000jaG\u0000\u0000jbG\u0000\u0000jcG\u0000\u0000jdG\u0000\u0000jeG\u0000\u0000jfG\u0000\u0000jgG\u0000\u0000jhG\u0000\u0000jiG\u0000\u0000jjG\u0000\u0000jkG\u0000\u0000jlG\u0000\u0000jmG\u0000\u0000jnG\u0000\u0000joG\u0000\u0000jpG\u0000\u0000jqG\u0000\u0000jrG\u0000\u0000jsG\u0000\u0000jtG\u0000\u0000juG\u0000\u0000jvG\u0000\u0000jwG\u0000\u0000jxG\u0000\u0000jyG\u0000\u0000jzG\u0000\u0000j{G\u0000\u0000j|G\u0000\u0000j}G\u0000\u0000j~G\u0000\u0000jG\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000e(j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j�G\u0000\u0000j\u0000H\u0000\u0000j\u0001H\u0000\u0000j\u0002H\u0000\u0000j\u0003H\u0000\u0000j\u0004H\u0000\u0000j\u0005H\u0000\u0000j\u0006H\u0000\u0000j\u0007H\u0000\u0000j\bH\u0000\u0000j\tH\u0000\u0000j\r\n",
      "H\u0000\u0000j\u000b",
      "H\u0000\u0000j\f",
      "H\u0000\u0000j\r",
      "H\u0000\u0000j\u000eH\u0000\u0000j\u000fH\u0000\u0000j\u0010H\u0000\u0000j\u0011H\u0000\u0000j\u0012H\u0000\u0000j\u0013H\u0000\u0000j\u0014H\u0000\u0000j\u0015H\u0000\u0000j\u0016H\u0000\u0000j\u0017H\u0000\u0000j\u0018H\u0000\u0000j\u0019H\u0000\u0000j\u001aH\u0000\u0000j\u001bH\u0000\u0000j\u001c",
      "H\u0000\u0000j\u001d",
      "H\u0000\u0000j\u001e",
      "H\u0000\u0000j\u001fH\u0000\u0000j H\u0000\u0000j!H\u0000\u0000j\"H\u0000\u0000j#H\u0000\u0000j$H\u0000\u0000j%H\u0000\u0000j&H\u0000\u0000j'H\u0000\u0000j(H\u0000\u0000j)H\u0000\u0000j*H\u0000\u0000j+H\u0000\u0000j,H\u0000\u0000j-H\u0000\u0000j.H\u0000\u0000j/H\u0000\u0000j0H\u0000\u0000j1H\u0000\u0000j2H\u0000\u0000j3H\u0000\u0000j4H\u0000\u0000j5H\u0000\u0000j6H\u0000\u0000j7H\u0000\u0000j8H\u0000\u0000j9H\u0000\u0000j:H\u0000\u0000j;H\u0000\u0000j<H\u0000\u0000j=H\u0000\u0000j>H\u0000\u0000j?H\u0000\u0000j@H\u0000\u0000jAH\u0000\u0000jBH\u0000\u0000jCH\u0000\u0000jDH\u0000\u0000jEH\u0000\u0000jFH\u0000\u0000jGH\u0000\u0000jHH\u0000\u0000jIH\u0000\u0000jJH\u0000\u0000jKH\u0000\u0000jLH\u0000\u0000jMH\u0000\u0000jNH\u0000\u0000jOH\u0000\u0000jPH\u0000\u0000jQH\u0000\u0000jRH\u0000\u0000jSH\u0000\u0000jTH\u0000\u0000jUH\u0000\u0000jVH\u0000\u0000jWH\u0000\u0000jXH\u0000\u0000jYH\u0000\u0000jZH\u0000\u0000j[H\u0000\u0000j\\H\u0000\u0000j]H\u0000\u0000j^H\u0000\u0000j_H\u0000\u0000j`H\u0000\u0000jaH\u0000\u0000jbH\u0000\u0000jcH\u0000\u0000jdH\u0000\u0000jeH\u0000\u0000jfH\u0000\u0000jgH\u0000\u0000jhH\u0000\u0000jiH\u0000\u0000jjH\u0000\u0000jkH\u0000\u0000jlH\u0000\u0000jmH\u0000\u0000jnH\u0000\u0000joH\u0000\u0000jpH\u0000\u0000jqH\u0000\u0000jrH\u0000\u0000jsH\u0000\u0000jtH\u0000\u0000juH\u0000\u0000jvH\u0000\u0000jwH\u0000\u0000jxH\u0000\u0000jyH\u0000\u0000jzH\u0000\u0000j{H\u0000\u0000j|H\u0000\u0000j}H\u0000\u0000j~H\u0000\u0000jH\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j�H\u0000\u0000j\u0000I\u0000\u0000j\u0001I\u0000\u0000j\u0002I\u0000\u0000j\u0003I\u0000\u0000j\u0004I\u0000\u0000j\u0005I\u0000\u0000j\u0006I\u0000\u0000j\u0007I\u0000\u0000j\bI\u0000\u0000j\tI\u0000\u0000j\r\n",
      "I\u0000\u0000j\u000b",
      "I\u0000\u0000j\f",
      "I\u0000\u0000j\r",
      "I\u0000\u0000j\u000eI\u0000\u0000j\u000fI\u0000\u0000j\u0010I\u0000\u0000j\u0011I\u0000\u0000j\u0012I\u0000\u0000j\u0013I\u0000\u0000j\u0014I\u0000\u0000j\u0015I\u0000\u0000j\u0016I\u0000\u0000j\u0017I\u0000\u0000j\u0018I\u0000\u0000j\u0019I\u0000\u0000j\u001aI\u0000\u0000j\u001bI\u0000\u0000j\u001c",
      "I\u0000\u0000j\u001d",
      "I\u0000\u0000j\u001e",
      "I\u0000\u0000j\u001fI\u0000\u0000j I\u0000\u0000j!I\u0000\u0000j\"I\u0000\u0000j#I\u0000\u0000j$I\u0000\u0000j%I\u0000\u0000j&I\u0000\u0000j'I\u0000\u0000j(I\u0000\u0000j)I\u0000\u0000j*I\u0000\u0000j+I\u0000\u0000j,I\u0000\u0000j-I\u0000\u0000j.I\u0000\u0000j/I\u0000\u0000j0I\u0000\u0000j1I\u0000\u0000j2I\u0000\u0000j3I\u0000\u0000j4I\u0000\u0000j5I\u0000\u0000j6I\u0000\u0000j7I\u0000\u0000j8I\u0000\u0000j9I\u0000\u0000j:I\u0000\u0000j;I\u0000\u0000j<I\u0000\u0000j=I\u0000\u0000j>I\u0000\u0000j?I\u0000\u0000j@I\u0000\u0000jAI\u0000\u0000jBI\u0000\u0000jCI\u0000\u0000jDI\u0000\u0000jEI\u0000\u0000jFI\u0000\u0000jGI\u0000\u0000jHI\u0000\u0000jII\u0000\u0000jJI\u0000\u0000jKI\u0000\u0000jLI\u0000\u0000jMI\u0000\u0000jNI\u0000\u0000jOI\u0000\u0000jPI\u0000\u0000jQI\u0000\u0000jRI\u0000\u0000jSI\u0000\u0000jTI\u0000\u0000jUI\u0000\u0000jVI\u0000\u0000jWI\u0000\u0000jXI\u0000\u0000jYI\u0000\u0000jZI\u0000\u0000j[I\u0000\u0000j\\I\u0000\u0000j]I\u0000\u0000j^I\u0000\u0000j_I\u0000\u0000j`I\u0000\u0000jaI\u0000\u0000jbI\u0000\u0000jcI\u0000\u0000jdI\u0000\u0000jeI\u0000\u0000jfI\u0000\u0000jgI\u0000\u0000jhI\u0000\u0000jiI\u0000\u0000jjI\u0000\u0000jkI\u0000\u0000jlI\u0000\u0000jmI\u0000\u0000jnI\u0000\u0000joI\u0000\u0000jpI\u0000\u0000jqI\u0000\u0000jrI\u0000\u0000jsI\u0000\u0000jtI\u0000\u0000juI\u0000\u0000jvI\u0000\u0000jwI\u0000\u0000jxI\u0000\u0000jyI\u0000\u0000jzI\u0000\u0000j{I\u0000\u0000j|I\u0000\u0000j}I\u0000\u0000j~I\u0000\u0000jI\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j�I\u0000\u0000j\u0000J\u0000\u0000j\u0001J\u0000\u0000j\u0002J\u0000\u0000j\u0003J\u0000\u0000j\u0004J\u0000\u0000j\u0005J\u0000\u0000j\u0006J\u0000\u0000j\u0007J\u0000\u0000j\bJ\u0000\u0000j\tJ\u0000\u0000j\r\n",
      "J\u0000\u0000j\u000b",
      "J\u0000\u0000j\f",
      "J\u0000\u0000j\r",
      "J\u0000\u0000j\u000eJ\u0000\u0000j\u000fJ\u0000\u0000j\u0010J\u0000\u0000j\u0011J\u0000\u0000j\u0012J\u0000\u0000j\u0013J\u0000\u0000j\u0014J\u0000\u0000j\u0015J\u0000\u0000j\u0016J\u0000\u0000j\u0017J\u0000\u0000j\u0018J\u0000\u0000j\u0019J\u0000\u0000j\u001aJ\u0000\u0000j\u001bJ\u0000\u0000j\u001c",
      "J\u0000\u0000j\u001d",
      "J\u0000\u0000j\u001e",
      "J\u0000\u0000j\u001fJ\u0000\u0000j J\u0000\u0000j!J\u0000\u0000j\"J\u0000\u0000j#J\u0000\u0000j$J\u0000\u0000j%J\u0000\u0000j&J\u0000\u0000j'J\u0000\u0000j(J\u0000\u0000j)J\u0000\u0000j*J\u0000\u0000j+J\u0000\u0000j,J\u0000\u0000j-J\u0000\u0000j.J\u0000\u0000j/J\u0000\u0000j0J\u0000\u0000j1J\u0000\u0000j2J\u0000\u0000j3J\u0000\u0000j4J\u0000\u0000j5J\u0000\u0000j6J\u0000\u0000j7J\u0000\u0000j8J\u0000\u0000j9J\u0000\u0000j:J\u0000\u0000j;J\u0000\u0000j<J\u0000\u0000j=J\u0000\u0000j>J\u0000\u0000j?J\u0000\u0000j@J\u0000\u0000jAJ\u0000\u0000jBJ\u0000\u0000jCJ\u0000\u0000jDJ\u0000\u0000jEJ\u0000\u0000jFJ\u0000\u0000jGJ\u0000\u0000jHJ\u0000\u0000jIJ\u0000\u0000jJJ\u0000\u0000jKJ\u0000\u0000jLJ\u0000\u0000jMJ\u0000\u0000jNJ\u0000\u0000jOJ\u0000\u0000jPJ\u0000\u0000jQJ\u0000\u0000jRJ\u0000\u0000jSJ\u0000\u0000jTJ\u0000\u0000jUJ\u0000\u0000jVJ\u0000\u0000jWJ\u0000\u0000jXJ\u0000\u0000jYJ\u0000\u0000jZJ\u0000\u0000j[J\u0000\u0000j\\J\u0000\u0000j]J\u0000\u0000j^J\u0000\u0000j_J\u0000\u0000j`J\u0000\u0000jaJ\u0000\u0000jbJ\u0000\u0000jcJ\u0000\u0000jdJ\u0000\u0000jeJ\u0000\u0000jfJ\u0000\u0000jgJ\u0000\u0000jhJ\u0000\u0000jiJ\u0000\u0000jjJ\u0000\u0000jkJ\u0000\u0000jlJ\u0000\u0000jmJ\u0000\u0000jnJ\u0000\u0000joJ\u0000\u0000jpJ\u0000\u0000jqJ\u0000\u0000jrJ\u0000\u0000jsJ\u0000\u0000jtJ\u0000\u0000juJ\u0000\u0000jvJ\u0000\u0000jwJ\u0000\u0000jxJ\u0000\u0000jyJ\u0000\u0000jzJ\u0000\u0000j{J\u0000\u0000j|J\u0000\u0000j}J\u0000\u0000j~J\u0000\u0000jJ\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j�J\u0000\u0000j\u0000K\u0000\u0000j\u0001K\u0000\u0000j\u0002K\u0000\u0000j\u0003K\u0000\u0000j\u0004K\u0000\u0000j\u0005K\u0000\u0000j\u0006K\u0000\u0000j\u0007K\u0000\u0000j\bK\u0000\u0000j\tK\u0000\u0000j\r\n",
      "K\u0000\u0000j\u000b",
      "K\u0000\u0000j\f",
      "K\u0000\u0000j\r",
      "K\u0000\u0000j\u000eK\u0000\u0000j\u000fK\u0000\u0000j\u0010K\u0000\u0000j\u0011K\u0000\u0000j\u0012K\u0000\u0000j\u0013K\u0000\u0000j\u0014K\u0000\u0000j\u0015K\u0000\u0000j\u0016K\u0000\u0000j\u0017K\u0000\u0000j\u0018K\u0000\u0000j\u0019K\u0000\u0000j\u001aK\u0000\u0000j\u001bK\u0000\u0000j\u001c",
      "K\u0000\u0000j\u001d",
      "K\u0000\u0000j\u001e",
      "K\u0000\u0000j\u001fK\u0000\u0000j K\u0000\u0000j!K\u0000\u0000j\"K\u0000\u0000j#K\u0000\u0000j$K\u0000\u0000j%K\u0000\u0000j&K\u0000\u0000j'K\u0000\u0000j(K\u0000\u0000j)K\u0000\u0000j*K\u0000\u0000j+K\u0000\u0000j,K\u0000\u0000j-K\u0000\u0000j.K\u0000\u0000j/K\u0000\u0000j0K\u0000\u0000j1K\u0000\u0000j2K\u0000\u0000j3K\u0000\u0000j4K\u0000\u0000j5K\u0000\u0000j6K\u0000\u0000j7K\u0000\u0000j8K\u0000\u0000j9K\u0000\u0000j:K\u0000\u0000j;K\u0000\u0000j<K\u0000\u0000j=K\u0000\u0000j>K\u0000\u0000j?K\u0000\u0000j@K\u0000\u0000jAK\u0000\u0000jBK\u0000\u0000jCK\u0000\u0000jDK\u0000\u0000jEK\u0000\u0000jFK\u0000\u0000jGK\u0000\u0000jHK\u0000\u0000jIK\u0000\u0000jJK\u0000\u0000jKK\u0000\u0000jLK\u0000\u0000jMK\u0000\u0000jNK\u0000\u0000jOK\u0000\u0000jPK\u0000\u0000jQK\u0000\u0000jRK\u0000\u0000jSK\u0000\u0000jTK\u0000\u0000jUK\u0000\u0000jVK\u0000\u0000jWK\u0000\u0000jXK\u0000\u0000jYK\u0000\u0000jZK\u0000\u0000j[K\u0000\u0000j\\K\u0000\u0000j]K\u0000\u0000j^K\u0000\u0000j_K\u0000\u0000j`K\u0000\u0000jaK\u0000\u0000jbK\u0000\u0000jcK\u0000\u0000jdK\u0000\u0000jeK\u0000\u0000jfK\u0000\u0000jgK\u0000\u0000jhK\u0000\u0000jiK\u0000\u0000jjK\u0000\u0000jkK\u0000\u0000jlK\u0000\u0000jmK\u0000\u0000jnK\u0000\u0000joK\u0000\u0000jpK\u0000\u0000jqK\u0000\u0000jrK\u0000\u0000jsK\u0000\u0000jtK\u0000\u0000juK\u0000\u0000jvK\u0000\u0000jwK\u0000\u0000jxK\u0000\u0000jyK\u0000\u0000jzK\u0000\u0000j{K\u0000\u0000j|K\u0000\u0000j}K\u0000\u0000j~K\u0000\u0000jK\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000e(j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j�K\u0000\u0000j\u0000L\u0000\u0000j\u0001L\u0000\u0000j\u0002L\u0000\u0000j\u0003L\u0000\u0000j\u0004L\u0000\u0000j\u0005L\u0000\u0000j\u0006L\u0000\u0000j\u0007L\u0000\u0000j\bL\u0000\u0000j\tL\u0000\u0000j\r\n"
     ]
    }
   ],
   "source": [
    "!head /Users/stearb/Desktop/R03_local/data/use_config/OUTPUT_FILES/test_concat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = pd.read_pickle('/Users/stearb/Desktop/R03_local/data/use_config/OUTPUT_FILES/HUBMAPsc/hubmap_CUI_CUIs.pickle')\n",
    "#f.to_csv('/Users/stearb/Desktop/R03_local/data/use_config/OUTPUT_FILES/HUBMAPsc/hubmap_CUI_CUIs.csv',index=False)\n",
    "#pd.read_csv('/Users/stearb/Desktop/R03_local/data/use_config/OUTPUT_FILES/HUBMAPsc/hubmap_CUI_CUIs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# pickle version\n",
    "with open(output_dir+'test_concat.pickle',\"wb\") as fout:\n",
    "    # first file:\n",
    "    with open(cui_cui_paths[0], \"rb\") as f:\n",
    "        fout.write(f.read())\n",
    "    # now the rest:    \n",
    "    for FILE in cui_cui_paths[2:]:\n",
    "        with open(FILE, \"rb\") as f:\n",
    "            next(f) # skip the header\n",
    "            fout.write(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.23 s, sys: 34 s, total: 38.2 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# csv version\n",
    "\n",
    "with open(output_dir+'test_concat.csv',\"wb\") as fout:\n",
    "    # first file:\n",
    "    with open(cui_cui_paths_csv[0], \"rb\") as f:\n",
    "        fout.write(f.read())\n",
    "    # now the rest:    \n",
    "    for FILE in cui_cui_paths_csv[1:]:\n",
    "        with open(FILE, \"rb\") as f:\n",
    "            next(f) # skip the header\n",
    "            fout.write(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv(output_dir+'test_concat.csv')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "      <th>SAB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0694879</td>\n",
       "      <td>SENPUCBIQ09QOkV4dDI=</td>\n",
       "      <td>has_mouse_ortholog</td>\n",
       "      <td>HGNC__HGNC_HCOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1332096</td>\n",
       "      <td>SENPUCBIQ09QOkFueGE4</td>\n",
       "      <td>has_mouse_ortholog</td>\n",
       "      <td>HGNC__HGNC_HCOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1332123</td>\n",
       "      <td>SENPUCBIQ09QOkF2cHIxYg==</td>\n",
       "      <td>has_mouse_ortholog</td>\n",
       "      <td>HGNC__HGNC_HCOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1332682</td>\n",
       "      <td>SENPUCBIQ09QOkNjbDE5</td>\n",
       "      <td>has_mouse_ortholog</td>\n",
       "      <td>HGNC__HGNC_HCOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1332682</td>\n",
       "      <td>SENPUCBIQ09QOkdtMjU2NA==</td>\n",
       "      <td>has_mouse_ortholog</td>\n",
       "      <td>HGNC__HGNC_HCOP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16739089</th>\n",
       "      <td>YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...</td>\n",
       "      <td>c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...</td>\n",
       "      <td>has_single_cell_expression</td>\n",
       "      <td>scHeart__cellType</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16739090</th>\n",
       "      <td>YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...</td>\n",
       "      <td>c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...</td>\n",
       "      <td>has_single_cell_expression</td>\n",
       "      <td>scHeart__cellType</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16739091</th>\n",
       "      <td>YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...</td>\n",
       "      <td>c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...</td>\n",
       "      <td>has_single_cell_expression</td>\n",
       "      <td>scHeart__cellType</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16739092</th>\n",
       "      <td>YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...</td>\n",
       "      <td>c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...</td>\n",
       "      <td>has_single_cell_expression</td>\n",
       "      <td>scHeart__cellType</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16739093</th>\n",
       "      <td>YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...</td>\n",
       "      <td>c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...</td>\n",
       "      <td>has_single_cell_expression</td>\n",
       "      <td>scHeart__cellType</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16739094 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  :START_ID  \\\n",
       "0                                                  C0694879   \n",
       "1                                                  C1332096   \n",
       "2                                                  C1332123   \n",
       "3                                                  C1332682   \n",
       "4                                                  C1332682   \n",
       "...                                                     ...   \n",
       "16739089  YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...   \n",
       "16739090  YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...   \n",
       "16739091  YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...   \n",
       "16739092  YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...   \n",
       "16739093  YXV0aG9yX2RlZmluZWRfY2x1c3RlcjpGaWJyb2JsYXN0LW...   \n",
       "\n",
       "                                                    :END_ID  \\\n",
       "0                                      SENPUCBIQ09QOkV4dDI=   \n",
       "1                                      SENPUCBIQ09QOkFueGE4   \n",
       "2                                  SENPUCBIQ09QOkF2cHIxYg==   \n",
       "3                                      SENPUCBIQ09QOkNjbDE5   \n",
       "4                                  SENPUCBIQ09QOkdtMjU2NA==   \n",
       "...                                                     ...   \n",
       "16739089  c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...   \n",
       "16739090  c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...   \n",
       "16739091  c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...   \n",
       "16739092  c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...   \n",
       "16739093  c2NIZWFydCBQTUlEOiAzMTgzNTAzNyBGaWJyb2JsYXN0LW...   \n",
       "\n",
       "                               :TYPE                SAB  \n",
       "0                 has_mouse_ortholog    HGNC__HGNC_HCOP  \n",
       "1                 has_mouse_ortholog    HGNC__HGNC_HCOP  \n",
       "2                 has_mouse_ortholog    HGNC__HGNC_HCOP  \n",
       "3                 has_mouse_ortholog    HGNC__HGNC_HCOP  \n",
       "4                 has_mouse_ortholog    HGNC__HGNC_HCOP  \n",
       "...                              ...                ...  \n",
       "16739089  has_single_cell_expression  scHeart__cellType  \n",
       "16739090  has_single_cell_expression  scHeart__cellType  \n",
       "16739091  has_single_cell_expression  scHeart__cellType  \n",
       "16739092  has_single_cell_expression  scHeart__cellType  \n",
       "16739093  has_single_cell_expression  scHeart__cellType  \n",
       "\n",
       "[16739094 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.91 s, sys: 1.11 s, total: 4.02 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np_concat = np.concatenate([CUI_CUI_ortho.values,\n",
    "                                    CUI_CUI_genopheno,\n",
    "                                    CUI_CUI_mp,\n",
    "                                    CUI_CUI_phenomap,\n",
    "                                    CUI_CUI_gtex, \n",
    "                                    CUI_CUI_kf, \n",
    "                                    CUI_CUI_scHeart,\n",
    "                                    CUI_CUI_hgnc_hpo, # CUI_CUI_dbsnp\n",
    "                                    CUI_CUI_hubmap\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 1.44 s, total: 6.14 s\n",
      "Wall time: 6.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_np_concat = pd.DataFrame(np_concat,columns=[':START_ID',':END_ID',':TYPE','SAB']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 13 s, total: 1min 36s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CUI_CUIs_all = pd.DataFrame(np.concatenate([CUI_CUI_ortho.values,\n",
    "                                            CUI_CUI_genopheno,\n",
    "                                            CUI_CUI_mp,\n",
    "                                            CUI_CUI_phenomap,\n",
    "                                            CUI_CUI_gtex, \n",
    "                                            CUI_CUI_kf, \n",
    "                                            CUI_CUI_scHeart,\n",
    "                                            CUI_CUI_hgnc_hpo, # CUI_CUI_dbsnp\n",
    "                                            CUI_CUI_hubmap\n",
    "                                            ]),\n",
    "                                                columns=[':START_ID',':END_ID',':TYPE','SAB']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why HGNC HCOP and HGNC HCOP//MP ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'HGNC__HGNC_HCOP': 132312,\n",
       "         'IMPC': 510680,\n",
       "         'MP': 33294,\n",
       "         'HPO__MP': 2428,\n",
       "         'GTEX_EXP__HGNC': 3947664,\n",
       "         'GTEX_EXP__UBERON': 3947664,\n",
       "         'GTEX_EQTL__HGNC': 1762790,\n",
       "         'GTEX_EQTL__UBERON': 2321876,\n",
       "         'GTEX_EQTL__DBSNP_151': 2321876,\n",
       "         'KF_HPO': 27388,\n",
       "         'scHeart__HGNC': 5632,\n",
       "         'scHeart__cellType': 5632,\n",
       "         'HGNC__HPO': 1717940,\n",
       "         'HUBMAP__HGNC': 21863490,\n",
       "         'HUBMAP__CLUSTER': 21863490,\n",
       "         'HUBMAP_DATASET__TISSUE': 934,\n",
       "         'HUBMAP_DONOR__HUBMAP_DATSET': 126,\n",
       "         'HUBMAP_CLUSTER__HUBMAP_DATASET': 1792,\n",
       "         'HUBMAP_DATASET__SEX': 126,\n",
       "         'HUBMAP_DATASET__RACE': 130,\n",
       "         'HUBMAP_DATASET__BMI': 126,\n",
       "         'HUBMAP_DATASET__BLOOD_TYPE': 82,\n",
       "         'HUBMAP_DATASET__CAUSE_OF_DEATH': 108,\n",
       "         'HUBMAP_DATASET__MECHANISM_OF_INJURY': 100,\n",
       "         'HUBMAP_DATASET__DEATH_EVENT': 100,\n",
       "         'HUBMAP_DATASET__MEDICAL_HISTORY': 128,\n",
       "         'HUBMAP_DATASET__SOCIAL_HISTORY': 46})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(CUI_CUIs_all['SAB']) # dont change inverse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and combine all CUI-CODEs files  (its actually CUI-CodeID)\n",
    "Cols = 'CUI', 'CODE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUI-Codes took 0.8091420491536458 minutes\n"
     ]
    }
   ],
   "source": [
    "# chnage thename of these to CUI_CODEs\n",
    "t0 = time.time()\n",
    "\n",
    "#Load mouse ortholog CODEs\n",
    "CUI_CODEs_ortho = pd.read_pickle(output_dir+'orthologs/CUI_CODE_ortho.pickle')\n",
    "\n",
    "# Load mouse phenotype CUI-CODEs\n",
    "CUI_CODEs_genopheno = pd.read_pickle(output_dir+'genopheno/CUI_CODE_genotype.pickle')\n",
    "\n",
    "# Load mammalian phenotype ontology CUI-CODEs\n",
    "CUI_CODEs_mp = pd.read_pickle(output_dir+'MPO/CUI_CODEs_mp_ont.pickle')  \n",
    "\n",
    "# Load phenomapping CUI-CODEs \n",
    "CUI_CODEs_phenomap = pd.read_csv(output_dir+'hpo_mp_mapping/CUI_CODEs_phenomapping.csv')\n",
    "\n",
    "#  GTEx CUI CODEs (eQTLs and median gene expression)  \n",
    "CUI_CODEs_gtex = pd.read_pickle(output_dir+'GTEx/CUI_CODEs_GTEx.pickle')\n",
    "\n",
    "# dbSNP CUI-CODEs\n",
    "#CUI_CODEs_dbsnp = pd.read_csv(LOCAL_PATH+'dbsnp/CUI_CODEs_dbsnp.csv')\n",
    "\n",
    "# hgncAnnos CUI-CODEs, (HGNC CUIs-GL_CODEs)\n",
    "CUI_CODEs_hgncAnnos =  pd.read_csv(output_dir+'hgnc_annos/CUI_CODEs_hgncAnno.csv')\n",
    "\n",
    "# kf phenotypes CUI-CODES\n",
    "CUI_CODES_kf = pd.read_csv(output_dir+'kf_phenotypes/CUI_CODEs_kf.csv')\n",
    "\n",
    "# scHeart CUI-CODES\n",
    "CUI_CODES_scHeart = pd.read_csv(output_dir+'scHeart/CUI_CODEs_scHeart.csv')\n",
    "\n",
    "# Hubmap \n",
    "CUI_CODEs_hubmap = pd.read_pickle(output_dir+'HUBMAPsc/hubmap_CUIs_CODEs.pickle')\n",
    "\n",
    "\n",
    "# The only CUI-CODEs file that doesnt have the same number of unique values in each column (aka a 1 to 1 mapping) \n",
    "# is the CODEs_phenomap file because it contains HPO CUI-Code mappings from  UMLS which are not always 1 to 1, meaning\n",
    "# some HPO Concepts nodes map to more than one HPO Code nodes.\n",
    "\n",
    "#  Select the CUI and CodeID columns\n",
    "CUI_CODEs_all = pd.DataFrame(np.concatenate([CUI_CODEs_ortho.values, \n",
    "                                         CUI_CODEs_mp.values, \n",
    "                                         CUI_CODEs_gtex.values,\n",
    "                                         CUI_CODEs_genopheno.values,\n",
    "                                         CUI_CODEs_phenomap.values, \n",
    "                                         CUI_CODEs_hgncAnnos.values,\n",
    "                                         CUI_CODES_kf.values,\n",
    "                                         CUI_CODES_scHeart.values,  #   CUI_CODEs_dbsnp.values\n",
    "                                         CUI_CODEs_hubmap.values\n",
    "                                       ]), columns=[':START_ID',':END_ID']).drop_duplicates()\n",
    "\n",
    "print('CUI-Codes took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all CODEs into one file.\n",
    "cols: CodeID, SAB, CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codes took 0.7405983487764994 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "\n",
    "#Load mouse ortholog CODEs\n",
    "CODEs_ortho = pd.read_pickle(output_dir+'orthologs/CODE_mouse_ortho.pickle')\n",
    "\n",
    "# Load mouse phenotype CODEs\n",
    "CODEs_genopheno = pd.read_pickle(output_dir+'genopheno/CODEs_genotype.pickle')\n",
    "\n",
    "# Load mammalian phenotype ontology CODEs\n",
    "CODEs_mp = pd.read_pickle(output_dir+'MPO/CODEs_mp_ont.pickle')    \n",
    "\n",
    "# Load phenomapping CODEs \n",
    "CODEs_phenomap = pd.read_csv(output_dir+'hpo_mp_mapping/CODEs_phenomapping.csv')\n",
    "\n",
    "# Load GTEx (eqtl and med. gene CODEs)\n",
    "CODEs_gtex = pd.read_pickle(output_dir+'GTEx/CODEs_GTEx.pickle')   \n",
    "\n",
    "# dbSNP CODEs\n",
    "#CODEs_dbsnp = pd.read_csv(LOCAL_PATH+'dbsnp/CODEs_dbsnp.csv')   \n",
    "\n",
    "CODEs_hgncAnnos = pd.read_csv(output_dir+'hgnc_annos/CODEs_hgncAnno.csv')  \n",
    "\n",
    "\n",
    "# kf phenotype CODEs\n",
    "CODEs_kf = pd.read_csv(output_dir+'kf_phenotypes/CODEs_kf.csv') \n",
    "\n",
    "# scHeart CODEs\n",
    "CODEs_scHeart = pd.read_csv(output_dir+'scHeart/CODEs_scHeart.csv') \n",
    "\n",
    "# Hubmap \n",
    "CODEs_hubmap = pd.read_pickle(output_dir+'HUBMAPsc/hubmap_CODEs.pickle')\n",
    "\n",
    "\n",
    "CODEs_all = pd.DataFrame(np.concatenate([CODEs_ortho.values, \n",
    "                                         CODEs_genopheno.values,\n",
    "                                         CODEs_mp.values, \n",
    "                                         CODEs_phenomap.values,\n",
    "                                        CODEs_gtex.values, # CODEs_dbsnp.values\n",
    "                                         CODEs_hgncAnnos.values,\n",
    "                                         CODEs_kf.values,\n",
    "                                         CODEs_scHeart.values,\n",
    "                                         CODEs_hubmap.values\n",
    "                                        ]),\n",
    "                                     columns=['CodeID:ID','SAB','CODE']).drop_duplicates()\n",
    "\n",
    "print('Codes took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST FIX FORMATTING OF THESE SABs ( should not have any spaces)\n",
    "#Counter(CODEs_all['SAB']).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(CODEs_hubmap['SAB']).most_common()\n",
    "\n",
    " #Why only 23 unique donors out of 63 datasets?\n",
    "# sum(hubmap)\tsum(hubmap_cluster)\tsum(hubmap_dataset)\tsum(hubmap_donor)\n",
    "# 10931745\t   896\t                   63\t          23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all Terms (SUIs) into one file\n",
    "Columns: SUI:ID, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUIs took 0.07345730463663737 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Load Ortholog SUIs\n",
    "SUIs_ortho = pd.read_pickle(output_dir+'orthologs/SUIs_ortho.pickle')\n",
    "\n",
    "# Load mammalian phenotype ontology SUIs\n",
    "SUIs_mp = pd.read_pickle(output_dir+'MPO/SUIs_mp_ont.pickle')\n",
    "SUIs_mp.rename(columns={'SUI':'SUI:ID','Term':'name'},inplace=True) \n",
    "\n",
    "\n",
    "# Load GTEx SUIs\n",
    "SUIs_gtex = pd.read_pickle(output_dir+'GTEx/SUIs_GTEx.pickle')\n",
    "SUIs_gtex['name'] = SUIs_gtex['name'].astype(str)\n",
    "\n",
    "# dbSNP SUIs\n",
    "#SUIs_dbsnp = pd.read_csv(LOCAL_PATH+'dbsnp/SUIs_dbsnp.csv')\n",
    "\n",
    "# hgnc_annotation SUIs, only adding  the '+' and '-' strand Terms\n",
    "SUIs_hgncAnno = pd.read_csv(output_dir+'hgnc_annos/SUIs_hgncAnnos.csv')\n",
    "\n",
    "# glygen glycosyltransferase/glycan annotations (on genes)\n",
    "SUIs_glygenAnno = pd.read_csv(output_dir+'glygen_annos/SUIs_glygenAnnos.csv')\n",
    "\n",
    "# scHeart SUIs\n",
    "SUIs_scHeart = pd.read_csv(output_dir+'scHeart/SUIs_scHeart.csv')\n",
    "\n",
    "SUIs_all = pd.concat([SUIs_ortho,\n",
    "                      SUIs_gtex, \n",
    "                      SUIs_mp,\n",
    "                      SUIs_hgncAnno,\n",
    "                      SUIs_glygenAnno,\n",
    "                      SUIs_scHeart]) \n",
    "\n",
    "\n",
    "SUIs_all.drop_duplicates('name',inplace=True)\n",
    "SUIs_all.drop_duplicates('SUI:ID',inplace=True)\n",
    "\n",
    "# Check that all SUI:IDs are in the same format (same length)\n",
    "#SUIs_all_len = [len(i) for i in SUIs_all['SUI:ID']]  # Some of the SUIs are from UMLS so they have length 8 or 9\n",
    "#assert len(np.unique(SUIs_all_len)) ==  1 # lengths will not be the same using the base 64 method\n",
    "assert 0 == len(SUIs_all[SUIs_all['SUI:ID'].duplicated()])\n",
    "\n",
    "print('SUIs took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the CODE-SUIs into one file\n",
    "cols = :START_ID, :END_ID, :TYPE, CUI\n",
    ":START_ID = CodeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE-SUIs took 0.38557483355204264 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "\n",
    "# Ortholog  CODE-SUIs\n",
    "CODE_SUI_ortho = pd.read_pickle(output_dir+'orthologs/CODE_SUI_ortho.pickle')\n",
    "\n",
    "# Load Mammalian Phenotype CODE-SUIs\n",
    "CODE_SUIs_mp = pd.read_pickle(output_dir+'MPO/CODE_SUIs_mp_ont.pickle')\n",
    "\n",
    "# Load GTEx CODE-SUIs\n",
    "CODE_SUIs_GTEX = pd.read_pickle(output_dir+'GTEx/CODE_SUIs_GTEx.pickle')\n",
    "\n",
    "# Load dbsnp CODE-SUIs\n",
    "#CODE_SUIs_dbsnp = pd.read_csv(LOCAL_PATH+'dbsnp/CODE_SUIs_dbsnp.csv')\n",
    "\n",
    "#  Load hgnc_annotation CODE-SUIs\n",
    "CODE_SUIs_hgncAnno = pd.read_csv(output_dir+'hgnc_annos/CODE_SUIs_hgncAnnos.csv') \n",
    "\n",
    "\n",
    "# glygen CODE-SUIs glycosyltransferase/glycan annotations (on genes)\n",
    "CODE_SUIs_glygenAnno = pd.read_csv(output_dir+'glygen_annos/CODE_SUIs_glygenAnnos.csv') \n",
    "\n",
    "\n",
    "#  Load scHeart CODE-SUIs\n",
    "CODE_SUIs_scHeart = pd.read_csv(output_dir+'scHeart/CODE_SUIs_scHeart.csv') \n",
    "\n",
    "# Hubmap \n",
    "CODE_SUIs_hubmap = pd.read_pickle(output_dir+'HUBMAPsc/hubmap_CODE_SUIs.pickle')\n",
    "\n",
    "CODE_SUIs_all = pd.concat([CODE_SUI_ortho,CODE_SUIs_GTEX,CODE_SUIs_mp,\n",
    "                           CODE_SUIs_hgncAnno,\n",
    "                           CODE_SUIs_glygenAnno,\n",
    "                           CODE_SUIs_scHeart,CODE_SUIs_hubmap]) # \n",
    "\n",
    "assert CODE_SUIs_all.isna().sum().sum() == 0\n",
    "\n",
    "#  Assert No overlap\n",
    "assert set(CODE_SUIs_mp[':START_ID']) & set(CODE_SUIs_GTEX[':START_ID']) &  set(CODE_SUI_ortho[':START_ID']) == set()\n",
    "assert set(CODE_SUIs_mp[':END_ID']) & set(CODE_SUIs_GTEX[':END_ID']) &  set(CODE_SUI_ortho[':END_ID']) == set()\n",
    "\n",
    "print('CODE-SUIs took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of GTEX EQTL Terms\n",
    "#sum(CODE_SUIs_all[':START_ID'].str.startswith('GTEX_EQTL',na=False))\n",
    "# Find number of GTEX EXP Terms\n",
    "#sum(CODE_SUIs_all[':START_ID'].str.startswith('GTEX_EXP',na=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CUI-SUIs (from MP and Orthologs steps), need to add ortholog CUI-SUIs\n",
    "Columns = :START_ID, :END_ID  \n",
    "start = CUI, end = SUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HUBMAP CSVs once youve moved them from cluster to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUI:ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENPUCBIQ09QOkV4dDI=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENPUCBIQ09QOkFueGE4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENPUCBIQ09QOkF2cHIxYg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENPUCBIQ09QOkNjbDE5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENPUCBIQ09QOkdtMjU2NA==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952805</th>\n",
       "      <td>SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952806</th>\n",
       "      <td>SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952807</th>\n",
       "      <td>SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952808</th>\n",
       "      <td>SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952809</th>\n",
       "      <td>SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14919100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     CUI:ID\n",
       "0                                      SENPUCBIQ09QOkV4dDI=\n",
       "1                                      SENPUCBIQ09QOkFueGE4\n",
       "2                                  SENPUCBIQ09QOkF2cHIxYg==\n",
       "3                                      SENPUCBIQ09QOkNjbDE5\n",
       "4                                  SENPUCBIQ09QOkdtMjU2NA==\n",
       "...                                                     ...\n",
       "14952805  SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...\n",
       "14952806  SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...\n",
       "14952807  SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...\n",
       "14952808  SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...\n",
       "14952809  SFVCTUFQIENMVVNURVIgYmRmZWJiZmJiYWEzM2JmMWQyYT...\n",
       "\n",
       "[14919100 rows x 1 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertions took 1.4107109308242798 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "\n",
    "# Check that there are no surprise Nans, remove the Nans we know about ( just 2 in CODE_SUIs)\n",
    "assert CUIs_all.isna().sum().sum() == 0\n",
    "assert CUI_CUIs_all.isna().sum().sum() == 0\n",
    "assert CUI_CODEs_all.isna().sum().sum() == 0\n",
    "assert CODEs_all.isna().sum().sum() == 0\n",
    "assert SUIs_all.isna().sum().sum() == 0\n",
    "assert CODE_SUIs_all.isna().sum().sum() == 0\n",
    "\n",
    "print('Assertions took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Check that all CUIs in CUI-CUI and CUI-CODE are in CUI_all\n",
    "#a=CUI_CUIs_all[CUI_CUIs_all[':START_ID'].str.contains('KC')] # filter for  only  the  'KC' CUIs\n",
    "#b= a[a[':END_ID'].str.contains('KC')]      # filter for  only  the  'KC' CUIs\n",
    "\n",
    "#assert np.all(b[':START_ID'].isin(CUIs_all['CUI:ID']))  # all :START_ID CUIs are  in master  CUI list\n",
    "#assert np.all(b[':END_ID'].isin(CUIs_all['CUI:ID']))  # all :END_ID CUIs are  in master  CUI list\n",
    "\n",
    "\n",
    "######  Make sure there is 100% overlap b/t CodeID from CUI_CODEs_all and  CodeIDs from CODEs_all\n",
    "#codeIDs_in = CUI_CODEs_all[CUI_CODEs_all[':END_ID'].isin(CODEs_all['CodeID:ID'])]\n",
    "codeIDs_not_in = CUI_CODEs_all[~CUI_CODEs_all[':END_ID'].isin(CODEs_all['CodeID:ID'])]  # which CODEs are/arent  in CODEs_all?\n",
    "\n",
    "assert  len(codeIDs_not_in)  == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all CodeIDs in CUI_CODEs are in CODEs_all\n",
    "#codes_check = CUI_CODEs_all[':END_ID']  #  CODEs are in  the  :END_ID column\n",
    "#codes_check.isin(CODEs_all['CodeID:ID']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the UMLS files and concatenate ours to them\n",
    "UMLS CSV files are in the 'new_build_csv_data' folder  (new build refers to the UMLS version with UBERON & CL included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 ###################################################################################\n",
    "from multiprocessing import Pool\n",
    "#import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UMLS_CODEs_SUIs[UMLS_CODEs_SUIs.isnull().any(axis=1)]\n",
    "#UMLS_CODEs_SUIs[UMLS_CODEs_SUIs['CUI'] == 'dG9waWMgMzY1Ng==']#[':END_ID'][9912137]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count()\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stearb/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def save_csv(t):\n",
    "    t[0].to_csv(t[1])\n",
    "    print('finished writing'+t[1],chunksize=1000000)\n",
    "    \n",
    "def read_csv(filename):\n",
    "    'converts a filename to a pandas dataframe'\n",
    "    return pd.read_csv(filename,na_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=6000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 24s, sys: 52.2 s, total: 7min 16s\n",
      "Wall time: 7min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CUIs_all.to_csv(umls_dir+'delete_cuiall.csv',chunksize=chunksize)\n",
    "CUI_CUIs_all.to_csv(umls_dir+'delete_cuicuiall.csv',chunksize=chunksize)\n",
    "CUI_CODEs_all.to_csv(umls_dir+'delete_cuicodeall.csv',chunksize=chunksize)\n",
    "CODEs_all.to_csv(umls_dir+'delete_codesall.csv',chunksize=chunksize)    \n",
    "\n",
    "# Wall time: 8min 11s,   \n",
    "# Wall time: 7min 58s w/ chunksize=1mil\n",
    "# Wall time: 7min 47s w/ chunksize=2mil\n",
    "# Wall time: 7min 46s w/ chunksize=4mil\n",
    "# Wall time: 7min 45s w/ chunksize=6mil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14958042"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CUI_CODEs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 52s, sys: 1min 8s, total: 13min\n",
      "Wall time: 12min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 7min 48s w chunksize = 200k, 8 workers\n",
    "# Wall time: 8min 3s w chunksize = 200k, 4 workers\n",
    "file_list_to_save = [ [CUIs_all,umls_dir+'delete_cuiall.csv'],\n",
    "                       [CUI_CUIs_all,umls_dir+'delete_cuicuiall.csv'],\n",
    "                     [CUI_CODEs_all,umls_dir+'delete_cuicodeall.csv'],\n",
    "                     [CODEs_all,umls_dir+'delete_codesall.csv']]\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as threads:\n",
    "    df_list = threads.map(save_csv, file_list_to_save)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stearb/opt/anaconda3/lib/python3.7/concurrent/futures/thread.py:57: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  result = self.fn(*self.args, **self.kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.9 s, sys: 11 s, total: 1min 4s\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor() as threads:\n",
    "    df_list = threads.map(read_csv, file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/stearb/Desktop/hubmap-kg/FREEZE/CUIs.csv',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs.csv']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_list\n",
    "\n",
    "file_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [umls_dir+'CUIs.csv',umls_dir+'CUI-CUIs.csv',umls_dir+'CODEs.csv',\n",
    "             umls_dir+'CUI-CODEs.csv',umls_dir+'SUIs.csv',umls_dir+ 'CODE-SUIs.csv',umls_dir+'CUI-SUIs.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#UMLS_CUIs = pd.read_csv(umls_dir+'CUIs.csv')\n",
    "#UMLS_CUI_CUIs = pd.read_csv(umls_dir+'CUI-CUIs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#UMLS_CUIs = dd.read_csv(umls_dir+'CUIs.csv')\n",
    "#UMLS_CUI_CUIs = dd.read_csv(umls_dir+'CUI-CUIs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stearb/opt/anaconda3/lib/python3.7/site-packages/dask/utils.py:29: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UMLS files w/ Dask took 0.9900113940238953 minutes\n",
      "CPU times: user 1min, sys: 12.9 s, total: 1min 13s\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time.time()\n",
    "\n",
    "UMLS_CUIs = dd.read_csv(umls_dir+'CUIs.csv').compute()\n",
    "\n",
    "UMLS_CUI_CUIs = dd.read_csv(umls_dir+'CUI-CUIs.csv').compute()\n",
    "\n",
    "UMLS_CODEs = dd.read_csv(umls_dir+'CODEs.csv').compute()\n",
    "\n",
    "UMLS_CUI_CODEs = dd.read_csv(umls_dir+'CUI-CODEs.csv').compute()\n",
    "\n",
    "UMLS_SUIs  = dd.read_csv(umls_dir+'SUIs.csv').compute()\n",
    "\n",
    "# Need to use na_filter = False to prevent the :TYPE 'NA' from being cast to NaN\n",
    "UMLS_CODEs_SUIs  = dd.read_csv(umls_dir+ 'CODE-SUIs.csv',na_filter = False).compute()\n",
    "\n",
    "# Drop rows that contain empty string, ('').\n",
    "UMLS_CODEs_SUIs = UMLS_CODEs_SUIs[UMLS_CODEs_SUIs[':END_ID'].astype(bool)]\n",
    "\n",
    "UMLS_CUI_SUIs = dd.read_csv(umls_dir+'CUI-SUIs.csv').compute()\n",
    "\n",
    "print('Loading UMLS files w/ Dask took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 6.82 s, total: 1min 44s\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/00.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/01.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/02.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/03.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/04.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/05.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/06.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/07.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/08.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/09.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/10.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/11.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/12.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/13.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/14.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/15.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/16.part',\n",
       " '/Users/stearb/Desktop/hubmap-kg/FREEZE/CUI-CUIs_2.csv/17.part']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# its slower to save a dask df than it is to save a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 5.15 s, total: 58.4 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "UMLS_CUIs.to_csv(umls_dir+'CUIs.csv')\n",
    "\n",
    "UMLS_CUI_CUIs.to_csv(umls_dir+'CUI-CUIs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 ##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These must be csvs, unless we store them someplace else and pickle them in and dsave as csvs in freeze import folder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UMLS files took 1.0659369985262552 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "\n",
    "UMLS_CUIs = pd.read_pickle(umls_dir+'CUIs.pickle')\n",
    "\n",
    "UMLS_CUI_CUIs = pd.read_pickle(umls_dir+'CUI-CUIs.pickle')\n",
    "\n",
    "UMLS_CODEs = pd.read_pickle(umls_dir+'CODEs.pickle')\n",
    "\n",
    "UMLS_CUI_CODEs = pd.read_pickle(umls_dir+'CUI-CODEs.pickle')\n",
    "\n",
    "UMLS_SUIs = pd.read_pickle(umls_dir+'SUIs.pickle')\n",
    "\n",
    "# Need to use na_filter = False to prevent the :TYPE 'NA' from being cast to NaN\n",
    "UMLS_CODEs_SUIs = pd.read_pickle(umls_dir+ 'CODE-SUIs.pickle')#,na_filter = False) \n",
    "\n",
    "# Drop rows that contain empty string, ('').\n",
    "UMLS_CODEs_SUIs = UMLS_CODEs_SUIs[UMLS_CODEs_SUIs[':END_ID'].astype(bool)]\n",
    "\n",
    "UMLS_CUI_SUIs = pd.read_pickle(umls_dir+'CUI-SUIs.pickle')\n",
    "\n",
    "print('Loading UMLS files took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating files took 3.1958942492802938 minutes\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "\n",
    "concat_CUIs = pd.concat([UMLS_CUIs.drop_duplicates(),CUIs_all])\n",
    "\n",
    "concat_CUI_CUIs = pd.concat([UMLS_CUI_CUIs.drop_duplicates(),CUI_CUIs_all])\n",
    "\n",
    "concat_CODEs =  pd.concat([UMLS_CODEs.drop_duplicates(),CODEs_all])\n",
    "\n",
    "concat_CUI_CODEs  = pd.concat([UMLS_CUI_CODEs.drop_duplicates(),CUI_CODEs_all])\n",
    "\n",
    "concat_SUIs = pd.concat([UMLS_SUIs.drop_duplicates(),SUIs_all])\n",
    "\n",
    "concat_CODE_SUIs = pd.concat([UMLS_CODEs_SUIs.drop_duplicates(),CODE_SUIs_all])\n",
    "\n",
    "#concat_CUI_SUIs = pd.concat([UMLS_CUI_SUIs,CUI_SUIs_all]) \n",
    "print('Concatenating files took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [(UMLS_CUIs.drop_duplicates(),CUIs_all),\n",
    "(UMLS_CUI_CUIs.drop_duplicates(),CUI_CUIs_all),\n",
    "(UMLS_CODEs.drop_duplicates(),CODEs_all),\n",
    "(UMLS_CUI_CODEs.drop_duplicates(),CUI_CODEs_all),\n",
    "(UMLS_SUIs.drop_duplicates(),SUIs_all),\n",
    "(UMLS_CODEs_SUIs.drop_duplicates(),CODE_SUIs_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "'i' format requires -2147483648 <= number <= 2147483647",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    429\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# For wire compatibility with 3.2 and lower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m16384\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# The payload is large so Nagle's algorithm won't be triggered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: 'i' format requires -2147483648 <= number <= 2147483647"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def concat_func(t):\n",
    "    return pd.concat([t(0),t(1)])\n",
    "\n",
    "# set up your pool\n",
    "with Pool(processes=8) as pool: # or whatever your hardware can support\n",
    "\n",
    "    # have your pool map the file names to dataframes\n",
    "    df_list = pool.map(concat_func, dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is already a '+' Term node in  UMLS! Now we have 2... KS73770739369183 and S0782579.  S0782579 is not a 'strandedness' Term though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the final version of the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated workflow (Using configuration file for loading and saving data)\n",
    "t0 = time.time()\n",
    "\n",
    "#concat_CUIs.to_csv(new_UMLS_CSVs_path+'CUIs.csv',index=False)\n",
    "#concat_CUI_CUIs.to_csv(new_UMLS_CSVs_path+'CUI-CUIs.csv',index=False)\n",
    "#concat_CODEs.to_csv(new_UMLS_CSVs_path+'CODEs.csv',index=False)\n",
    "#concat_CUI_CODEs.to_csv(new_UMLS_CSVs_path+'CUI-CODEs.csv',index=False)\n",
    "#concat_SUIs.to_csv(new_UMLS_CSVs_path+'SUIs.csv',index=False)\n",
    "#concat_CODE_SUIs.to_csv(new_UMLS_CSVs_path+'CODE-SUIs.csv',index=False)\n",
    "\n",
    "# Save just to neo4j db import folder \n",
    "concat_CUIs.to_csv(umls_out_dir+'CUIs.csv',index=False)\n",
    "concat_CUI_CUIs.to_csv(umls_out_dir+'CUI-CUIs.csv',index=False)\n",
    "concat_CODEs.to_csv(umls_out_dir+'CODEs.csv',index=False)\n",
    "concat_CUI_CODEs.to_csv(umls_out_dir+'CUI-CODEs.csv',index=False)\n",
    "concat_SUIs.to_csv(umls_out_dir+'SUIs.csv',index=False)\n",
    "concat_CODE_SUIs.to_csv(umls_out_dir+'CODE-SUIs.csv',index=False)\n",
    "\n",
    "print('Saving files took',(time.time()-t0)/60,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concat_CUI_CODEs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'concat_CUI_CODEs' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "concat_CUI_CODEs.to_csv(umls_out_dir+'CUI-CODEs.csv',index=False)\n",
    "concat_SUIs.to_csv(umls_out_dir+'SUIs.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ALTERNATIVE PATHs to save the build\n",
    "\n",
    "UMLS_KF_2_path = '/Users/stearb/Library/Application Support/com.Neo4j.Relate/Data/dbmss/dbms-02dbd2af-2446-47a9-91d7-4d9a3a435ce0/import/'\n",
    "desktop_path = '/Users/stearb/desktop/hubmap-kg/final_build_csv_data/'\n",
    "\n",
    "# UMLS base64 database path\n",
    "UMLS_base64_path = '/Users/stearb/Library/Application Support/com.Neo4j.Relate/Data/dbmss/dbms-bebc96c2-11d9-4c97-8636-9a630b41457e/import/'\n",
    "\n",
    "concat_CUIs.to_csv(UMLS_base64_path+'CUIs.csv',index=False)\n",
    "concat_CUI_CUIs.to_csv(UMLS_base64_path+'CUI-CUIs.csv',index=False)\n",
    "concat_CODEs.to_csv(UMLS_base64_path+'CODEs.csv',index=False)\n",
    "concat_CUI_CODEs.to_csv(UMLS_base64_path+'CUI-CODEs.csv',index=False)\n",
    "concat_SUIs.to_csv(UMLS_base64_path+'SUIs.csv',index=False)\n",
    "concat_CODE_SUIs.to_csv(UMLS_base64_path+'CODE-SUIs.csv',index=False)\n",
    "concat_CUIs.to_csv(UMLS_KF_2_path+'CUIs.csv',index=False)\n",
    "concat_CUI_CUIs.to_csv(UMLS_KF_2_path+'CUI-CUIs.csv',index=False)\n",
    "concat_CODEs.to_csv(UMLS_KF_2_path+'CODEs.csv',index=False)\n",
    "concat_CUI_CODEs.to_csv(UMLS_KF_2_path+'CUI-CODEs.csv',index=False)\n",
    "concat_SUIs.to_csv(UMLS_KF_2_path+'SUIs.csv',index=False)\n",
    "concat_CODE_SUIs.to_csv(UMLS_KF_2_path+'CODE-SUIs.csv',index=False)\n",
    "#concat_CUI_SUIs.to_csv('/Users/stearb/desktop/hubmap-kg/final_build_csv_data/CUI-SUIs.csv',index=False)\n",
    "\n",
    "\n",
    "concat_CUIs.to_csv(desktop_path+'CUIs.csv',index=False)\n",
    "concat_CUI_CUIs.to_csv(desktop_path+'CUI-CUIs.csv',index=False)\n",
    "concat_CODEs.to_csv(desktop_path+'CODEs.csv',index=False)\n",
    "concat_CUI_CODEs.to_csv(desktop_path+'CUI-CODEs.csv',index=False)\n",
    "concat_SUIs.to_csv(desktop_path+'SUIs.csv',index=False)\n",
    "concat_CODE_SUIs.to_csv(desktop_path+'CODE-SUIs.csv',index=False)\n",
    "#concat_CUI_SUIs.to_csv('/Users/stearb/desktop/hubmap-kg/final_build_csv_data/CUI-SUIs.csv',index=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate number of new nodes, of each type, and number of new relationships, of each type that we will be adding to the graph and do some final checks (asserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1839188"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1019564+ 819624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUIs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of KF CUIs: 3401693\n"
     ]
    }
   ],
   "source": [
    "# Print total number of CUIs were adding\n",
    "print(f'# of KF CUIs: {CUIs_all.shape[0]}')\n",
    "\n",
    "# Check that all CUIs we're adding are KF CUIs (start with 'K')\n",
    "assert CUIs_all.shape[0] == CUIs_all['CUI:ID'].str.contains('K').sum() \n",
    "\n",
    "# Check that there are no duplicates\n",
    "assert CUIs_all['CUI:ID'].duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUI_CUIs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'has_mouse_ortholog': 66754,\n",
       "         'has_human_ortholog': 66754,\n",
       "         'gene_associated_with_disease': 234042,\n",
       "         'disease_has_associated_gene': 234042,\n",
       "         'SCO': 14165,\n",
       "         'has_mouse_phenotype': 1218,\n",
       "         'has_human_phenotype': 1218,\n",
       "         'median_expression_in_gene': 1839188,\n",
       "         'median_expression_in_tissue': 1839188,\n",
       "         'in_gene': 884757,\n",
       "         'in_tissue': 884757,\n",
       "         'in_variant': 884757})"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all CUIs in CUI_CUIs_all are in CUIs_all\n",
    "\n",
    "# First remove all UMLS CUI IDs (starts with a C) from the ':START_ID' and 'END_ID' cols\n",
    "cca_allKF = CUI_CUIs_all[CUI_CUIs_all[':START_ID'].str.contains('K') & CUI_CUIs_all[':END_ID'].str.contains('K')]\n",
    "print(len(cca_allKF))\n",
    "assert np.all(cca_allKF[':START_ID'].isin(CUIs_all['CUI:ID']))\n",
    "assert np.all(cca_allKF[':END_ID'].isin(CUIs_all['CUI:ID']))\n",
    "\n",
    "Counter(CUI_CUIs_all[':TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a row from each of the relationship types\n",
    "#CUI_CUIs_all.drop_duplicates(':TYPE')\n",
    "\n",
    "# ortholog         :   mouse gene <---> human gene\n",
    "# has_phenotype    :   mouse gene <---> mouse phenotype\n",
    "# SCO              :   MP child   <---> MP adult\n",
    "# hpo_mp_crosswalk :   HPO term   <---> MP term\n",
    "# in_gene          :   eQTL       <---> human gene\n",
    "# in_tissue        :   eQTL       <---> (human) tissue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUI_CODEs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3401693, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUI_CODEs_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'HGNC HCOP': 27357,\n",
       "         'MP': 14274,\n",
       "         'GTEX EXP': 1839188,\n",
       "         'GTEX EQTL': 884757,\n",
       "         'DBSNP 151': 636117})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(CODEs_all['SAB']) #.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'HCOP': 27357, 'MP': 14274, 'GTEX': 2723945, 'dbSNP_151': 636117})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([i[0] for i in CODEs_all['CodeID:ID'].str.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODEs_all[CODEs_all['CodeID:ID'].str.contains('KC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check that the Gene to Gene and MP to HPO relationships are  1 to  1 (at the CUI-CODE level). \n",
    "#This will ensure that there are no collisions with CUIs.  \n",
    "#The genes overlap in the ortholog step and the genotype/phenotype step.  \n",
    "#The MP terms overlap in the genotype/phenotype step and HPO MP mapping step.\n",
    "\n",
    "##### Ortholog file (CUI-CODE gene mappings)\n",
    "#orthologs = pd.read_csv('/Users/stearb/desktop/R03_local/data/UI_check/orthologs_uicheck.csv')\n",
    "\n",
    "# Dont need to check human genes CUIs, CODEs, we used the UMLS HGNC CUIs and CODEs\n",
    "#mouse_genes_ortho = orthologs[['CUI_mouse','CODE_mouse']]\n",
    "#assert mouse_genes_ortho.nunique()['CUI_mouse']  ==  mouse_genes_ortho.nunique()['CODE_mouse'] \n",
    "\n",
    "##### Genotype to Phenotype files  (CUI-CODE gene mappings)\n",
    "#genopheno = pd.read_csv('/Users/stearb/desktop/R03_local/data/UI_check/MASTER_G2P.csv')\n",
    "#mouse_pheno_g2p = genopheno[['CUI_mp_term','CODE_mp_term']]\n",
    "#mouse_gene_g2p = genopheno[['CODE_mouse_gene','CUI_mouse_gene']]\n",
    "\n",
    "##### HPO to MP mapping files (CUI-CODE MP mappings)\n",
    "#hpo2mp = pd.read_csv('/Users/stearb/desktop/R03_local/data/UI_check/hpo_mp_mappings.csv')\n",
    "#muse_pheno_hpo2mp = hpo2mp[['CUI_MP','CODE_MP']]\n",
    "\n",
    "##### Mammalian Phenotype Ontology files  (CUI-CODE MP mappings)\n",
    "#mp_ont = pd.read_csv('/Users/stearb/desktop/R03_local/data/UI_check/mp_ontology_uicheck.csv')\n",
    "#mouse_pheno_mpOnt = mp_ont[['CUI','MP_term']]\n",
    "\n",
    "##### Compare mouse gene CUIs and CODEs\n",
    "#cui_mouse_genes = pd.DataFrame(np.concatenate([mouse_genes_ortho.values,\n",
    "#                                               mouse_pheno_g2p.values,mouse_pheno_mpOnt.values]),columns=['CUI','CODE'])\n",
    "# Check that there are equal number of unique mouse gene CUIs and CODEs. We need to \n",
    "# check this because there may be multiple CUIs, but the multiples alwsays need to map to the same CODE,\n",
    "# ie, if the same CUI maps to different CODEs, we have a collision\n",
    "#assert cui_mouse_genes.nunique()['CUI'] == cui_mouse_genes.nunique()['CODE']\n",
    "\n",
    "#### Compare MP term CUIs and CODEs\n",
    "#assert mouse_pheno_g2p.nunique()['CUI_mp_term'] == mouse_pheno_g2p.nunique()['CODE_mp_term']\n",
    "#assert mouse_pheno_hpo2mp.nunique()['CUI_MP'] == mouse_pheno_hpo2mp.nunique()['CODE_MP']\n",
    "#assert mouse_pheno_mpOnt.nunique()['CUI'] == mouse_pheno_mpOnt.nunique()['MP_term']\n",
    "# Combine MP CUIs/CODEs from genophenotype, phenomapping and mp_ontology steps together.\n",
    "#cui_mp_terms  = pd.DataFrame(np.concatenate([mouse_pheno_g2p.values,\n",
    "#                                             mouse_pheno_hpo2mp.values,\n",
    "#                                             mouse_pheno_mpOnt.values]),columns=['CUI','CODE'])\n",
    "# If the mapping is 1 to 1 both columns should have the same number of unique values\n",
    "#assert cui_mp_terms.nunique()['CUI'] == cui_mp_terms.nunique()['CODE']\n",
    "\n",
    "#### Overlap in (mp_term) CUIs and CODEs should be identical from the 3 lists\n",
    "# Overlap in CODEs\n",
    "#venn3([set(mouse_pheno_g2p['CODE_mp_term']),set(mouse_pheno_hpo2mp['CODE_MP']),set(mouse_pheno_mpOnt['MP_term'])]) ; plt.show()\n",
    "# Overlap in CUIs\n",
    "#venn3([set(mouse_pheno_g2p['CUI_mp_term']),set(mouse_pheno_hpo2mp['CUI_MP']),set(mouse_pheno_mpOnt['CUI'])]) ; plt.show()\n",
    "#### Must also load some form of metadata here as well, so we can determine if we have multiple instances of the same CUI,or if its an actual collision (can't do that with CUI alone).\n",
    "### The reason we don't have to compare the CUI-CODE 1 to 1 mapping for all of the CUI lists (like we did for the mouse gene CUIs list and the MP CUIs list) is because the other lists (GTEx and )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "assert UMLS_CUIs.isna().sum().sum() == 0\n",
    "assert UMLS_CUI_CUIs.isna().sum().sum() == 0\n",
    "assert UMLS_CODEs.isna().sum().sum() == 5; \n",
    "UMLS_CODEs.dropna(inplace=True); \n",
    "assert UMLS_CODEs.isna().sum().sum() == 0\n",
    "\n",
    "assert UMLS_CUI_CODEs.isna().sum().sum() == 0\n",
    "assert UMLS_SUIs.isna().sum().sum() == 12; \n",
    "UMLS_SUIs.dropna(inplace=True); \n",
    "assert UMLS_SUIs.isna().sum().sum() == 0\n",
    "\n",
    "assert UMLS_CODEs_SUIs.isna().sum().sum() == 0; \n",
    "#UMLS_CODEs_SUIs.dropna(inplace=True); \n",
    "#assert UMLS_CODEs_SUIs.isna().sum().sum() == 0\n",
    "assert UMLS_CUI_SUIs.isna().sum().sum() == 0'''\n",
    "\n",
    "\n",
    "'''UMLS_CUIs.to_pickle(umls_dir+'CUIs.pickle')\n",
    "\n",
    "UMLS_CUI_CUIs.to_pickle(umls_dir+'CUI-CUIs.pickle')\n",
    "\n",
    "UMLS_CODEs.to_pickle(umls_dir+'CODEs.pickle')\n",
    "\n",
    "UMLS_CUI_CODEs.to_pickle(umls_dir+'CUI-CODEs.pickle')\n",
    "\n",
    "UMLS_SUIs.to_pickle(umls_dir+'SUIs.pickle')\n",
    "\n",
    "# Need to use na_filter = False to prevent the :TYPE 'NA' from being cast to NaN\n",
    "UMLS_CODEs_SUIs.to_pickle(umls_dir+ 'CODE-SUIs.pickle')#,na_filter = False) \n",
    "\n",
    "# Drop rows that contain empty string, ('').\n",
    "#UMLS_CODEs_SUIs = UMLS_CODEs_SUIs[UMLS_CODEs_SUIs[':END_ID'].astype(bool)]\n",
    "\n",
    "UMLS_CUI_SUIs.to_pickle(umls_dir+'CUI-SUIs.pickle')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

#######################################
### Scripts to run graph algorithms ###
#######################################


Before we can run any graph algorithms we need to extract our sub graph from the entire UMLS graph.

We want to include all node types (Concept, Code, Term) from the data
sources we put in the graph as well as any data sources that our data makes a direct relationship to.
These include:

## Added to UMLS
- HGNC HCOP (mouse genes) nodes
- IMPC (no new SAB here, just HGNC and MP nodes)
- MP
- GTEX eqtl and GTEX exp

## IN UMLS already
- HGNC (human genes) nodes
- HPO
- UBERON
#################### We are only going to consider the Concept space (Concept-Concept)...

####### DON'T use gds.graph.create() ##########   whats the difference b/t gds.graph.create() and gds.graph.create.cypher(), both create in-memory?
### Create an in-memory graph w/ gds.graph.create('name','Labels','relationships')
CALL gds.graph.create('my-graph', 'Concept', 'has_human_phenotype')
YIELD graphName, nodeCount, relationshipCount;
Nodes: 9,669,972	Relationships: 1218
remove graph,  CALL gds.graph.drop('myGraph') 
get graph info, CALL gds.graph.list('my-graph3')
check for graph, CALL gds.graph.exists('myGraph') YIELD exists

########### Use apoc.path.subgraphAll to get subgraph########
MATCH (p:Person {name: "Stefan"})
CALL apoc.path.subgraphAll(p, {relationshipFilter: "KNOWS",minLevel: 1,maxLevel: 2}) 
YIELD nodes, relationships RETURN p,nodes, relationships;

### Example of apoc.path.subgraphAll() #######
MATCH (e:COMP) WHERE e.componentID= "f4db22e7-68d2-473d-960b-c98dbbadb3a0" 
with e limit 1 CALL apoc.path.subgraphAll(e, 
{relationshipFilter:'CHILD_OF|CONNECTED_TO|LINKED_TO', limit:10}) YIELD nodes 
UNWIND nodes as node  RETURN node.componentID as uuid, node.orphanID as oid, 
node.cTime as time





####### Or just use  gds.graph.create.cypher()     https://towardsdatascience.com/how-to-get-started-with-the-new-graph-data-science-library-of-neo4j-3c8fff6107b
CALL gds.graph.create.cypher('full_graph','MATCH (n) RETURN id(n) AS id','MATCH (n)-[e]-(m) RETURN id(n) AS source, e.weight AS weight, id(m) AS target')

--------------- UMLS UBERON graph algo results-------------------
###########################################################################################
######### Create a Subgraph of the entire Concept-space on the 'UMLS UBERON' graph  #######  <---- This is the one you want if youre on the server
###########################################################################################
CALL gds.graph.create.cypher('g1', 'MATCH (n:Concept) 
RETURN id(n) AS id', 'MATCH (n:Concept)-[e]-(m:Concept) RETURN id(n) AS source, id(m) AS target' );

##### UMLS UBERON ONLY #####
CALL gds.graph.create.cypher('g1','MATCH (n:Concept) WHERE n.CUI starts with "H" RETURN id(n) AS id','MATCH (n:Concept)-[e]-(m:Concept) RETURN id(n) AS source, id(m) AS target',{validateRelationships: False});




### CALL gds.louvain.stream('g1') yield nodeId,communityId,intermediateCommunityIds
### CALL gds.pageRank.stream('g1') yield nodeId, score
### CALL gds.localClusteringCoefficient.stream('g1') yield nodeId, localClusteringCoefficient
### CALL gds.betweenness.stream('g1') YIELD nodeId, score



######################################
############ GRAPH ALGOS #############  https://neo4j.com/docs/graph-data-science/current/appendix-b/migration-product-algos/
######################################

####### Page Rank ##############
WITH "CALL gds.pageRank.stream('g1') yield nodeId, score" AS query
CALL apoc.export.csv.query(query, "pageRank_concepts.csv", {})
YIELD  done, RETURN done;

##### Betweenness #############
WITH "CALL gds.betweenness.stream('g1') YIELD nodeId, score" AS query
CALL apoc.export.csv.query(query, "betweenness_concepts.csv", {})
YIELD  done RETURN done;



######## Mutate graph w/ algo score as property #####
gds.pageRank.mutate()
 CALL gds.pageRank.mutate('g1', {mutateProperty: 'score'});
#######
CALL gds.pageRank.mutate('g1', {
  maxIterations: 20,
  dampingFactor: 0.85,
  mutateProperty: 'pagerank'
})
YIELD nodePropertiesWritten, ranIterations
#######
CALL gds.pageRank.stream('g1')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).name AS name, score
ORDER BY score DESC, name ASC
#######
CALL gds.pageRank.stream('categorical_men',
    {relationshipWeightProperty:'weight'})
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).Label as name, score
#######
CALL gds.util.nodeProperty('g1','pagerank')
#######
CALL gds.pageRank.write('g1', {
  maxIterations: 20,
  dampingFactor: 0.85,
  writeProperty: 'pagerank'
})
YIELD nodePropertiesWritten, ranIterations



CALL gds.pageRank.stream('g1')
YIELD nodeId, score
RETURN gds.util.asNode(nodeId).Label as name, score
ORDER BY score DESC LIMIT 5

CALL gds.graph.create.cypher('g1', 'MATCH (n:Concept) RETURN id(n) AS id',
'MATCH (n:Concept)-[e]-(m:Concept) RETURN id(n) AS source, id(m) AS target, n.CUI as CUI' )

# Native Projection
CALL gds.graph.create('g1', 'Concept', '*', {nodeProperties: ['CUI']})
YIELD graphName, nodeCount, relationshipCount;



########### Stream node properties (after mutating graph to add) #########
########## This way we can return the score along with the CUI which allows us to map the scores by SAB  via the CUI-CODE file ######
CALL gds.graph.streamNodeProperties('g1', ['ID'])






#### Louvain #####
CALL gds.louvain.stream('my-graph3') YIELD nodeId, communityId, intermediateCommunityIds
### Node Similarity ###
CALL gds.nodeSimilarity.stream('my-graph3') YIELD node1, node2, similarity
### Weakly Connected Components ###
CALL gds.wcc.stream('myGraph') YIELD nodeId, componentId


### Page Rank ###
CALL gds.pageRank.stream('my-graph3',{maxIterations: 2})

### Triangle Counts ####
CALL gds.triangleCount.stream('myGraph')       // relationship  orientation must be 'UNDIRECTED'
YIELD nodeId, triangleCount

### Clustering Coefficients ###
CALL gds.localClusteringCoefficient.stream('myGraph')     // relationship  orientation must be 'UNDIRECTED'
YIELD nodeId, localClusteringCoefficient

### Betweenness Centrality ###
CALL gds.betweenness.stream('myGraph') YIELD nodeId, score

#####################################
######### Helpful queries ###########
#####################################

Check memory estimation of algorithm (just bc the estimate fits into memory (max heap size) this does not guaruntee the actual query will fit.)
------------------------------------
CALL gds.louvain.stream.estimate('g1') 


# Return info about graph projection
CALL gds.graph.list('g1') YIELD
  graphName,
  database,
  nodeProjection,
  relationshipProjection,
  nodeQuery,
  relationshipQuery,
  nodeCount,
  relationshipCount,
  schema,
  degreeDistribution,
  density,
  creationTime,
  modificationTime,
  sizeInBytes,
  memoryUsage;
  

  

# How to get a list of nodeIds with their node type, for plotting
MATCH (n:Concept) WHERE n.CUI starts with "H" RETURN id(n) AS id, labels(n) as nodetype

# List of Concepts, with their attached Code node SABs
MATCH (n:Concept)-[:CODE]-(c:Code) WHERE n.CUI starts with "H" RETURN id(n) AS id, c.SAB as sab


###############
### Degree ####   (Make sure single quotes are of this kind: " ' ")
###############   (Run the first one on cluster in bin/cypher-shell)

# seperate queries by semicolon allows you to put multiple queries in a single script in the cypher-shell. 
If you want to execute multiple queries at a time in the desktop you need to go to the settings tab and enable multiple query capability
cypher-shell --format plain < query.txt # write results to a file without apoc.export.csv function


# Degree of whole concept space
WITH "MATCH (c:Concept)-[*1]-(c2:Concept) RETURN c as concept,count(c2) as degree" AS query  CALL apoc.export.csv.query(query, "degree-concept.csv", {})  
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data  
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data; 

# Degree of HGNC concept space
WITH "MATCH (hgnc_code:Code {SAB: 'HGNC'})-[:CODE]-(c:Concept)-[*1]-(c2:Concept) RETURN c as concept,count(c2) as degree" AS query  CALL apoc.export.csv.query(query, "degree-HGNC-concepts.csv", {})  
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data  
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data; 

# Degree of HPO concept space
WITH "MATCH (hpo_code:Code {SAB: 'HPO'})-[:CODE]-(c:Concept)-[*1]-(c2:Concept) RETURN c as concept, count(c2) as degree" AS query
CALL apoc.export.csv.query(query, "degree-concept-HPO.csv", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;

# Degree of UBERON concept space
WITH "MATCH (ub_code:Code {SAB: 'UBERON'})-[:CODE]-(c:Concept)-[*1]-(c2:Concept) RETURN c as concept,count(c2) as degree" AS query
CALL apoc.export.csv.query(query, "degree-concept-UBERON.csv", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;

# Degree of GTEx concept space
WITH "MATCH (gtex:Code)-[:CODE]-(c:Concept)-[*1]-(c2:Concept) WHERE gtex.SAB = 'GTEX EQTL' or gtex.SAB = 'GTEX EXP'
RETURN c as concept,count(c2) as degree" AS query
CALL apoc.export.csv.query(query, "degree-concept-GTEX-both.csv", {})
YIELD file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data
RETURN file, source, format, nodes, relationships, properties, time, rows, batchSize, batches, done, data;


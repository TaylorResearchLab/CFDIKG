#########################################################################
#### Code/notes for interacting with the Spark cluster on Kids First ####
#########################################################################


%pyspark
# Show cohorts accessible to the user
oc_studies = spark.table('occurrences').select('study_id').distinct()
t_st = spark.table('studies').select('kf_id', 'short_name')
r = oc_studies.join(t_st, oc_studies['study_id'] == t_st['kf_id']).select('study_id', 'short_name')
z.show(r)

# The above paragraph shows actual studies accessible to you, but it takes some time (I have access to 17 studies and it took ~6 min)

------------------------------------------------------------------------------------------


In the Zepplin notebooks, have you ever had to re-code data to an additive model (0,1,2)?
, turning 0/0 to 0, 0/1 to 1, 1/1 to 2?

t_vrt = spark \
    .table('variants') \
    .withColumn('max_gnomad_topmed', F.greatest(F.lit(0), F.col('topmed')['af'], F.col('gnomad_exomes_2_1')['af'], \
        F.col('gnomad_genomes_2_1')['af'], F.col('gnomad_genomes_3_0')['af'], F.col('gnomad_genomes_3_1_1')['af'])) \
    .where(F.size(F.array_intersect(F.col('studies'), F.lit(F.array(*map(F.lit, study_id_list))))) > 0) \
    .select(cond + c_vrt)


# you can use something like this (the function getItem() starts an array from index 0)
output.withColumn('AdditiveModelGenotype', t_ocr.calls.getItem(0) + t_ocr.calls.getItem(1))

# or (the function element_at() starts an array from index 1)
from pyspark.sql import functions as F
output.withColumn('AdditiveModelGenotype', F.element_at(t_ocr.calls, 1) + F.element_at(t_ocr.calls, 2))
